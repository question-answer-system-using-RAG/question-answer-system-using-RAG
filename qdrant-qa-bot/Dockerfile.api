# Dockerfile.api - для API сервиса
FROM python:3.10-slim

# Устанавливаем рабочую директорию внутри контейнера
WORKDIR /app

# Устанавливаем необходимые системные зависимости
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    g++ \
    python3-dev \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Копируем файл с зависимостями
COPY requirements.txt .

# Устанавливаем NumPy отдельно до других зависимостей
RUN pip install --no-cache-dir numpy

# Устанавливаем остальные зависимости
RUN pip install --no-cache-dir -r requirements.txt

# Создаем директорию для моделей
RUN mkdir -p /app/models

# Копируем файлы приложения в контейнер
COPY pipeline_file.py api.py ./

# Скачиваем необходимые ресурсы NLTK
RUN python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# Скачиваем модель deepseek-coder
RUN mkdir -p /app/models && \
    wget -q "https://gpt4all.io/models/gguf/deepseek-coder-1.3b-instruct.Q4_K_M.gguf" -O /app/models/deepseek-coder-1.3b-instruct.Q4_K_M.gguf || echo "Модель будет скачана при первом запуске"

# Устанавливаем переменную окружения для хранения моделей gpt4all
ENV GPT4ALL_MODEL_PATH=/app/models

# Указываем переменные для подключения к Qdrant
ENV QDRANT_HOST=qdrant
ENV QDRANT_PORT=6333

# Указываем порт, который будет использоваться
EXPOSE 8000

# Запускаем API сервер
CMD ["python", "api.py"]