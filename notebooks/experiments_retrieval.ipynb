{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Union, Optional\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Абстрактный класс для моделей эмбеддинга\n",
    "class EmbeddingModel(ABC):\n",
    "    @abstractmethod\n",
    "    def compute_embeddings(self, texts: List[str]) -> Union[List[List[float]], np.ndarray]:\n",
    "        \"\"\"Вычисляет эмбеддинги для списка текстов.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_single_embedding(self, text: str) -> Union[List[float], np.ndarray]:\n",
    "        \"\"\"Вычисляет эмбеддинг для одного текста.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_vector_size(self) -> int:\n",
    "        \"\"\"Возвращает размерность векторов для модели.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"Возвращает имя модели для отчетов.\"\"\"\n",
    "        pass\n",
    "\n",
    "# Реализация для SentenceTransformer\n",
    "class SentenceTransformerModel(EmbeddingModel):\n",
    "    def __init__(self, model_name: str = 'BAAI/bge-large-en-v1.5'):\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def compute_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings = self.model.encode(texts, normalize_embeddings=True)\n",
    "        return [embedding.tolist() for embedding in embeddings]\n",
    "    \n",
    "    def compute_single_embedding(self, text: str) -> List[float]:\n",
    "        embedding = self.model.encode(text, normalize_embeddings=True)\n",
    "        return embedding.tolist()\n",
    "    \n",
    "    def get_vector_size(self) -> int:\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    def get_model_name(self) -> str:\n",
    "        return f\"SentenceTransformer-{self.model_name.split('/')[-1]}\"\n",
    "\n",
    "# Реализация для BM25\n",
    "class BM25Model(EmbeddingModel):\n",
    "    def __init__(self):\n",
    "        self.corpus = None\n",
    "        self.bm25 = None\n",
    "        self.vector_size = 768  # Фиктивное значение для совместимости с Qdrant\n",
    "        # Подготовка для токенизации и стемминга\n",
    "        self.stemmer = PorterStemmer()\n",
    "        try:\n",
    "            nltk.data.find('tokenizers/punkt')\n",
    "            nltk.data.find('corpora/stopwords')\n",
    "        except LookupError:\n",
    "            nltk.download('punkt')\n",
    "            nltk.download('stopwords')\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Предобработка текста: токенизация, удаление стоп-слов, стемминг.\"\"\"\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        tokens = [self.stemmer.stem(token) for token in tokens if token.isalnum() and token not in self.stop_words]\n",
    "        return tokens\n",
    "    \n",
    "    def initialize_corpus(self, texts: List[str]) -> None:\n",
    "        \"\"\"Инициализация индекса BM25 на основе корпуса документов.\"\"\"\n",
    "        processed_corpus = [self.preprocess_text(text) for text in texts]\n",
    "        self.corpus = texts  # Сохраняем оригинальные тексты\n",
    "        self.bm25 = BM25Okapi(processed_corpus)\n",
    "    \n",
    "    def compute_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Для BM25 возвращаем фиктивные эмбеддинги.\n",
    "        В реальном использовании будем напрямую использовать BM25 для поиска.\n",
    "        \"\"\"\n",
    "        if self.corpus is None:\n",
    "            self.initialize_corpus(texts)\n",
    "        \n",
    "        # Возвращаем фиктивные эмбеддинги для совместимости с API\n",
    "        return np.random.rand(len(texts), self.vector_size)\n",
    "    \n",
    "    def compute_single_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Для BM25 эмбеддинг не используется.\n",
    "        Возвращаем фиктивный эмбеддинг для совместимости с API.\n",
    "        \"\"\"\n",
    "        return np.random.rand(self.vector_size)\n",
    "    \n",
    "    def get_vector_size(self) -> int:\n",
    "        return self.vector_size\n",
    "    \n",
    "    def get_model_name(self) -> str:\n",
    "        return \"BM25\"\n",
    "    \n",
    "    def search(self, query: str, limit: int = 6) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Поиск схожих документов с помощью BM25.\"\"\"\n",
    "        if self.bm25 is None:\n",
    "            raise ValueError(\"BM25 не инициализирован. Сначала вызовите compute_embeddings с корпусом документов.\")\n",
    "        \n",
    "        query_tokens = self.preprocess_text(query)\n",
    "        scores = self.bm25.get_scores(query_tokens)\n",
    "        \n",
    "        # Получаем индексы документов, отсортированных по убыванию релевантности\n",
    "        top_indices = np.argsort(scores)[::-1][:limit]\n",
    "        \n",
    "        # Формируем результаты в том же формате, что и для других моделей\n",
    "        results = []\n",
    "        for i in top_indices:\n",
    "            if scores[i] > 0:  # Добавляем только документы с ненулевой релевантностью\n",
    "                results.append({\n",
    "                    'id': i,\n",
    "                    'text': self.corpus[i],\n",
    "                    'score': float(scores[i])\n",
    "                })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модифицированный класс QdrantManager для поддержки разных моделей\n",
    "class QdrantManager:\n",
    "    \"\"\"Класс для работы с базой Qdrant.\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model: EmbeddingModel = None):\n",
    "        self.client = QdrantClient(\":memory:\")\n",
    "        self.collection_name = \"documentation\"\n",
    "        self.embedding_model = embedding_model\n",
    "        # Для сохранения оригинальных текстов (нужно для BM25)\n",
    "        self.corpus = []\n",
    "        self.id_to_idx = {}  # Отображение id -> индекс в corpus\n",
    "    \n",
    "    def set_embedding_model(self, embedding_model: EmbeddingModel) -> None:\n",
    "        \"\"\"Устанавливает модель для эмбеддинга.\"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "    \n",
    "    def initialize_collection(self, vector_size: int = None):\n",
    "        \"\"\"Инициализирует коллекцию в Qdrant.\"\"\"\n",
    "        if vector_size is None and self.embedding_model is not None:\n",
    "            vector_size = self.embedding_model.get_vector_size()\n",
    "        \n",
    "        # Удаление существующей коллекции, если она есть\n",
    "        try:\n",
    "            self.client.delete_collection(collection_name=self.collection_name)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # Создание новой коллекции\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=vector_size,\n",
    "                distance=models.Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Очистка корпуса при инициализации новой коллекции\n",
    "        self.corpus = []\n",
    "        self.id_to_idx = {}\n",
    "    \n",
    "    def upsert_batch(self, id_offset: int, vectors: List[List[float]], \n",
    "                    payloads: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Добавляет партию данных в Qdrant.\"\"\"\n",
    "        # Сохраняем тексты в корпусе (для BM25)\n",
    "        for idx, payload in enumerate(payloads):\n",
    "            corpus_idx = len(self.corpus)\n",
    "            self.corpus.append(payload['text'])\n",
    "            self.id_to_idx[idx + id_offset] = corpus_idx\n",
    "        \n",
    "        # Добавляем в Qdrant\n",
    "        points = [\n",
    "            models.PointStruct(\n",
    "                id=idx + id_offset,\n",
    "                vector=vector,\n",
    "                payload=payload\n",
    "            )\n",
    "            for idx, (vector, payload) in enumerate(zip(vectors, payloads))\n",
    "        ]\n",
    "        \n",
    "        self.client.upsert(\n",
    "            collection_name=self.collection_name,\n",
    "            points=points\n",
    "        )\n",
    "    \n",
    "    def search(self, query: str, limit: int = 6) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Выполняет поиск похожих документов.\"\"\"\n",
    "        # Для BM25 используем прямой поиск\n",
    "        if isinstance(self.embedding_model, BM25Model):\n",
    "            return self.embedding_model.search(query, limit=limit)\n",
    "        \n",
    "        # Для других моделей используем Qdrant\n",
    "        query_vector = self.embedding_model.compute_single_embedding(query)\n",
    "        search_result = self.client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            query_vector=query_vector,\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                'text': hit.payload['text'],\n",
    "                'id': hit.payload['id'],\n",
    "                'score': hit.score\n",
    "            }\n",
    "            for hit in search_result\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCalculator:\n",
    "    \"\"\"Класс для расчета метрик оценки качества поиска.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_recall_at_k(relevant_ids: List[int], retrieved_ids: List[int], k: int) -> float:\n",
    "        \"\"\"Рассчитывает Recall@k для одного запроса.\"\"\"\n",
    "        if not relevant_ids:\n",
    "            return 0.0\n",
    "        \n",
    "        relevant_retrieved = set(relevant_ids).intersection(set(retrieved_ids[:k]))\n",
    "        return len(relevant_retrieved) / len(relevant_ids)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_precision_at_k(relevant_ids: List[int], retrieved_ids: List[int], k: int) -> float:\n",
    "        \"\"\"Рассчитывает Precision@k для одного запроса.\"\"\"\n",
    "        if k == 0 or not retrieved_ids:\n",
    "            return 0.0\n",
    "        \n",
    "        relevant_retrieved = set(relevant_ids).intersection(set(retrieved_ids[:k]))\n",
    "        return len(relevant_retrieved) / min(k, len(retrieved_ids))\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_mrr_at_k(relevant_ids: List[int], retrieved_ids: List[int], k: int) -> float:\n",
    "        \"\"\"Рассчитывает MRR@k (Mean Reciprocal Rank) для одного запроса.\"\"\"\n",
    "        if not relevant_ids or not retrieved_ids:\n",
    "            return 0.0\n",
    "        \n",
    "        for i, doc_id in enumerate(retrieved_ids[:k]):\n",
    "            if doc_id in relevant_ids:\n",
    "                return 1.0 / (i + 1)\n",
    "        return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_ndcg_at_k(relevant_ids: List[int], retrieved_ids: List[int], k: int) -> float:\n",
    "        \"\"\"Рассчитывает nDCG@k для одного запроса вручную.\"\"\"\n",
    "        if not relevant_ids or not retrieved_ids or k <= 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Обрезаем список до k элементов\n",
    "        retrieved_ids_k = retrieved_ids[:k]\n",
    "        \n",
    "        # Создаем вектор релевантности (1 для релевантных документов, 0 для нерелевантных)\n",
    "        relevance = [1.0 if doc_id in relevant_ids else 0.0 for doc_id in retrieved_ids_k]\n",
    "        \n",
    "        # Если нет релевантных документов среди извлеченных, возвращаем 0\n",
    "        if sum(relevance) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Вычисляем DCG (Discounted Cumulative Gain)\n",
    "        dcg = 0.0\n",
    "        for i, rel in enumerate(relevance):\n",
    "            # Используем формулу DCG = rel_1 + rel_2/log2(2+1) + rel_3/log2(3+1) + ...\n",
    "            if rel > 0:\n",
    "                dcg += rel / np.log2(i + 2)  # +2 потому что индексация с 0, и log2(1)=0\n",
    "        \n",
    "        # Вычисляем идеальный DCG (IDCG)\n",
    "        # В идеальном случае релевантные документы находятся в начале списка\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = 0.0\n",
    "        for i, rel in enumerate(ideal_relevance):\n",
    "            if rel > 0:\n",
    "                idcg += rel / np.log2(i + 2)\n",
    "        \n",
    "        # nDCG = DCG / IDCG\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_average_metrics(metrics_list: List[Dict[str, float]]) -> Dict[str, float]:\n",
    "        \"\"\"Вычисляет средние значения метрик по всем запросам.\"\"\"\n",
    "        if not metrics_list:\n",
    "            return {}\n",
    "        \n",
    "        # Инициализируем результирующий словарь\n",
    "        result = {}\n",
    "        \n",
    "        # Собираем все ключи метрик\n",
    "        all_keys = set()\n",
    "        for metrics in metrics_list:\n",
    "            all_keys.update(metrics.keys())\n",
    "        \n",
    "        # Вычисляем среднее значение для каждой метрики\n",
    "        for key in all_keys:\n",
    "            values = [metrics.get(key, 0.0) for metrics in metrics_list]\n",
    "            result[key] = sum(values) / len(metrics_list)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модифицированный класс DocumentationQA\n",
    "class DocumentationQA:\n",
    "    \"\"\"Главный класс, объединяющий все компоненты системы.\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model: Optional[EmbeddingModel] = None):\n",
    "        # Если модель не передана, используем SentenceTransformer по умолчанию\n",
    "        self.embedding_model = embedding_model or SentenceTransformerModel()\n",
    "        self.qdrant_manager = QdrantManager(self.embedding_model)\n",
    "        self.metrics_calculator = MetricsCalculator()\n",
    "        self.is_initialized = False\n",
    "        self.df = None\n",
    "        self.section_id_map = {}  # Для хранения мапинга section_content -> id\n",
    "    \n",
    "    def set_embedding_model(self, embedding_model: EmbeddingModel) -> None:\n",
    "        \"\"\"Устанавливает модель для эмбеддинга и сбрасывает инициализацию.\"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "        self.qdrant_manager.set_embedding_model(embedding_model)\n",
    "        self.is_initialized = False\n",
    "    \n",
    "    def load_data(self, file_path: str = 'qdrant_documentation_dataset.csv'):\n",
    "        \"\"\"Загружает данные из CSV файла.\"\"\"\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        print(f\"Загружено {len(self.df)} записей из датасета.\")\n",
    "    \n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализирует базу данных, добавляя чанки из датасета в Qdrant.\"\"\"\n",
    "        if self.is_initialized:\n",
    "            return\n",
    "        \n",
    "        if self.df is None:\n",
    "            raise ValueError(\"Данные не загружены. Вызовите метод load_data() перед инициализацией базы.\")\n",
    "        \n",
    "        # Получаем уникальные чанки контента\n",
    "        sections = self.df['section_content'].unique()\n",
    "        print(f\"Найдено {len(sections)} уникальных чанков для индексации.\")\n",
    "        \n",
    "        # Создаем мапинг section_content -> id\n",
    "        for idx, section in enumerate(sections):\n",
    "            self.section_id_map[section] = idx\n",
    "        \n",
    "        # Инициализация коллекции Qdrant\n",
    "        vector_size = self.embedding_model.get_vector_size()\n",
    "        self.qdrant_manager.initialize_collection(vector_size=vector_size)\n",
    "        \n",
    "        # Специальная обработка для BM25\n",
    "        if isinstance(self.embedding_model, BM25Model):\n",
    "            self.embedding_model.initialize_corpus(sections)\n",
    "        \n",
    "        # Вычисление эмбеддингов и добавление в Qdrant\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(sections), batch_size):\n",
    "            batch = sections[i:i + batch_size]\n",
    "            \n",
    "            # Вычисление эмбеддингов\n",
    "            print(f\"Вычисление эмбеддингов для батча {i//batch_size + 1}/{(len(sections) - 1)//batch_size + 1}\")\n",
    "            embeddings = self.embedding_model.compute_embeddings(batch)\n",
    "            \n",
    "            # Подготовка payload\n",
    "            payloads = [\n",
    "                {\n",
    "                    'text': section,\n",
    "                    'id': self.section_id_map[section]\n",
    "                }\n",
    "                for section in batch\n",
    "            ]\n",
    "            \n",
    "            # Добавление в Qdrant\n",
    "            self.qdrant_manager.upsert_batch(i, embeddings, payloads)\n",
    "        \n",
    "        self.is_initialized = True\n",
    "        print(f\"База данных успешно инициализирована с моделью {self.embedding_model.get_model_name()}.\")\n",
    "    \n",
    "    def search_similar_sections(self, query: str, top_k: int = 6) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Ищет чанки, похожие на запрос.\"\"\"\n",
    "        # Поиск через менеджер Qdrant (он определит нужный метод поиска)\n",
    "        return self.qdrant_manager.search(query, limit=top_k)\n",
    "    \n",
    "    def evaluate_model(self, k_values: List[int] = [1, 4, 6]) -> Dict[str, float]:\n",
    "        \"\"\"Оценивает модель по различным метрикам.\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            self.initialize_database()\n",
    "        \n",
    "        all_metrics = []\n",
    "        model_name = self.embedding_model.get_model_name()\n",
    "        \n",
    "        print(f\"Оценка модели: {model_name}\")\n",
    "        \n",
    "        # Перебираем все вопросы в датасете\n",
    "        for idx, row in tqdm(self.df.iterrows(), total=len(self.df), desc=\"Оценка модели\"):\n",
    "            question = row['question']\n",
    "            relevant_section = row['section_content']\n",
    "            relevant_id = self.section_id_map[relevant_section]\n",
    "            \n",
    "            # Получаем результаты поиска\n",
    "            search_results = self.search_similar_sections(question, top_k=max(k_values))\n",
    "            retrieved_ids = [result['id'] for result in search_results]\n",
    "            \n",
    "            # Рассчитываем метрики для текущего запроса\n",
    "            query_metrics = {}\n",
    "            for k in k_values:\n",
    "                query_metrics[f'Recall@{k}'] = self.metrics_calculator.calculate_recall_at_k([relevant_id], retrieved_ids, k)\n",
    "                query_metrics[f'Precision@{k}'] = self.metrics_calculator.calculate_precision_at_k([relevant_id], retrieved_ids, k)\n",
    "                query_metrics[f'MRR@{k}'] = self.metrics_calculator.calculate_mrr_at_k([relevant_id], retrieved_ids, k)\n",
    "                query_metrics[f'nDCG@{k}'] = self.metrics_calculator.calculate_ndcg_at_k([relevant_id], retrieved_ids, k)\n",
    "            \n",
    "            all_metrics.append(query_metrics)\n",
    "        \n",
    "        # Вычисляем средние метрики\n",
    "        average_metrics = self.metrics_calculator.compute_average_metrics(all_metrics)\n",
    "        \n",
    "        # Добавляем информацию о модели\n",
    "        average_metrics['model_name'] = model_name\n",
    "        \n",
    "        return average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для тестирования нескольких моделей и сравнения их результатов\n",
    "def compare_models(data_path: str = 'qdrant_documentation_dataset.csv', k_values: List[int] = [1, 4, 6]):\n",
    "    \"\"\"Сравнивает различные модели и выводит их метрики.\"\"\"\n",
    "    # Создаем объект DocumentationQA\n",
    "    qa_system = DocumentationQA()\n",
    "    \n",
    "    # Загружаем данные\n",
    "    qa_system.load_data(data_path)\n",
    "    \n",
    "    # Список моделей для тестирования\n",
    "    models = [\n",
    "        SentenceTransformerModel('BAAI/bge-large-en-v1.5'),\n",
    "        SentenceTransformerModel('intfloat/multilingual-e5-large'),\n",
    "        BM25Model()\n",
    "    ]\n",
    "    \n",
    "    # Оценка каждой модели\n",
    "    results = []\n",
    "    for model in models:\n",
    "        print(f\"\\n===== Тестирование модели: {model.get_model_name()} =====\")\n",
    "        \n",
    "        # Устанавливаем модель\n",
    "        qa_system.set_embedding_model(model)\n",
    "        \n",
    "        # Инициализируем базу данных с новой моделью\n",
    "        qa_system.initialize_database()\n",
    "        \n",
    "        # Оцениваем модель\n",
    "        metrics = qa_system.evaluate_model(k_values=k_values)\n",
    "        results.append(metrics)\n",
    "        \n",
    "        # Выводим результаты для текущей модели\n",
    "        print(\"\\nМетрики:\")\n",
    "        for metric_name, value in sorted(metrics.items()):\n",
    "            if metric_name != 'model_name':\n",
    "                print(f\"{metric_name}: {value:.4f}\")\n",
    "    \n",
    "    # Сравнительная таблица метрик\n",
    "    print(\"\\n===== Сравнение моделей =====\")\n",
    "    \n",
    "    # Получаем все метрики\n",
    "    all_metric_names = set()\n",
    "    for result in results:\n",
    "        all_metric_names.update([k for k in result.keys() if k != 'model_name'])\n",
    "    \n",
    "    # Форматируем таблицу\n",
    "    metric_names_sorted = sorted(all_metric_names)\n",
    "    model_names = [result['model_name'] for result in results]\n",
    "    \n",
    "    # Верхний заголовок таблицы\n",
    "    header = f\"{'Метрика':<15} | \" + \" | \".join(f\"{name:<25}\" for name in model_names)\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    \n",
    "    # Строки таблицы\n",
    "    for metric in metric_names_sorted:\n",
    "        row = f\"{metric:<15} | \"\n",
    "        for result in results:\n",
    "            value = result.get(metric, 0.0)\n",
    "            row += f\"{value:.4f}{' ' * (25 - len(f'{value:.4f}'))}\"\n",
    "            row += \" | \"\n",
    "        print(row[:-3])  # Убираем лишний разделитель в конце\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 328 записей из датасета.\n",
      "\n",
      "===== Модель: SentenceTransformer-bge-large-en-v1.5 =====\n",
      "Найдено 121 уникальных чанков для индексации.\n",
      "Вычисление эмбеддингов для батча 1/2\n",
      "Вычисление эмбеддингов для батча 2/2\n",
      "База данных успешно инициализирована с моделью SentenceTransformer-bge-large-en-v1.5.\n",
      "Оценка модели: SentenceTransformer-bge-large-en-v1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка модели:   0%|          | 0/328 [00:00<?, ?it/s]C:\\Users\\sekho\\AppData\\Local\\Temp\\ipykernel_25444\\1846738923.py:73: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = self.client.search(\n",
      "Оценка модели: 100%|██████████| 328/328 [00:28<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics:\n",
      "\n",
      "Recall@k:\n",
      "  Recall@1: 0.7012\n",
      "  Recall@4: 0.8811\n",
      "  Recall@6: 0.9146\n",
      "\n",
      "Precision@k:\n",
      "  Precision@1: 0.7012\n",
      "  Precision@4: 0.2203\n",
      "  Precision@6: 0.1524\n",
      "\n",
      "MRR@k:\n",
      "  MRR@1: 0.7012\n",
      "  MRR@4: 0.7800\n",
      "  MRR@6: 0.7865\n",
      "\n",
      "nDCG@k:\n",
      "  nDCG@1: 0.7012\n",
      "  nDCG@4: 0.8058\n",
      "  nDCG@6: 0.8186\n",
      "\n",
      "==================================================\n",
      "\n",
      "===== Модель: SentenceTransformer-multilingual-e5-large =====\n",
      "Найдено 121 уникальных чанков для индексации.\n",
      "Вычисление эмбеддингов для батча 1/2\n",
      "Вычисление эмбеддингов для батча 2/2\n",
      "База данных успешно инициализирована с моделью SentenceTransformer-multilingual-e5-large.\n",
      "Оценка модели: SentenceTransformer-multilingual-e5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка модели: 100%|██████████| 328/328 [00:31<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics:\n",
      "\n",
      "Recall@k:\n",
      "  Recall@1: 0.6189\n",
      "  Recall@4: 0.8598\n",
      "  Recall@6: 0.8933\n",
      "\n",
      "Precision@k:\n",
      "  Precision@1: 0.6189\n",
      "  Precision@4: 0.2149\n",
      "  Precision@6: 0.1489\n",
      "\n",
      "MRR@k:\n",
      "  MRR@1: 0.6189\n",
      "  MRR@4: 0.7172\n",
      "  MRR@6: 0.7234\n",
      "\n",
      "nDCG@k:\n",
      "  nDCG@1: 0.6189\n",
      "  nDCG@4: 0.7533\n",
      "  nDCG@6: 0.7658\n",
      "\n",
      "==================================================\n",
      "\n",
      "===== Модель: BM25 =====\n",
      "Найдено 121 уникальных чанков для индексации.\n",
      "Вычисление эмбеддингов для батча 1/2\n",
      "Вычисление эмбеддингов для батча 2/2\n",
      "База данных успешно инициализирована с моделью BM25.\n",
      "Оценка модели: BM25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка модели: 100%|██████████| 328/328 [00:00<00:00, 3205.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics:\n",
      "\n",
      "Recall@k:\n",
      "  Recall@1: 0.5823\n",
      "  Recall@4: 0.8262\n",
      "  Recall@6: 0.8628\n",
      "\n",
      "Precision@k:\n",
      "  Precision@1: 0.5823\n",
      "  Precision@4: 0.2066\n",
      "  Precision@6: 0.1438\n",
      "\n",
      "MRR@k:\n",
      "  MRR@1: 0.5823\n",
      "  MRR@4: 0.6855\n",
      "  MRR@6: 0.6923\n",
      "\n",
      "nDCG@k:\n",
      "  nDCG@1: 0.5823\n",
      "  nDCG@4: 0.7213\n",
      "  nDCG@6: 0.7350\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Простая функция для вывода всех метрик по каждой модели.\"\"\"\n",
    "    # Список моделей для тестирования\n",
    "    models = [\n",
    "        SentenceTransformerModel('BAAI/bge-large-en-v1.5'),\n",
    "        SentenceTransformerModel('intfloat/multilingual-e5-large'),\n",
    "        BM25Model()\n",
    "    ]\n",
    "    \n",
    "    # Создаем объект DocumentationQA\n",
    "    qa_system = DocumentationQA()\n",
    "    \n",
    "    # Загружаем данные\n",
    "    qa_system.load_data('qdrant_documentation_dataset.csv')\n",
    "    \n",
    "    # Перебираем модели и выводим их метрики\n",
    "    for model in models:\n",
    "        print(f\"\\n===== Модель: {model.get_model_name()} =====\")\n",
    "        \n",
    "        # Устанавливаем модель\n",
    "        qa_system.set_embedding_model(model)\n",
    "        \n",
    "        # Инициализируем базу данных с новой моделью\n",
    "        qa_system.initialize_database()\n",
    "        \n",
    "        # Оцениваем модель\n",
    "        metrics = qa_system.evaluate_model(k_values=[1, 4, 6])\n",
    "        \n",
    "        # Выводим метрики по группам\n",
    "        print(\"\\nMetrics:\")\n",
    "        \n",
    "        # Recall\n",
    "        print(\"\\nRecall@k:\")\n",
    "        for k in [1, 4, 6]:\n",
    "            print(f\"  Recall@{k}: {metrics.get(f'Recall@{k}', 0.0):.4f}\")\n",
    "        \n",
    "        # Precision\n",
    "        print(\"\\nPrecision@k:\")\n",
    "        for k in [1, 4, 6]:\n",
    "            print(f\"  Precision@{k}: {metrics.get(f'Precision@{k}', 0.0):.4f}\")\n",
    "        \n",
    "        # MRR\n",
    "        print(\"\\nMRR@k:\")\n",
    "        for k in [1, 4, 6]:\n",
    "            print(f\"  MRR@{k}: {metrics.get(f'MRR@{k}', 0.0):.4f}\")\n",
    "        \n",
    "        # nDCG\n",
    "        print(\"\\nnDCG@k:\")\n",
    "        for k in [1, 4, 6]:\n",
    "            print(f\"  nDCG@{k}: {metrics.get(f'nDCG@{k}', 0.0):.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
