# Эксперименты с retrieval
Были выбраны три базовые модели: SentenceTransformer('intfloat/multilingual-e5-large'), SentenceTransformer('BAAI/bge-large-en-v1.5'), BM25 и четыре реранкера: cross-encoder/ms-marco-MiniLM-L-12-v2, BAAI/bge-reranker-base, nboost/pt-tinybert-msmarco, sentence-transformers/msmarco-distilbert-base-tas-b. Также аналитически было выделено количество фрагментов, которые целесообразно вытягивать из массивов документации: 4 и 6 фрагментов на тестирование. Обоснование этого лежит в ноутбуке eda.

Итого, было проведено 30 экспериментов с retrieval частью: с каждой из три базовых моделей 1 вариант без реранкера и 4 варианта с различным реранкерами, а также с вытягиванием 4 и 6 фрагментов для каждого из вариантов. Цель - корректно выбирать 1 (первый) фрагмент, т.к. именно его будет отдавать LLM на этапе generation. 

Оценку проводим в срелующих метриках: Recall@1/4/6, Precision@1/4/6, MRR@1/4/6, DCG@1/4/6. Результат сведен в таблицу.

# Таблица результатов для разных моделей и реранкеров

| Базовая модель | Реранкер | Recall@1 | Recall@4 | Recall@6 | Precision@1 | Precision@4 | Precision@6 | MRR@1 | MRR@4 | MRR@6 | DCG@1 | DCG@4 | DCG@6 |
|---------------|----------|----------|----------|----------|-------------|-------------|-------------|-------|-------|-------|-------|-------|-------|
| SentenceTransformer('intfloat/multilingual-e5-base') | - | 0.56 | 0.79 | 0.83 | 0.56 | 0.20 | 0.14 | 0.56 | 0.65 | 0.66 | 0.56 | 0.68 | 0.70 |
| | cross-encoder/ms-marco-MiniLM-L-12-v2 | 0.70 | 0.87 | 0.89 | 0.70 | 0.22 | 0.15 | 0.70 | 0.77 | 0.78 | 0.70 | 0.80 | 0.80 |
| | BAAI/bge-reranker-base | 0.71 | 0.87 | 0.89 | 0.71 | 0.22 | 0.15 | 0.71 | 0.77 | 0.78 | 0.71 | 0.80 | 0.80 |
| | nboost/pt-tinybert-msmarco | 0.00 | 0.02 | 0.03 | 0.00 | 0.01 | 0.01 | 0.00 | 0.01 | 0.01 | 0.00 | 0.01 | 0.01 |
| | sentence-transformers/msmarco-distilbert-base-tas-b | 0.01 | 0.13 | 0.27 | 0.01 | 0.03 | 0.04 | 0.01 | 0.05 | 0.08 | 0.01 | 0.07 | 0.12 |
| SentenceTransformer('BAAI/bge-base-en-v1.5') | - | 0.64 | 0.88 | 0.9 | 0.64 | 0.22 | 0.15 | 0.64 | 0.74 | 0.75 | 0.64 | 0.78 | 0.79 |
| | cross-encoder/ms-marco-MiniLM-L-12-v2 | 0.71 | 0.88 | 0.90 | 0.71 | 0.22 | 0.15 | 0.71 | 0.78 | 0.78 | 0.71 | 0.80 | 0.81 |
| | BAAI/bge-reranker-base | 0.70 | 0.87 | 0.89 | 0.70 | 0.22 | 0.15 | 0.70 | 0.77 | 0.77 | 0.70 | 0.80 | 0.80 |
| | nboost/pt-tinybert-msmarco | 0.01 | 0.02 | 0.03 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.02 |
| | sentence-transformers/msmarco-distilbert-base-tas-b | 0.04 | 0.19 | 0.30 | 0.04 | 0.05 | 0.05 | 0.04 | 0.0 | 0.11 | 0.04 | 0.12 | 0.15 |
| BM25 | - | 0.58 | 0.83 | 0.86 | 0.58 | 0.21 | 0.14 | 0.58 | 0.69 | 0.69 | 0.58 | 0.72 | 0.74 |
| | cross-encoder/ms-marco-MiniLM-L-12-v2 | 0.68 | 0.85 | 0.88 | 0.68 | 0.21 | 0.15 | 0.68 | 0.75 | 0.76 | 0.68 | 0.78 | 0.79 |
| | BAAI/bge-reranker-base | 0.71 | 0.85 | 0.89 | 0.71 | 0.21 | 0.15 | 0.71 | 0.76 | 0.77 | 0.71 | 0.79 | 0.80 |
| | nboost/pt-tinybert-msmarco | 0.01 | 0.02 | 0.03 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 |
| | sentence-transformers/msmarco-distilbert-base-tas-b | 0.04 | 0.20 | 0.30 | 0.04 | 0.05 | 0.05 | 0.04 | 0.11 | 0.12 | 0.04 | 0.12 | 0.16 |

Пара, показавшая себя лучше всего - SentenceTransformer('BAAI/bge-base-en-v1.5') + Реранкер cross-encoder/ms-marco-MiniLM-L-12-v2.
