{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлен пайплайн с использованием BM25 вместо эмбеддингов для поиска релевантных документов, а также код для оценки его эффективности с использованием тех же метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончания -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "class DocumentationQA_BM25:\n",
    "    def __init__(self):\n",
    "        self.bm25 = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.tokenized_corpus = []\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "        # Использование переменных из глобального контекста\n",
    "        self.stop_words = stop_words\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Предобработка текста: токенизация, удаление стоп-слов и стемминг\"\"\"\n",
    "        # Токенизация и приведение к нижнему регистру\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        # Удаление пунктуации и цифр\n",
    "        tokens = [token for token in tokens if token not in string.punctuation and not token.isdigit()]\n",
    "        # Удаление стоп-слов\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        # Стемминг\n",
    "        try:\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка стемминга: {e}. Пропускаем этап стемминга.\")\n",
    "        return tokens\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        \n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        \n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "        \n",
    "        # Токенизация и предобработка текстовых фрагментов для BM25\n",
    "        print(\"Начинаем токенизацию и предобработку текста...\")\n",
    "        self.tokenized_corpus = [self.preprocess_text(doc['text']) for doc in self.doc_paragraphs]\n",
    "        \n",
    "        # Проверка на пустые токенизированные документы\n",
    "        non_empty_docs = [(i, doc) for i, doc in enumerate(self.tokenized_corpus) if doc]\n",
    "        if len(non_empty_docs) < len(self.tokenized_corpus):\n",
    "            print(f\"Внимание: {len(self.tokenized_corpus) - len(non_empty_docs)} документов не содержат токенов после предобработки.\")\n",
    "            \n",
    "            # Отфильтровываем пустые документы\n",
    "            valid_indices = [i for i, _ in non_empty_docs]\n",
    "            self.tokenized_corpus = [self.tokenized_corpus[i] for i in valid_indices]\n",
    "            self.doc_paragraphs = [self.doc_paragraphs[i] for i in valid_indices]\n",
    "        \n",
    "        # Инициализация BM25\n",
    "        print(\"Инициализация BM25...\")\n",
    "        try:\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            print(f\"BM25 успешно инициализирован. Всего документов: {len(self.tokenized_corpus)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации BM25: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs(self, user_query, top_k=3):\n",
    "        \"\"\"Поиск похожих параграфов с использованием BM25\"\"\"\n",
    "        if not self.bm25:\n",
    "            print(\"Ошибка: BM25 не инициализирован!\")\n",
    "            return []\n",
    "            \n",
    "        # Предобработка запроса\n",
    "        tokenized_query = self.preprocess_text(user_query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            print(\"Предупреждение: запрос не содержит значимых токенов после предобработки!\")\n",
    "            return []\n",
    "        \n",
    "        # Получение BM25 scores для всех документов\n",
    "        try:\n",
    "            scores = self.bm25.get_scores(tokenized_query)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении оценок BM25: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Индексы документов с наивысшими оценками\n",
    "        top_n = np.argsort(scores)[::-1][:top_k]\n",
    "        \n",
    "        # Возвращение текста, имени документа и оценки BM25\n",
    "        results = []\n",
    "        for i in top_n:\n",
    "            if scores[i] > 0:  # Добавление только если оценка больше 0\n",
    "                results.append((self.doc_paragraphs[i]['text'], self.doc_paragraphs[i]['name'], float(scores[i])))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ,            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_bm25(qa_system, question, top_k=6):\n",
    "    \"\"\"Получение релевантных фрагментов с использованием BM25\"\"\"\n",
    "    fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "    return fragments\n",
    "\n",
    "def calculate_metrics(retrieval_results):\n",
    "    \"\"\"Вычисление метрик эффективности ретривала\"\"\"\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:min(6, len(retrieved_fragments))] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / min(4, len(retrieved_fragments)))\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / min(6, len(retrieved_fragments)))\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(4, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(6, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k4 = min(4, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k4 документа\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:k4]])\n",
    "            predicted_order_relevance_4 = np.array([f[3] for f in retrieved_fragments[:k4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_order_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k6 = min(6, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k6 документов\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:k6]])\n",
    "            predicted_order_relevance_6 = np.array([f[3] for f in retrieved_fragments[:k6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_order_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Основной код для тестирования системы и вычисления метрик\n",
    "\n",
    "def run_evaluation(api_key, test_questions):\n",
    "    \"\"\"Запуск оценки BM25 системы на наборе тестовых вопросов\"\"\"\n",
    "    # Инициализация системы BM25\n",
    "    qa_system = DocumentationQA_BM25()\n",
    "    qa_system.initialize_database()\n",
    "    \n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "    \n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        \n",
    "        # Получение фрагментов с помощью BM25\n",
    "        fragments = get_relevant_fragments_bm25(qa_system, question, top_k=6)\n",
    "        \n",
    "        # Результаты для текущего вопроса\n",
    "        result = {'question': question, 'fragments': []}\n",
    "        \n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, score in fragments:\n",
    "            # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, score, relevance_score))\n",
    "        \n",
    "        retrieval_results.append(result)\n",
    "    \n",
    "    # Вычисление метрик\n",
    "    metrics_results = calculate_metrics(retrieval_results)\n",
    "    \n",
    "    return metrics_results, retrieval_results\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "        \n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "        \n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "        \n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки BM25 ретривала...\")\n",
    "        metrics, results = run_evaluation(api_key, test_questions)\n",
    "        \n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки BM25-ретривала:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            \n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "                \n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "            \n",
    "            # Сортировка по BM25\n",
    "            sorted_by_bm25 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по BM25:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_bm25[:min(3, len(sorted_by_bm25))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "        \n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"bm25_retrieval_results.csv\")\n",
    "        \n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, bm25_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'bm25_score': bm25_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "api_key_file = 'api.txt'\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего загружено 292 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Внимание: 16 документов не содержат токенов после предобработки.\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 276\n"
     ]
    }
   ],
   "source": [
    "metrics, res = run_evaluation(api_key = api_key, test_questions = questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.37041666666666656,\n",
       " 'recall@4': 0.8120833333333334,\n",
       " 'recall@6': 1.0,\n",
       " 'precision@1': 0.6666666666666666,\n",
       " 'precision@4': 0.4791666666666667,\n",
       " 'precision@6': 0.4208333333333332,\n",
       " 'mrr@4': 0.7659722222222222,\n",
       " 'mrr@6': 0.7726388888888889,\n",
       " 'ndcg@4': np.float64(0.9662130678581775),\n",
       " 'ndcg@6': np.float64(0.9384500595773312)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлена реализация с базовой моделью SentenceTransformer('BAAI/bge-large-en-v1.5') и различными реранкерами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели E5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60406cba7a9e4efea4f3004c2eff9786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e381c14d89b4eba9ce54cdeb84c89ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44466054b1204512a3799442ab0d39ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f6c273fba1495f9ce1922e2af518d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed493f0c10974acaad5a0971aef8277d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c3d52cb3ad46b08487cfd1d0e9329c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d99335d3d7485bae181c14f40c4f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fe30884fa14d40a3116f506725ee93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38b182f44e243f0b4f200341c6756cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a241313fd1e47c5b63706808fba0fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae19f481080c4affbf48abd84380ec62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель E5 успешно загружена\n",
      "Всего загружено 292 фрагментов.\n",
      "Генерация эмбеддингов для документов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffa4d94a5de47ecb2f7f590b762dbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги успешно созданы. Размерность: (292, 1024)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончения -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "class DocumentationQA_E5Embeddings:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.doc_embeddings = None\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        print(\"Загрузка модели...\")\n",
    "        try:\n",
    "            self.model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "            print(\"Модель успешно загружена\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке модели: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        \n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        \n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "        \n",
    "        # Создание эмбеддингов для всех документов\n",
    "        print(\"Генерация эмбеддингов для документов...\")\n",
    "        try:\n",
    "            # Формируем тексты документов с инструкцией для E5\n",
    "            doc_texts = [f\"passage: {doc['text']}\" for doc in self.doc_paragraphs]\n",
    "            \n",
    "            # Преобразуем тексты в эмбеддинги\n",
    "            self.doc_embeddings = self.model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "            print(f\"Эмбеддинги успешно созданы. Размерность: {self.doc_embeddings.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при создании эмбеддингов: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs(self, user_query, top_k=3):\n",
    "        \"\"\"Поиск похожих параграфов с использованием эмбеддингов E5\"\"\"\n",
    "        if self.doc_embeddings is None or not self.model:\n",
    "            print(\"Ошибка: База данных не инициализирована!\")\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            # Формируем запрос с инструкцией для E5\n",
    "            query_text = f\"query: {user_query}\"\n",
    "            \n",
    "            # Получаем эмбеддинг запроса\n",
    "            query_embedding = self.model.encode([query_text], convert_to_numpy=True)[0]\n",
    "            \n",
    "            # Вычисляем косинусное сходство между запросом и всеми документами\n",
    "            similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "            \n",
    "            # Находим индексы с наибольшим сходством\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "            \n",
    "            # Возвращаем результаты с указанием текста, имени и оценки сходства\n",
    "            results = []\n",
    "            for idx in top_indices:\n",
    "                if similarities[idx] > 0:  # Добавляем только позитивные сходства\n",
    "                    results.append((self.doc_paragraphs[idx]['text'], \n",
    "                                   self.doc_paragraphs[idx]['name'], \n",
    "                                   float(similarities[idx])))\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при поиске похожих параграфов: {e}\")\n",
    "            return []\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_e5(qa_system, question, top_k=6):\n",
    "    \"\"\"Получение релевантных фрагментов с использованием E5 эмбеддингов\"\"\"\n",
    "    fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "    return fragments\n",
    "\n",
    "def calculate_metrics(retrieval_results):\n",
    "    \"\"\"Вычисление метрик эффективности ретривала\"\"\"\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:min(6, len(retrieved_fragments))] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / min(4, len(retrieved_fragments)))\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / min(6, len(retrieved_fragments)))\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(4, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(6, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k4 = min(4, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k4 документа\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:k4]])\n",
    "            predicted_order_relevance_4 = np.array([f[3] for f in retrieved_fragments[:k4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_order_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k6 = min(6, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k6 документов\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:k6]])\n",
    "            predicted_order_relevance_6 = np.array([f[3] for f in retrieved_fragments[:k6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_order_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Основной код для тестирования системы и вычисления метрик\n",
    "\n",
    "def run_evaluation(api_key, test_questions):\n",
    "    \"\"\"Запуск оценки системы ретривала на основе E5 на наборе тестовых вопросов\"\"\"\n",
    "    # Инициализация системы на основе E5\n",
    "    qa_system = DocumentationQA_E5Embeddings()\n",
    "    qa_system.initialize_database()\n",
    "    \n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "    \n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        \n",
    "        # Получение фрагментов с помощью E5\n",
    "        fragments = get_relevant_fragments_e5(qa_system, question, top_k=6)\n",
    "        \n",
    "        # Результаты для текущего вопроса\n",
    "        result = {'question': question, 'fragments': []}\n",
    "        \n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, score in fragments:\n",
    "            # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, score, relevance_score))\n",
    "        \n",
    "        retrieval_results.append(result)\n",
    "    \n",
    "    # Вычисление метрик\n",
    "    metrics_results = calculate_metrics(retrieval_results)\n",
    "    \n",
    "    return metrics_results, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, e5_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'e5_score': e5_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "        \n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "        \n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "        \n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки E5 ретривала...\")\n",
    "        metrics, results = run_evaluation(api_key, test_questions)\n",
    "        \n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки E5-ретривала:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            \n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "                \n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "            \n",
    "            # Сортировка по E5 сходству\n",
    "            sorted_by_e5 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по E5:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_e5[:min(3, len(sorted_by_e5))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "        \n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"e5_retrieval_results.csv\")\n",
    "        \n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "api_key_file = 'api.txt'\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "metrics, res = run_evaluation(api_key=api_key, test_questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.33069444444444446,\n",
       " 'recall@4': 0.7888888888888885,\n",
       " 'recall@6': 1.0,\n",
       " 'precision@1': 0.7833333333333333,\n",
       " 'precision@4': 0.5916666666666667,\n",
       " 'precision@6': 0.5305555555555554,\n",
       " 'mrr@4': 0.8506944444444445,\n",
       " 'mrr@6': 0.8554166666666667,\n",
       " 'ndcg@4': np.float64(0.9713621177570062),\n",
       " 'ndcg@6': np.float64(0.948999405854192)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель BAAI/bge-large-en-v1.5 с реранкером cross-encoder/ms-marco-MiniLM-L-12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели...\n",
      "Модели успешно загружены\n",
      "Всего загружено 130 фрагментов.\n",
      "Генерация эмбеддингов для документов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b2c214ffef4dd6a9868fd21d8a58d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги успешно созданы. Размерность: (130, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.5195833333333334,\n",
       " 'recall@4': 0.8645833333333334,\n",
       " 'recall@6': 1.0,\n",
       " 'precision@1': 0.7166666666666667,\n",
       " 'precision@4': 0.4395833333333333,\n",
       " 'precision@6': 0.37361111111111095,\n",
       " 'mrr@4': 0.7784722222222221,\n",
       " 'mrr@6': 0.7801388888888889,\n",
       " 'ndcg@4': np.float64(0.9745421620607291),\n",
       " 'ndcg@6': np.float64(0.9590797106850054)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончения -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "class DocumentationQA_E5Embeddings:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.reranker = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.doc_embeddings = None\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        print(\"Загрузка модели...\")\n",
    "        try:\n",
    "            self.model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "            self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "            print(\"Модели успешно загружены\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке модели: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "\n",
    "        # Создание эмбеддингов для всех документов\n",
    "        print(\"Генерация эмбеддингов для документов...\")\n",
    "        try:\n",
    "            doc_texts = [f\"passage: {doc['text']}\" for doc in self.doc_paragraphs]\n",
    "            self.doc_embeddings = self.model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "            print(f\"Эмбеддинги успешно созданы. Размерность: {self.doc_embeddings.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при создании эмбеддингов: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs_with_reranking(self, user_query, top_k_initial=20, top_k_final=6):\n",
    "        \"\"\"Поиск похожих параграфов с использованием эмбеддингов E5 и реранкинга\"\"\"\n",
    "        if self.doc_embeddings is None or not self.model:\n",
    "            print(\"Ошибка: База данных не инициализирована!\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            # Формируем запрос с инструкцией для E5\n",
    "            query_text = f\"query: {user_query}\"\n",
    "            query_embedding = self.model.encode([query_text], convert_to_numpy=True)[0]\n",
    "\n",
    "            # Вычисляем косинусное сходство между запросом и всеми документами\n",
    "            similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k_initial]\n",
    "\n",
    "            # Получаем топ-20 фрагментов\n",
    "            initial_results = [(self.doc_paragraphs[idx]['text'], self.doc_paragraphs[idx]['name'], float(similarities[idx]))\n",
    "                               for idx in top_indices]\n",
    "\n",
    "            # Подготовка данных для реранкера\n",
    "            rerank_input = [[user_query, text] for text, _, _ in initial_results]\n",
    "            rerank_scores = self.reranker.predict(rerank_input)\n",
    "\n",
    "            # Комбинируем результаты и сортируем по оценкам реранкера\n",
    "            combined_results = [(text, name, score) for (text, name, _), score in zip(initial_results, rerank_scores)]\n",
    "            sorted_results = sorted(combined_results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Возвращаем топ-k фрагментов после реранкинга\n",
    "            return sorted_results[:top_k_final]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при поиске похожих параграфов: {e}\")\n",
    "            return []\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6):\n",
    "    \"\"\"Получение релевантных фрагментов с использованием E5 эмбеддингов и реранкера\"\"\"\n",
    "    fragments = qa_system.search_similar_paragraphs_with_reranking(question, top_k_initial=top_k_initial, top_k_final=top_k_final)\n",
    "    return fragments\n",
    "\n",
    "def calculate_metrics(retrieval_results):\n",
    "    \"\"\"Вычисление метрик эффективности ретривала\"\"\"\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:min(6, len(retrieved_fragments))] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / min(4, len(retrieved_fragments)))\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / min(6, len(retrieved_fragments)))\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(4, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(6, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k4 = min(4, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k4 документа\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:k4]])\n",
    "            predicted_order_relevance_4 = np.array([f[3] for f in retrieved_fragments[:k4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_order_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k6 = min(6, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k6 документов\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:k6]])\n",
    "            predicted_order_relevance_6 = np.array([f[3] for f in retrieved_fragments[:k6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_order_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Основной код для тестирования системы и вычисления метрик\n",
    "\n",
    "def run_evaluation_with_reranking(api_key, test_questions):\n",
    "    \"\"\"Запуск оценки системы ретривала на основе E5 и реранкера на наборе тестовых вопросов\"\"\"\n",
    "    # Инициализация системы на основе E5\n",
    "    qa_system = DocumentationQA_E5Embeddings()\n",
    "    qa_system.initialize_database()\n",
    "\n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "\n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        # Получение фрагментов с помощью E5 и реранкера\n",
    "        fragments = get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6)\n",
    "        result = {'question': question, 'fragments': []}\n",
    "\n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, score in fragments:\n",
    "            time.sleep(2)  # Задержка между запросами\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, score, relevance_score))\n",
    "        retrieval_results.append(result)\n",
    "\n",
    "    # Вычисление метрик\n",
    "    metrics_results = calculate_metrics(retrieval_results)\n",
    "    return metrics_results, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, e5_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'e5_score': e5_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "\n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "\n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "\n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки E5 ретривала с реранкером...\")\n",
    "        metrics, results = run_evaluation_with_reranking(api_key, test_questions)\n",
    "\n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки E5-ретривала с реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "\n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "            # Сортировка по E5 сходству\n",
    "            sorted_by_e5 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по E5:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_e5[:min(3, len(sorted_by_e5))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"e5_reranker_retrieval_results.csv\")\n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "api_key_file = 'api.txt'\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "metrics, res = run_evaluation_with_reranking(api_key=api_key, test_questions=questions)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реранкер BAAI/bge-reranker-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей...\n",
      "Модели успешно загружены\n",
      "Всего загружено 130 фрагментов.\n",
      "Генерация эмбеддингов для документов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0cf07267ff444a8225340351d03a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги успешно созданы. Размерность: (130, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.4730555555555557,\n",
       " 'recall@4': 0.8708333333333333,\n",
       " 'recall@6': 1.0,\n",
       " 'precision@1': 0.7333333333333333,\n",
       " 'precision@4': 0.4625,\n",
       " 'precision@6': 0.38333333333333336,\n",
       " 'mrr@4': 0.8,\n",
       " 'mrr@6': 0.8016666666666666,\n",
       " 'ndcg@4': np.float64(0.9712515695237147),\n",
       " 'ndcg@6': np.float64(0.9554671891932263)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончения -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "class DocumentationQA_E5Embeddings:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.reranker = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.doc_embeddings = None\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        print(\"Загрузка моделей...\")\n",
    "        try:\n",
    "            self.model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "            self.reranker = CrossEncoder('BAAI/bge-reranker-base')\n",
    "            print(\"Модели успешно загружены\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке моделей: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "\n",
    "        # Создание эмбеддингов для всех документов\n",
    "        print(\"Генерация эмбеддингов для документов...\")\n",
    "        try:\n",
    "            doc_texts = [f\"passage: {doc['text']}\" for doc in self.doc_paragraphs]\n",
    "            self.doc_embeddings = self.model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "            print(f\"Эмбеддинги успешно созданы. Размерность: {self.doc_embeddings.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при создании эмбеддингов: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs_with_reranking(self, user_query, top_k_initial=20, top_k_final=6):\n",
    "        \"\"\"Поиск похожих параграфов с использованием эмбеддингов E5 и реранкера BAAI/bge-reranker-base\"\"\"\n",
    "        if self.doc_embeddings is None or not self.model:\n",
    "            print(\"Ошибка: База данных не инициализирована!\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            # Формируем запрос с инструкцией для E5\n",
    "            query_text = f\"query: {user_query}\"\n",
    "            query_embedding = self.model.encode([query_text], convert_to_numpy=True)[0]\n",
    "\n",
    "            # Вычисляем косинусное сходство между запросом и всеми документами\n",
    "            similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k_initial]\n",
    "\n",
    "            # Получаем топ-20 фрагментов\n",
    "            initial_results = [(self.doc_paragraphs[idx]['text'], self.doc_paragraphs[idx]['name'], float(similarities[idx]))\n",
    "                               for idx in top_indices]\n",
    "\n",
    "            # Подготовка данных для реранкера\n",
    "            rerank_input = [[user_query, text] for text, _, _ in initial_results]\n",
    "            rerank_scores = self.reranker.predict(rerank_input)\n",
    "\n",
    "            # Комбинируем результаты и сортируем по оценкам реранкера\n",
    "            combined_results = [(text, name, score) for (text, name, _), score in zip(initial_results, rerank_scores)]\n",
    "            sorted_results = sorted(combined_results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Возвращаем топ-k фрагментов после реранкинга\n",
    "            return sorted_results[:top_k_final]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при поиске похожих параграфов: {e}\")\n",
    "            return []\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6):\n",
    "    \"\"\"Получение релевантных фрагментов с использованием E5 эмбеддингов и реранкера\"\"\"\n",
    "    fragments = qa_system.search_similar_paragraphs_with_reranking(question, top_k_initial=top_k_initial, top_k_final=top_k_final)\n",
    "    return fragments\n",
    "\n",
    "def calculate_metrics(retrieval_results):\n",
    "    \"\"\"Вычисление метрик эффективности ретривала\"\"\"\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:min(6, len(retrieved_fragments))] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / min(4, len(retrieved_fragments)))\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / min(6, len(retrieved_fragments)))\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(4, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(6, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k4 = min(4, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k4 документа\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:k4]])\n",
    "            predicted_order_relevance_4 = np.array([f[3] for f in retrieved_fragments[:k4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_order_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k6 = min(6, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k6 документов\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:k6]])\n",
    "            predicted_order_relevance_6 = np.array([f[3] for f in retrieved_fragments[:k6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_order_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Основной код для тестирования системы и вычисления метрик\n",
    "\n",
    "def run_evaluation_with_reranking(api_key, test_questions):\n",
    "    \"\"\"Запуск оценки системы ретривала на основе E5 и реранкера на наборе тестовых вопросов\"\"\"\n",
    "    # Инициализация системы на основе E5\n",
    "    qa_system = DocumentationQA_E5Embeddings()\n",
    "    qa_system.initialize_database()\n",
    "\n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "\n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        # Получение фрагментов с помощью E5 и реранкера\n",
    "        fragments = get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6)\n",
    "        result = {'question': question, 'fragments': []}\n",
    "\n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, score in fragments:\n",
    "            time.sleep(2)  # Задержка между запросами\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, score, relevance_score))\n",
    "        retrieval_results.append(result)\n",
    "\n",
    "    # Вычисление метрик\n",
    "    metrics_results = calculate_metrics(retrieval_results)\n",
    "    return metrics_results, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, e5_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'e5_score': e5_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "\n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "\n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "\n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки E5 ретривала с реранкером BAAI/bge-reranker-base...\")\n",
    "        metrics, results = run_evaluation_with_reranking(api_key, test_questions)\n",
    "\n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки E5-ретривала с реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "\n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "            # Сортировка по E5 сходству\n",
    "            sorted_by_e5 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по E5:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_e5[:min(3, len(sorted_by_e5))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"e5_bge_reranker_retrieval_results.csv\")\n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "api_key_file = 'api.txt'\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "metrics, res = run_evaluation_with_reranking(api_key=api_key, test_questions=questions)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реарнкер nboost/pt-tinybert-msmarco, модель та же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей...\n",
      "Модели успешно загружены\n",
      "Всего загружено 130 фрагментов.\n",
      "Генерация эмбеддингов для документов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347098f23b1b423fbee00f167dea5c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги успешно созданы. Размерность: (130, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.44041666666666673,\n",
       " 'recall@4': 0.8283333333333333,\n",
       " 'recall@6': 1.0,\n",
       " 'precision@1': 0.5083333333333333,\n",
       " 'precision@4': 0.33541666666666664,\n",
       " 'precision@6': 0.30277777777777787,\n",
       " 'mrr@4': 0.6291666666666667,\n",
       " 'mrr@6': 0.6369444444444444,\n",
       " 'ndcg@4': np.float64(0.9480241434393737),\n",
       " 'ndcg@6': np.float64(0.9257728989466522)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончения -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "class DocumentationQA_E5Embeddings:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.reranker_tokenizer = None\n",
    "        self.reranker_model = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.doc_embeddings = None\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        print(\"Загрузка моделей...\")\n",
    "        try:\n",
    "            # Загрузка модели SentenceTransformer для начального поиска\n",
    "            self.model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "            \n",
    "            # Загрузка модели nboost/pt-tinybert-msmarco для реранкинга\n",
    "            self.reranker_tokenizer = AutoTokenizer.from_pretrained('nboost/pt-tinybert-msmarco')\n",
    "            self.reranker_model = AutoModelForSequenceClassification.from_pretrained('nboost/pt-tinybert-msmarco')\n",
    "            self.reranker_model.eval()  # Переводим модель в режим оценки\n",
    "            \n",
    "            print(\"Модели успешно загружены\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке моделей: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "\n",
    "        # Создание эмбеддингов для всех документов\n",
    "        print(\"Генерация эмбеддингов для документов...\")\n",
    "        try:\n",
    "            doc_texts = [f\"passage: {doc['text']}\" for doc in self.doc_paragraphs]\n",
    "            self.doc_embeddings = self.model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "            print(f\"Эмбеддинги успешно созданы. Размерность: {self.doc_embeddings.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при создании эмбеддингов: {e}\")\n",
    "            raise\n",
    "\n",
    "    def rerank_with_nboost(self, query, passages):\n",
    "        \"\"\"Реранкинг с использованием модели nboost/pt-tinybert-msmarco\"\"\"\n",
    "        inputs = self.reranker_tokenizer(\n",
    "            [query] * len(passages),\n",
    "            passages,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.reranker_model(**inputs)\n",
    "        scores = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()  # Вероятности релевантности\n",
    "        return scores\n",
    "\n",
    "    def search_similar_paragraphs_with_reranking(self, user_query, top_k_initial=20, top_k_final=6):\n",
    "        \"\"\"Поиск похожих параграфов с использованием эмбеддингов E5 и реранкера nboost/pt-tinybert-msmarco\"\"\"\n",
    "        if self.doc_embeddings is None or not self.model:\n",
    "            print(\"Ошибка: База данных не инициализирована!\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            # Формируем запрос с инструкцией для E5\n",
    "            query_text = f\"query: {user_query}\"\n",
    "            query_embedding = self.model.encode([query_text], convert_to_numpy=True)[0]\n",
    "\n",
    "            # Вычисляем косинусное сходство между запросом и всеми документами\n",
    "            similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k_initial]\n",
    "\n",
    "            # Получаем топ-20 фрагментов\n",
    "            initial_results = [(self.doc_paragraphs[idx]['text'], self.doc_paragraphs[idx]['name'], float(similarities[idx]))\n",
    "                               for idx in top_indices]\n",
    "\n",
    "            # Подготовка данных для реранкера\n",
    "            passages = [text for text, _, _ in initial_results]\n",
    "            rerank_scores = self.rerank_with_nboost(user_query, passages)\n",
    "\n",
    "            # Комбинируем результаты и сортируем по оценкам реранкера\n",
    "            combined_results = [(text, name, score) for (text, name, _), score in zip(initial_results, rerank_scores)]\n",
    "            sorted_results = sorted(combined_results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Возвращаем топ-k фрагментов после реранкинга\n",
    "            return sorted_results[:top_k_final]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при поиске похожих параграфов: {e}\")\n",
    "            return []\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_e5(qa_system, question, top_k=6):\n",
    "    \"\"\"Получение релевантных фрагментов с использованием E5 эмбеддингов\"\"\"\n",
    "    fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "    return fragments\n",
    "\n",
    "def calculate_metrics(retrieval_results):\n",
    "    \"\"\"Вычисление метрик эффективности ретривала\"\"\"\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:min(6, len(retrieved_fragments))] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / min(4, len(retrieved_fragments)))\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / min(6, len(retrieved_fragments)))\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(4, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(6, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k4 = min(4, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k4 документа\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:k4]])\n",
    "            predicted_order_relevance_4 = np.array([f[3] for f in retrieved_fragments[:k4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_order_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k6 = min(6, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k6 документов\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:k6]])\n",
    "            predicted_order_relevance_6 = np.array([f[3] for f in retrieved_fragments[:k6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_order_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Основной код для тестирования системы и вычисления метрик\n",
    "\n",
    "def run_evaluation_with_reranking(api_key, test_questions):\n",
    "    \"\"\"Запуск оценки системы ретривала на основе E5 и реранкера на наборе тестовых вопросов\"\"\"\n",
    "    # Инициализация системы на основе E5\n",
    "    qa_system = DocumentationQA_E5Embeddings()\n",
    "    qa_system.initialize_database()\n",
    "\n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "\n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        # Получение фрагментов с помощью E5 и реранкера\n",
    "        fragments = get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6)\n",
    "        result = {'question': question, 'fragments': []}\n",
    "\n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, score in fragments:\n",
    "            time.sleep(2)  # Задержка между запросами\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, score, relevance_score))\n",
    "        retrieval_results.append(result)\n",
    "\n",
    "    # Вычисление метрик\n",
    "    metrics_results = calculate_metrics(retrieval_results)\n",
    "    return metrics_results, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, e5_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'e5_score': e5_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "\n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "\n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "\n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки E5 ретривала с реранкером BAAI/bge-reranker-base...\")\n",
    "        metrics, results = run_evaluation_with_reranking(api_key, test_questions)\n",
    "\n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки E5-ретривала с реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "\n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "            # Сортировка по E5 сходству\n",
    "            sorted_by_e5 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по E5:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_e5[:min(3, len(sorted_by_e5))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"e5_bge_reranker_retrieval_results.csv\")\n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "api_key_file = 'api.txt'\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "metrics, res = run_evaluation_with_reranking(api_key=api_key, test_questions=questions)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реранкер sentence-transformers/msmarco-distilbert-base-tas-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-tas-b and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели успешно загружены\n",
      "Всего загружено 130 фрагментов.\n",
      "Генерация эмбеддингов для документов...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aafda0665c4165be4df4aae87fadfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги успешно созданы. Размерность: (130, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall@1': 0.46,\n",
       " 'recall@4': 0.7545833333333332,\n",
       " 'recall@6': 1.0,\n",
       " 'precision@1': 0.21666666666666667,\n",
       " 'precision@4': 0.18125,\n",
       " 'precision@6': 0.19166666666666668,\n",
       " 'mrr@4': 0.32152777777777775,\n",
       " 'mrr@6': 0.34958333333333336,\n",
       " 'ndcg@4': np.float64(0.9351913913241777),\n",
       " 'ndcg@6': np.float64(0.8959125339131639)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончения -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "class DocumentationQA_E5Embeddings:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.reranker = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.doc_embeddings = None\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        print(\"Загрузка моделей...\")\n",
    "        try:\n",
    "            # Загрузка модели SentenceTransformer для начального поиска\n",
    "            self.model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "            \n",
    "            # Загрузка модели msmarco-distilbert-base-tas-b для реранкинга\n",
    "            self.reranker = CrossEncoder('sentence-transformers/msmarco-distilbert-base-tas-b')\n",
    "            print(\"Модели успешно загружены\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке моделей: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "\n",
    "        # Создание эмбеддингов для всех документов\n",
    "        print(\"Генерация эмбеддингов для документов...\")\n",
    "        try:\n",
    "            doc_texts = [f\"passage: {doc['text']}\" for doc in self.doc_paragraphs]\n",
    "            self.doc_embeddings = self.model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "            print(f\"Эмбеддинги успешно созданы. Размерность: {self.doc_embeddings.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при создании эмбеддингов: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs_with_reranking(self, user_query, top_k_initial=20, top_k_final=6):\n",
    "        \"\"\"Поиск похожих параграфов с использованием эмбеддингов E5 и реранкера msmarco-distilbert-base-tas-b\"\"\"\n",
    "        if self.doc_embeddings is None or not self.model:\n",
    "            print(\"Ошибка: База данных не инициализирована!\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            # Формируем запрос с инструкцией для E5\n",
    "            query_text = f\"query: {user_query}\"\n",
    "            query_embedding = self.model.encode([query_text], convert_to_numpy=True)[0]\n",
    "\n",
    "            # Вычисляем косинусное сходство между запросом и всеми документами\n",
    "            similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k_initial]\n",
    "\n",
    "            # Получаем топ-20 фрагментов\n",
    "            initial_results = [(self.doc_paragraphs[idx]['text'], self.doc_paragraphs[idx]['name'], float(similarities[idx]))\n",
    "                               for idx in top_indices]\n",
    "\n",
    "            # Подготовка данных для реранкера\n",
    "            rerank_input = [[user_query, text] for text, _, _ in initial_results]\n",
    "            rerank_scores = self.reranker.predict(rerank_input)\n",
    "\n",
    "            # Комбинируем результаты и сортируем по оценкам реранкера\n",
    "            combined_results = [(text, name, score) for (text, name, _), score in zip(initial_results, rerank_scores)]\n",
    "            sorted_results = sorted(combined_results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "            # Возвращаем топ-k фрагментов после реранкинга\n",
    "            return sorted_results[:top_k_final]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при поиске похожих параграфов: {e}\")\n",
    "            return []\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6):\n",
    "    \"\"\"Получение релевантных фрагментов с использованием E5 эмбеддингов и реранкера\"\"\"\n",
    "    fragments = qa_system.search_similar_paragraphs_with_reranking(question, top_k_initial=top_k_initial, top_k_final=top_k_final)\n",
    "    return fragments\n",
    "\n",
    "def calculate_metrics(retrieval_results):\n",
    "    \"\"\"Вычисление метрик эффективности ретривала\"\"\"\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:min(6, len(retrieved_fragments))] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / min(4, len(retrieved_fragments)))\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / min(6, len(retrieved_fragments)))\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(4, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(6, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k4 = min(4, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k4 документа\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:k4]])\n",
    "            predicted_order_relevance_4 = np.array([f[3] for f in retrieved_fragments[:k4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_order_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "            # Определяем количество документов для оценки\n",
    "            k6 = min(6, len(sorted_fragments), len(retrieved_fragments))\n",
    "            \n",
    "            # Берем только первые k6 документов\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:k6]])\n",
    "            predicted_order_relevance_6 = np.array([f[3] for f in retrieved_fragments[:k6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_order_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Основной код для тестирования системы и вычисления метрик\n",
    "\n",
    "def run_evaluation_with_reranking(api_key, test_questions):\n",
    "    \"\"\"Запуск оценки системы ретривала на основе E5 и реранкера на наборе тестовых вопросов\"\"\"\n",
    "    # Инициализация системы на основе E5\n",
    "    qa_system = DocumentationQA_E5Embeddings()\n",
    "    qa_system.initialize_database()\n",
    "\n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "\n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        # Получение фрагментов с помощью E5 и реранкера\n",
    "        fragments = get_relevant_fragments_e5_with_reranking(qa_system, question, top_k_initial=20, top_k_final=6)\n",
    "        result = {'question': question, 'fragments': []}\n",
    "\n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, score in fragments:\n",
    "            time.sleep(2)  # Задержка между запросами\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, score, relevance_score))\n",
    "        retrieval_results.append(result)\n",
    "\n",
    "    # Вычисление метрик\n",
    "    metrics_results = calculate_metrics(retrieval_results)\n",
    "    return metrics_results, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, e5_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'e5_score': e5_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "\n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "\n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "\n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки E5 ретривала с реранкером msmarco-distilbert-base-tas-b...\")\n",
    "        metrics, results = run_evaluation_with_reranking(api_key, test_questions)\n",
    "\n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки E5-ретривала с реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "\n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "            # Сортировка по E5 сходству\n",
    "            sorted_by_e5 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по E5:\")\n",
    "            for i, (text, name, e5_score, relevance) in enumerate(sorted_by_e5[:min(3, len(sorted_by_e5))]):\n",
    "                print(f\"{i+1}. {name} (E5: {e5_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "\n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"e5_msmarco_distilbert_retrieval_results.csv\")\n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "questions = df['question'].tolist()\n",
    "\n",
    "api_key_file = 'api.txt'\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "metrics, res = run_evaluation_with_reranking(api_key=api_key, test_questions=questions)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь те же реранкеры, однако в качестве базовой модели возьмем BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало оценки системы с BM25 и реранкером TinyBERT...\n",
      "Всего загружено 292 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Внимание: 16 документов не содержат токенов после предобработки.\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 276\n",
      "Инициализация TinyBert реранкера...\n",
      "TinyBert реранкер успешно инициализирован (устройство: cpu)\n",
      "\n",
      "Результаты оценки системы:\n",
      "top_4_recall@4: 1.0000\n",
      "top_4_precision@4: 0.4771\n",
      "top_4_mrr@4: 0.7715\n",
      "top_4_ndcg@4: 0.8638\n",
      "top_4_recall@1: 0.4764\n",
      "top_4_precision@1: 0.6917\n",
      "top_6_recall@6: 1.0000\n",
      "top_6_precision@6: 0.4222\n",
      "top_6_mrr@6: 0.7739\n",
      "top_6_ndcg@6: 0.8684\n",
      "top_6_recall@1: 0.3728\n",
      "top_6_precision@1: 0.6833\n",
      "\n",
      "Детальный анализ результатов:\n",
      "\n",
      "Вопрос: What is a collection in the context of Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 2.3204, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. storage (BM25: 2.1274, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. collections (BM25: 2.4173, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 2.4173, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "2. collections (BM25: 2.4120, Релевантность: 3)\n",
      "   Grey collection status Available as of v1.9.0 A collection may have the grey ⚫ status or show \"optim...\n",
      "3. collections (BM25: 2.3204, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What must be true about the dimensionality of vectors within a single collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 19.3769, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 11.0846, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. storage (BM25: 6.7468, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 19.3769, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 11.0846, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. filtering (BM25: 8.1289, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: How does Qdrant support different metrics for comparing vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 10.3251, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 8.9298, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. search (BM25: 5.5140, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 10.3251, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 10.1447, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. vectors (BM25: 8.9298, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Вопрос: When should multiple collections be created instead of just one?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 7.6921, Релевантность: 5)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "2. storage (BM25: 9.6927, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. collections (BM25: 7.9942, Релевантность: 3)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 11.3943, Релевантность: 2)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. storage (BM25: 9.6927, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. collections (BM25: 7.9942, Релевантность: 3)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "\n",
      "Вопрос: What are some parameters that can be tuned for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 4.3279, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. collections (BM25: 5.0438, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. collections (BM25: 9.9338, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 9.9338, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. collections (BM25: 5.0438, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. search (BM25: 4.7121, Релевантность: 3)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "\n",
      "Вопрос: What happens if different types of vectors are used within a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 9.6020, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. collections (BM25: 10.7464, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. vectors (BM25: 8.4438, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 12.1858, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. collections (BM25: 10.9899, Релевантность: 2)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "3. collections (BM25: 10.7464, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: How can the existence of a collection in Qdrant be checked?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 6.0303, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "2. search (BM25: 3.8579, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "3. payload (BM25: 3.6978, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 6.0303, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "2. snapshots (BM25: 5.3204, Релевантность: 2)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "3. search (BM25: 3.8579, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "\n",
      "Вопрос: What is the purpose of the payload in vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 2.9769, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. storage (BM25: 2.8684, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. search (BM25: 2.9232, Релевантность: 4)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 2.9769, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. search (BM25: 2.9232, Релевантность: 4)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "3. storage (BM25: 2.8684, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: Can collections be updated after their creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 5.0140, Релевантность: 5)\n",
      "   Check collection existence Available as of v1.8.0 http GET http://localhost:6333/collections/{collec...\n",
      "2. storage (BM25: 11.8126, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. collections (BM25: 6.5507, Релевантность: 4)\n",
      "   Grey collection status Available as of v1.9.0 A collection may have the grey ⚫ status or show \"optim...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 11.8126, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 11.7449, Релевантность: 2)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. storage (BM25: 8.8041, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Вопрос: How does the choice of metric influence search results in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 13.2348, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 9.5335, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. indexing (BM25: 6.5513, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 13.2348, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 9.5335, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. indexing (BM25: 7.8866, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What Stack of APIs does Qdrant provide for data exploration?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 23.6349, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. points (BM25: 9.4373, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. explore (BM25: 9.0313, Релевантность: 4)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 23.6349, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. search (BM25: 12.6266, Релевантность: 3)\n",
      "   Random Sampling Available as of v1.11.0 In some cases it might be useful to retrieve a random sample...\n",
      "3. points (BM25: 9.4373, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "\n",
      "Вопрос: How does the Recommendation API enhance the search functionality?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 9.2949, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 6.8743, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "3. explore (BM25: 6.6306, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 13.4568, Релевантность: 3)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "2. explore (BM25: 9.2949, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 7.9667, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What is the default strategy for recommendations in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 11.4131, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 6.4254, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. explore (BM25: 4.0376, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 11.4131, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 6.4254, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. explore (BM25: 4.6377, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the purpose of the 'best_score' strategy introduced in Qdrant v1.6.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 6.5200, Релевантность: 4)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "2. explore (BM25: 5.6468, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "3. explore (BM25: 5.8738, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 6.5200, Релевантность: 4)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "2. explore (BM25: 5.8738, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. explore (BM25: 5.6468, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Вопрос: How can users find the most dissimilar vectors using only negative examples?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 24.3114, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. explore (BM25: 18.8816, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 14.0001, Релевантность: 4)\n",
      "   The way to produce the searching vector is by first averaging all the positive and negative examples...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 24.3114, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. explore (BM25: 18.8816, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 14.0001, Релевантность: 4)\n",
      "   The way to produce the searching vector is by first averaging all the positive and negative examples...\n",
      "\n",
      "Вопрос: What can be specified in the recommendation request when a collection is created with multiple vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 12.9624, Релевантность: 5)\n",
      "   Multiple vectors Available as of v0.10.0 If the collection was created with multiple vectors, the na...\n",
      "2. explore (BM25: 8.7750, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. collections (BM25: 7.6432, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 12.9624, Релевантность: 5)\n",
      "   Multiple vectors Available as of v0.10.0 If the collection was created with multiple vectors, the na...\n",
      "2. collections (BM25: 11.3766, Релевантность: 2)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "3. payload (BM25: 9.7910, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "\n",
      "Вопрос: What is the function of the 'lookup_from' parameter in the recommendation request?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 6.8301, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 7.2313, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. points (BM25: 7.8888, Релевантность: 2)\n",
      "   Awaiting result If the API is called with the &wait=false parameter, or if it is not explicitly spec...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 9.2651, Релевантность: 2)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "2. points (BM25: 7.8888, Релевантность: 2)\n",
      "   Awaiting result If the API is called with the &wait=false parameter, or if it is not explicitly spec...\n",
      "3. explore (BM25: 7.2313, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: How does the Discovery API differ from the Recommendation API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 16.7102, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "2. explore (BM25: 13.2937, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 6.8846, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 16.7102, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "2. explore (BM25: 13.2937, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 9.5293, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What is the significance of using a context in Discovery search?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 13.1547, Релевантность: 5)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "2. search (BM25: 7.4386, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. search (BM25: 3.6897, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 13.1547, Релевантность: 5)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "2. search (BM25: 7.4386, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. hybrid-queries (BM25: 3.9986, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: Can the Distance Matrix API be used for clustering similar vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 23.4369, Релевантность: 5)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. collections (BM25: 9.4487, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. indexing (BM25: 6.8252, Релевантность: 3)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 23.4369, Релевантность: 5)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. collections (BM25: 9.4487, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 7.8614, Релевантность: 3)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What types of conditions can you set when filtering points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.3774, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.2984, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "3. payload (BM25: 7.6866, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.6866, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. filtering (BM25: 7.6691, Релевантность: 4)\n",
      "   To retrieve only the points which are matching the conditions on an array element basis, that is the...\n",
      "3. filtering (BM25: 7.3774, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Вопрос: What logical operations are available when combining filtering conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 11.3240, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.7860, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "3. filtering (BM25: 7.6542, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 11.3240, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. points (BM25: 9.2093, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Count(con...\n",
      "3. filtering (BM25: 7.6542, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: What is the function of the 'must' clause in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.0550, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "2. filtering (BM25: 8.1145, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. filtering (BM25: 5.5609, Релевантность: 5)\n",
      "   Clauses combination It is also possible to use several clauses simultaneously: http POST /collection...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 8.1145, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.0550, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "3. filtering (BM25: 6.0374, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: What does the 'should' clause do in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 5.1670, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "2. filtering (BM25: 5.6822, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "3. filtering (BM25: 6.0550, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 8.1145, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.0550, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "3. filtering (BM25: 6.0374, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: How does the 'must_not' clause work in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 4.3911, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "2. filtering (BM25: 2.3740, Релевантность: 5)\n",
      "   You can apply it to keyword and integer payloads. Example: json { \"key\": \"color\", \"match\": { \"any\": ...\n",
      "3. filtering (BM25: 4.2049, Релевантность: 5)\n",
      "   Clauses combination It is also possible to use several clauses simultaneously: http POST /collection...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.6407, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "2. filtering (BM25: 6.8240, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. filtering (BM25: 4.7029, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: Can you filter using nested fields in Qdrant, and how?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.9473, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "2. filtering (BM25: 9.6520, Релевантность: 5)\n",
      "   To retrieve only the points which are matching the conditions on an array element basis, that is the...\n",
      "3. filtering (BM25: 7.7429, Релевантность: 5)\n",
      "   Example: json { \"key\": \"color\", \"match\": { \"except\": [\"black\", \"yellow\"] } } python models.FieldCond...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 11.7109, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. search (BM25: 10.8556, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. filtering (BM25: 9.6520, Релевантность: 5)\n",
      "   To retrieve only the points which are matching the conditions on an array element basis, that is the...\n",
      "\n",
      "Вопрос: What condition would you use to check if a field has multiple values in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.9524, Релевантность: 5)\n",
      "   Example: json { \"key\": \"color\", \"match\": { \"except\": [\"black\", \"yellow\"] } } python models.FieldCond...\n",
      "2. filtering (BM25: 10.4233, Релевантность: 5)\n",
      "   You can apply it to keyword and integer payloads. Example: json { \"key\": \"color\", \"match\": { \"any\": ...\n",
      "3. payload (BM25: 10.7735, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 10.7735, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. filtering (BM25: 10.4233, Релевантность: 5)\n",
      "   You can apply it to keyword and integer payloads. Example: json { \"key\": \"color\", \"match\": { \"any\": ...\n",
      "3. indexing (BM25: 9.2834, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: How can you check if a field exists with no value in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.8305, Релевантность: 5)\n",
      "   The IsEmpty condition may help you with that: json { \"is_empty\": { \"key\": \"reports\" } } python model...\n",
      "2. storage (BM25: 4.5793, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. payload (BM25: 8.1174, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.1174, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. filtering (BM25: 6.8305, Релевантность: 5)\n",
      "   The IsEmpty condition may help you with that: json { \"is_empty\": { \"key\": \"reports\" } } python model...\n",
      "3. indexing (BM25: 5.6776, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What is the purpose of the 'has_id' condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 2.3351, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 2.3630, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "3. filtering (BM25: 2.3115, Релевантность: 2)\n",
      "   The IsEmpty condition may help you with that: json { \"is_empty\": { \"key\": \"reports\" } } python model...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 2.3630, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "2. filtering (BM25: 2.3351, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. filtering (BM25: 2.3115, Релевантность: 2)\n",
      "   The IsEmpty condition may help you with that: json { \"is_empty\": { \"key\": \"reports\" } } python model...\n",
      "\n",
      "Вопрос: How do you filter records using geographic conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 5.0526, Релевантность: 5)\n",
      "   http POST /collections/{collection_name}/points/scroll { \"filter\": { \"should\": [ { \"key\": \"country.n...\n",
      "2. payload (BM25: 5.3738, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. filtering (BM25: 8.7040, Релевантность: 2)\n",
      "   We have to use IsNull condition instead: json { \"is_null\": { \"key\": \"reports\" } } python models.IsNu...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 8.7040, Релевантность: 2)\n",
      "   We have to use IsNull condition instead: json { \"is_null\": { \"key\": \"reports\" } } python models.IsNu...\n",
      "2. optimizer (BM25: 7.3207, Релевантность: 1)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. payload (BM25: 6.9913, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 3.7932, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 3.4707, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. collections (BM25: 4.0153, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.5432, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. vectors (BM25: 4.4878, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. collections (BM25: 4.0153, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.7094, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 6.1723, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 12.8699, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.8699, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 12.7094, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. hybrid-queries (BM25: 6.1723, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.8466, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 4.8419, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 9.5724, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.8466, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 9.5724, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)...\n",
      "3. snapshots (BM25: 6.8391, Релевантность: 1)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.7675, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 3.6918, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. hybrid-queries (BM25: 8.8012, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 9.7696, Релевантность: 3)\n",
      "   With Qdrant, you can benefit from a more compact and efficient immutable sparse index, which is cons...\n",
      "2. hybrid-queries (BM25: 8.8012, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 7.7675, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.7119, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. indexing (BM25: 5.9524, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. payload (BM25: 11.5897, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 11.5897, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. explore (BM25: 9.3935, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "3. hybrid-queries (BM25: 7.7119, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 4.1432, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. payload (BM25: 8.6688, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "3. storage (BM25: 3.3947, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.6688, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 4.9743, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "3. search (BM25: 4.1865, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 13.1058, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 5.1583, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "3. filtering (BM25: 5.2145, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 13.1058, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 7.1909, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. filtering (BM25: 5.8317, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 10.2042, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. hybrid-queries (BM25: 11.3780, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 6.2646, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 11.3780, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 10.2042, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 7.4450, Релевантность: 3)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 7.5817, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "2. indexing (BM25: 9.3282, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. search (BM25: 9.4281, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.4281, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. indexing (BM25: 9.3282, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. optimizer (BM25: 9.3263, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 14.2877, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 12.9275, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 13.3340, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 14.2877, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 13.4026, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. hybrid-queries (BM25: 13.3340, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 3.4707, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 3.7932, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. collections (BM25: 4.0153, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.5432, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. vectors (BM25: 4.4878, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. collections (BM25: 4.0153, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.7094, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 6.1723, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 12.8699, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.8699, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 12.7094, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. hybrid-queries (BM25: 6.1723, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.8466, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 4.8419, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 9.5724, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.8466, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 9.5724, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)...\n",
      "3. snapshots (BM25: 6.8391, Релевантность: 1)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.7675, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 3.6918, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. hybrid-queries (BM25: 8.8012, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 9.7696, Релевантность: 3)\n",
      "   With Qdrant, you can benefit from a more compact and efficient immutable sparse index, which is cons...\n",
      "2. hybrid-queries (BM25: 8.8012, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 7.7675, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.7119, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. indexing (BM25: 5.9524, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. payload (BM25: 11.5897, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 11.5897, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. explore (BM25: 9.3935, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "3. hybrid-queries (BM25: 7.7119, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 4.1432, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. payload (BM25: 8.6688, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "3. storage (BM25: 3.3947, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.6688, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 4.9743, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "3. search (BM25: 4.1865, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 13.1058, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 5.1583, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "3. filtering (BM25: 5.2145, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 13.1058, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 7.1909, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. filtering (BM25: 5.8317, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 10.2042, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. hybrid-queries (BM25: 11.3780, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 6.2646, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 11.3780, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 10.2042, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 7.4450, Релевантность: 3)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.4281, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 7.5817, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "3. indexing (BM25: 9.3282, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.4281, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. indexing (BM25: 9.3282, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. optimizer (BM25: 9.3263, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 14.2877, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 12.9275, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 13.3340, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 14.2877, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. hybrid-queries (BM25: 13.4026, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. hybrid-queries (BM25: 13.3340, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: Why is it more efficient to apply changes in batches in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.7074, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. storage (BM25: 13.5733, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. indexing (BM25: 4.9715, Релевантность: 3)\n",
      "   With Qdrant, you can benefit from a more compact and efficient immutable sparse index, which is cons...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 13.5733, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. search (BM25: 9.7074, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. points (BM25: 6.6435, Релевантность: 2)\n",
      "   The Qdrant API supports two ways of creating batches - record-oriented and column-oriented. Internal...\n",
      "\n",
      "Вопрос: What does Qdrant use to handle data changes during segment optimization?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 14.7528, Релевантность: 5)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. optimizer (BM25: 24.4602, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. collections (BM25: 11.7456, Релевантность: 4)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 24.4602, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. storage (BM25: 14.7528, Релевантность: 5)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. optimizer (BM25: 12.1165, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What is the purpose of the Vacuum Optimizer in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 11.5111, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. storage (BM25: 4.0608, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. collections (BM25: 4.4815, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 11.5111, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. indexing (BM25: 4.8563, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. collections (BM25: 4.4815, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Вопрос: What criteria determine when to trigger the Vacuum Optimizer?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 15.1269, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 8.3411, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. optimizer (BM25: 8.3882, Релевантность: 4)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 15.1269, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 8.3882, Релевантность: 4)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "3. optimizer (BM25: 8.3411, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What does the Merge Optimizer do in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 9.5006, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. collections (BM25: 4.4815, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. optimizer (BM25: 4.3171, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 9.5006, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. collections (BM25: 4.4815, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. optimizer (BM25: 4.3171, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: How does the Indexing Optimizer determine when to enable indexes in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 13.4856, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. indexing (BM25: 13.0018, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 7.0929, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 13.4856, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. indexing (BM25: 13.0018, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 11.5732, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What happens to segments larger than the specified memmap_threshold in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 11.9247, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 9.1401, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. optimizer (BM25: 6.4909, Релевантность: 2)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 11.9247, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 9.1401, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. storage (BM25: 7.0370, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Вопрос: What can the user configure in the Qdrant configuration file related to optimizers?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 7.6652, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "2. optimizer (BM25: 12.2716, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. optimizer (BM25: 11.1734, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 12.7442, Релевантность: 3)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. optimizer (BM25: 12.2716, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. collections (BM25: 11.6569, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: Why might a user choose to disable indexing during initial data loading in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 19.0776, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. optimizer (BM25: 14.8252, Релевантность: 3)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 10.9083, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 19.0776, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. optimizer (BM25: 14.8252, Релевантность: 3)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 10.9083, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What is the primary challenge faced by Qdrant regarding deleted records?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 12.2231, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. search (BM25: 4.2657, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "3. search (BM25: 3.4514, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 12.2231, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 5.4012, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. search (BM25: 4.2657, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "\n",
      "Вопрос: What is the term used in Qdrant for storing additional information along with vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 17.8697, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 11.9423, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. search (BM25: 11.7397, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 17.8697, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. collections (BM25: 13.8839, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. indexing (BM25: 11.9423, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What data format does Qdrant allow for the representation of payload information?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 12.6093, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. storage (BM25: 8.1930, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. storage (BM25: 7.7079, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 13.2281, Релевантность: 2)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "2. payload (BM25: 12.6093, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 8.6075, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What happens during filtering if the stored value type does not fit the filtering condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 18.3895, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 8.8931, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 7.9796, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Scroll(co...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 18.3895, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. storage (BM25: 10.7932, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. filtering (BM25: 9.2361, Релевантность: 2)\n",
      "   If several location values are stored for a point, then any of them matching will include that point...\n",
      "\n",
      "Вопрос: What type of numbers does Qdrant support for integer values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 12.8775, Релевантность: 5)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "2. payload (BM25: 10.0864, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "3. search (BM25: 8.3413, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 12.8775, Релевантность: 5)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "2. payload (BM25: 10.0864, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "3. payload (BM25: 8.3980, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: What are the two methods to update payloads mentioned in the text?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 11.6703, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. points (BM25: 12.0444, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. vectors (BM25: 5.2144, Релевантность: 4)\n",
      "   Multiple representation of the same object - For example, you can store multiple embeddings for pict...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 12.0444, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. payload (BM25: 11.6703, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. search (BM25: 7.5273, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: Which method is used to remove all payload keys from specified points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 16.5167, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. indexing (BM25: 7.0232, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 6.8880, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 16.5167, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. indexing (BM25: 7.9281, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. search (BM25: 7.7580, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What type of indexing does Qdrant allow for payload fields to improve search efficiency?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 18.9665, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "2. indexing (BM25: 12.0498, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 12.3327, Релевантность: 4)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 18.9665, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "2. storage (BM25: 16.2577, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. indexing (BM25: 12.3327, Релевантность: 4)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What is faceting in the context of Qdrant, and what can it be used for?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 10.2833, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 5.6540, Релевантность: 5)\n",
      "   REST API (Facet) http POST /collections/{collection_name}/facet { \"key\": \"size\", \"filter\": { \"must\":...\n",
      "3. explore (BM25: 3.7463, Релевантность: 2)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 10.2833, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 5.6540, Релевантность: 5)\n",
      "   REST API (Facet) http POST /collections/{collection_name}/facet { \"key\": \"size\", \"filter\": { \"must\":...\n",
      "3. explore (BM25: 3.7463, Релевантность: 2)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Вопрос: What should you do before using faceting on a field in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 13.8426, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 5.8453, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "3. indexing (BM25: 5.4218, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 13.8426, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 5.8453, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.DeletePay...\n",
      "3. indexing (BM25: 5.4218, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What will the response contain when performing a facet count for a field?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 17.1225, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) res, err := clie...\n",
      "2. payload (BM25: 20.3371, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "3. filtering (BM25: 5.8267, Релевантность: 3)\n",
      "   Match json { \"key\": \"color\", \"match\": { \"value\": \"red\" } } python models.FieldCondition( key=\"color\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 20.3371, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "2. payload (BM25: 17.1225, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) res, err := clie...\n",
      "3. payload (BM25: 9.6415, Релевантность: 2)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "\n",
      "Вопрос: What is the primary function of the Qdrant Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.8980, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "2. hybrid-queries (BM25: 4.6492, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. hybrid-queries (BM25: 3.6183, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 4.8980, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "2. hybrid-queries (BM25: 4.6492, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. explore (BM25: 3.6969, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: Which similarity search method is referred to as k-NN?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 7.1911, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. search (BM25: 10.9221, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. collections (BM25: 8.6212, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 10.9221, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. collections (BM25: 8.6212, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. indexing (BM25: 7.6334, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: What types of metrics does Qdrant support for estimating vector similarity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 21.8547, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 8.8589, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. search (BM25: 9.9615, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 21.8547, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 12.0122, Релевантность: 3)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. indexing (BM25: 10.2723, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What does the 'limit' parameter specify in a search query?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 7.8494, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 4.7576, Релевантность: 5)\n",
      "   } ``` python client.query_points_groups( collection_name=\"chunks\", # Same as in the regular search()...\n",
      "3. search (BM25: 6.4315, Релевантность: 2)\n",
      "   hnsw_ef - value that specifies ef parameter of the HNSW algorithm. exact - option to not use the app...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 7.8494, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. indexing (BM25: 6.5749, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. search (BM25: 6.4315, Релевантность: 2)\n",
      "   hnsw_ef - value that specifies ef parameter of the HNSW algorithm. exact - option to not use the app...\n",
      "\n",
      "Вопрос: In which version of Qdrant is the batch search API available?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 12.9262, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. points (BM25: 8.9172, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Count(con...\n",
      "3. explore (BM25: 12.0257, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 12.9262, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 12.0257, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. points (BM25: 9.4769, Релевантность: 2)\n",
      "   The Qdrant API supports two ways of creating batches - record-oriented and column-oriented. Internal...\n",
      "\n",
      "Вопрос: How can you filter search results based on a specific payload key using the Qdrant search API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 16.2728, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "2. payload (BM25: 10.8307, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 14.2882, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 16.2728, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "2. indexing (BM25: 14.2882, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 14.2606, Релевантность: 2)\n",
      "   We have to use IsNull condition instead: json { \"is_null\": { \"key\": \"reports\" } } python models.IsNu...\n",
      "\n",
      "Вопрос: What is the default scoring metric for sparse queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 16.0466, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 7.0730, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. vectors (BM25: 6.7595, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 16.0466, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 13.8412, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 9.8470, Релевантность: 2)\n",
      "   Normalizes the scores of the points in each query, using the mean +/- the 3rd standard deviation as ...\n",
      "\n",
      "Вопрос: What is the purpose of the 'with_lookup' parameter in the grouping API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 11.3168, Релевантность: 5)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "2. search (BM25: 7.1687, Релевантность: 5)\n",
      "   } ``` python client.query_points_groups( collection_name=\"chunks\", # Same as in the regular search()...\n",
      "3. search (BM25: 5.6564, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 11.3168, Релевантность: 5)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "2. search (BM25: 9.8920, Релевантность: 5)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "3. search (BM25: 7.1687, Релевантность: 5)\n",
      "   } ``` python client.query_points_groups( collection_name=\"chunks\", # Same as in the regular search()...\n",
      "\n",
      "Вопрос: What does the 'offset' parameter do when searching with Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 3.1777, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. search (BM25: 3.8171, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. indexing (BM25: 3.9293, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 4.2971, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. indexing (BM25: 3.9293, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 3.9041, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What is a unique feature of the random sampling API in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 18.1782, Релевантность: 4)\n",
      "   Random Sampling Available as of v1.11.0 In some cases it might be useful to retrieve a random sample...\n",
      "2. search (BM25: 5.2684, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. vectors (BM25: 7.6919, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 18.1782, Релевантность: 4)\n",
      "   Random Sampling Available as of v1.11.0 In some cases it might be useful to retrieve a random sample...\n",
      "2. collections (BM25: 8.5258, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. vectors (BM25: 7.6919, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What is a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 1.3449, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 1.3366, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. storage (BM25: 1.5186, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 1.5488, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. storage (BM25: 1.5186, Релевантность: 2)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. collections (BM25: 1.4912, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "\n",
      "Вопрос: What identifier types does Qdrant support for points?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 8.1592, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. payload (BM25: 4.8572, Релевантность: 2)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "3. vectors (BM25: 6.9676, Релевантность: 2)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 8.1592, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. vectors (BM25: 6.9676, Релевантность: 2)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. collections (BM25: 6.3430, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: How can you modify a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 7.1557, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. payload (BM25: 5.8184, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Overwrite...\n",
      "3. payload (BM25: 5.9042, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.SetPayloa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 7.1557, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. payload (BM25: 5.9042, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.SetPayloa...\n",
      "3. payload (BM25: 5.8184, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Overwrite...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.5076, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 7.4180, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. search (BM25: 4.9819, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 7.5076, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 7.4180, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. storage (BM25: 5.7301, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: Can multiple types of vectors be attached to a single point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.4104, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. vectors (BM25: 5.8936, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. points (BM25: 12.4746, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 12.4746, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. collections (BM25: 11.1644, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. vectors (BM25: 7.4104, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What does the batch loading feature in Qdrant do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 10.0788, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. points (BM25: 7.5371, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Count(con...\n",
      "3. search (BM25: 6.8324, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 10.0788, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. points (BM25: 7.5371, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Count(con...\n",
      "3. search (BM25: 6.8324, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What is the purpose of the update_vectors method in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 3.7914, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. points (BM25: 3.8404, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateVec...\n",
      "3. payload (BM25: 5.3547, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 5.3547, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. points (BM25: 3.8404, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateVec...\n",
      "3. points (BM25: 3.7914, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "\n",
      "Вопрос: How does Qdrant handle deleting vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 11.1252, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. points (BM25: 6.4926, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateVec...\n",
      "3. points (BM25: 4.4510, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Count(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 11.1252, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. points (BM25: 6.4926, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateVec...\n",
      "3. points (BM25: 4.4510, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Count(con...\n",
      "\n",
      "Вопрос: What response is received when an API call is made with wait=false in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 23.2661, Релевантность: 5)\n",
      "   Awaiting result If the API is called with the &wait=false parameter, or if it is not explicitly spec...\n",
      "2. payload (BM25: 6.1523, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) res, err := clie...\n",
      "3. hybrid-queries (BM25: 5.7597, Релевантность: 2)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 23.2661, Релевантность: 5)\n",
      "   Awaiting result If the API is called with the &wait=false parameter, or if it is not explicitly spec...\n",
      "2. points (BM25: 11.0865, Релевантность: 1)\n",
      "   The Qdrant API supports two ways of creating batches - record-oriented and column-oriented. Internal...\n",
      "3. payload (BM25: 6.1523, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) res, err := clie...\n",
      "\n",
      "Вопрос: What is the Scroll API used for in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 5.5867, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. search (BM25: 4.0405, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 4.2925, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 5.5867, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. hybrid-queries (BM25: 4.2925, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. hybrid-queries (BM25: 4.2758, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What are snapshots in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 8.2771, Релевантность: 5)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 7.8135, Релевантность: 4)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "3. snapshots (BM25: 5.9164, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 8.2771, Релевантность: 5)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 7.8135, Релевантность: 4)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "3. snapshots (BM25: 5.9164, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Вопрос: How are snapshots created in a distributed deployment?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 26.1918, Релевантность: 5)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 10.0503, Релевантность: 3)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "3. collections (BM25: 10.7112, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 26.1918, Релевантность: 5)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. collections (BM25: 10.7112, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. snapshots (BM25: 10.0503, Релевантность: 3)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: What is the purpose of using snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 10.0236, Релевантность: 5)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 9.6415, Релевантность: 4)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "3. snapshots (BM25: 7.9007, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 10.0236, Релевантность: 5)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 9.6415, Релевантность: 4)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "3. snapshots (BM25: 9.1847, Релевантность: 3)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: What is the difference between snapshots and backups in Qdrant Cloud?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 21.1427, Релевантность: 4)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 7.8135, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "3. snapshots (BM25: 5.9164, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 21.1427, Релевантность: 4)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 7.8135, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "3. snapshots (BM25: 5.9164, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Вопрос: What does the API endpoint /collections/{collection_name}/snapshots do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 3.4370, Релевантность: 3)\n",
      "   http POST /collections/{collection_name}/facet { \"key\": \"size\", \"exact\": true } python client.facet(...\n",
      "2. points (BM25: 3.4750, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. search (BM25: 3.6103, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 9.4824, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. explore (BM25: 4.0808, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. vectors (BM25: 3.9162, Релевантность: 2)\n",
      "   ) client.Upsert(context.Background(), &qdrant.UpsertPoints{ CollectionName: \"{collection_name}\", Poi...\n",
      "\n",
      "Вопрос: What command is used to list snapshots for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 6.3357, Релевантность: 4)\n",
      "   For example, you can switch underlying collection with the following command: http POST /collections...\n",
      "2. snapshots (BM25: 11.6758, Релевантность: 2)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "3. snapshots (BM25: 10.3873, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 11.6758, Релевантность: 2)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 11.6074, Релевантность: 1)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "3. snapshots (BM25: 10.3873, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: What limitations exist when restoring snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.4388, Релевантность: 3)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "2. snapshots (BM25: 11.7444, Релевантность: 3)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "3. snapshots (BM25: 11.2638, Релевантность: 3)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 19.9134, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 11.7863, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 11.7444, Релевантность: 3)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: How can you recover a snapshot from a URL?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 24.0269, Релевантность: 5)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "2. snapshots (BM25: 20.6555, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 7.9363, Релевантность: 3)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 24.0269, Релевантность: 5)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "2. snapshots (BM25: 20.6555, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 14.7279, Релевантность: 2)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "\n",
      "Вопрос: What is the significance of snapshot priority during recovery?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 15.5064, Релевантность: 4)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "2. snapshots (BM25: 22.0111, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "3. snapshots (BM25: 5.4930, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 22.0111, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "2. snapshots (BM25: 15.5064, Релевантность: 4)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "3. snapshots (BM25: 14.4435, Релевантность: 2)\n",
      "   Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly reg...\n",
      "\n",
      "Вопрос: Where are snapshots stored by default?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 10.0439, Релевантность: 3)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "2. snapshots (BM25: 10.3447, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "3. snapshots (BM25: 10.2186, Релевантность: 2)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 11.1909, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 10.3447, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "3. snapshots (BM25: 10.2186, Релевантность: 2)\n",
      "   To recover a new collection from a snapshot, you need to set the priority to snapshot. With snapshot...\n",
      "\n",
      "Вопрос: What is the structure of data storage within a collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 5.7315, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 13.2296, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. storage (BM25: 9.3907, Релевантность: 4)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 15.0454, Релевантность: 3)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. storage (BM25: 13.2296, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. storage (BM25: 9.3907, Релевантность: 4)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "\n",
      "Вопрос: What types of segments are there in Qdrant, and what operations can be performed on them?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.8308, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 13.4915, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. explore (BM25: 7.8479, Релевантность: 3)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 13.4915, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. optimizer (BM25: 12.1035, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. explore (BM25: 7.8479, Релевантность: 3)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Вопрос: What is the difference between in-memory storage and memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 14.6155, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. optimizer (BM25: 20.1689, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 23.4083, Релевантность: 3)\n",
      "   With sufficient RAM, it is almost as fast as in-memory storage. Configuring Memmap storage There are...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 23.4083, Релевантность: 3)\n",
      "   With sufficient RAM, it is almost as fast as in-memory storage. Configuring Memmap storage There are...\n",
      "2. optimizer (BM25: 20.1689, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 14.6155, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What parameter is used to configure memmap storage for vectors during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 13.1303, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 12.2178, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. collections (BM25: 12.0792, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 21.9600, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. collections (BM25: 15.1424, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. storage (BM25: 13.1303, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What is the recommended approach for using memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 13.5030, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 11.7662, Релевантность: 4)\n",
      "   With sufficient RAM, it is almost as fast as in-memory storage. Configuring Memmap storage There are...\n",
      "3. storage (BM25: 11.3246, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 13.5030, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 11.7662, Релевантность: 4)\n",
      "   With sufficient RAM, it is almost as fast as in-memory storage. Configuring Memmap storage There are...\n",
      "3. storage (BM25: 11.3246, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: How does Qdrant handle the versioning of data and ensure data integrity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 24.4505, Релевантность: 5)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. snapshots (BM25: 7.1372, Релевантность: 4)\n",
      "   Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration...\n",
      "3. optimizer (BM25: 10.2546, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 24.4505, Релевантность: 5)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. indexing (BM25: 11.3000, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "3. optimizer (BM25: 10.2546, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Вопрос: What types of payload storage does Qdrant support, and what are their characteristics?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 12.5777, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. points (BM25: 8.0270, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. payload (BM25: 6.0391, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 12.5777, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 9.6530, Релевантность: 3)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. hybrid-queries (BM25: 8.7212, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: What should be done if large payload values are attached in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 12.9367, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. collections (BM25: 6.8919, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. indexing (BM25: 7.2551, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 12.9367, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. indexing (BM25: 7.2551, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateFie...\n",
      "3. collections (BM25: 6.8919, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What configuration parameter is used to specify the type of payload storage during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 9.4185, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 21.0965, Релевантность: 4)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "3. collections (BM25: 10.7871, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 21.0965, Релевантность: 4)\n",
      "   Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardl...\n",
      "2. storage (BM25: 15.9174, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. search (BM25: 14.3950, Релевантность: 2)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "\n",
      "Вопрос: What is the purpose of the memmap_threshold option in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 9.7538, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 4.4237, Релевантность: 5)\n",
      "   http PUT /collections/{collection_name} { \"vectors\": { \"size\": 768, \"distance\": \"Cosine\" }, \"optimiz...\n",
      "3. optimizer (BM25: 4.2103, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.7538, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. storage (BM25: 6.0790, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. storage (BM25: 4.7090, Релевантность: 4)\n",
      "   http PUT /collections/{collection_name} { \"vectors\": { \"size\": 768, \"distance\": \"Cosine\" }, \"optimiz...\n",
      "\n",
      "Вопрос: What are vectors in the context of Qdrant Vector Search engine?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.0539, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. indexing (BM25: 3.1361, Релевантность: 5)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. collections (BM25: 2.8808, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 7.0539, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. search (BM25: 3.4724, Релевантность: 3)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 3.3428, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: How does a vector representation relate to the similarity of objects?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 13.5669, Релевантность: 5)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. vectors (BM25: 14.8800, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. explore (BM25: 7.6275, Релевантность: 4)\n",
      "   Context is a set of positive-negative pairs, and each pair divides the space into positive and negat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 14.8800, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. search (BM25: 13.5669, Релевантность: 5)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. vectors (BM25: 10.8759, Релевантность: 3)\n",
      "   Multiple representation of the same object - For example, you can store multiple embeddings for pict...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.5076, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 7.4180, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. search (BM25: 4.9819, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 7.5076, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 7.4180, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. storage (BM25: 5.7301, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What is the difference between dense vectors and sparse vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 9.1984, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "2. vectors (BM25: 5.6163, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. points (BM25: 7.3787, Релевантность: 3)\n",
      "   They are represented as a list of (index, value) pairs, where index is an integer and value is a flo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 13.5415, Релевантность: 2)\n",
      "   There is a difference in how Uint8 vectors are handled for dense and sparse vectors. Dense vectors a...\n",
      "2. points (BM25: 9.1984, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. points (BM25: 7.3787, Релевантность: 3)\n",
      "   They are represented as a list of (index, value) pairs, where index is an integer and value is a flo...\n",
      "\n",
      "Вопрос: What configuration must be set to create a collection with sparse vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 7.3669, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. collections (BM25: 9.5102, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. collections (BM25: 9.7564, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 11.6750, Релевантность: 2)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "2. collections (BM25: 9.7564, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "3. collections (BM25: 9.5102, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What are multivectors and what scenarios are they useful in?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 13.1520, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. points (BM25: 4.5887, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Upsert(co...\n",
      "3. explore (BM25: 6.5686, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 13.1520, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. explore (BM25: 6.5686, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "3. search (BM25: 6.1494, Релевантность: 1)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.QueryGrou...\n",
      "\n",
      "Вопрос: What datatype is used by default for vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 11.8283, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. collections (BM25: 6.2811, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. hybrid-queries (BM25: 5.8407, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 11.8283, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "2. collections (BM25: 6.2811, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. hybrid-queries (BM25: 5.8407, Релевантность: 3)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.Query(con...\n",
      "\n",
      "Вопрос: How does Qdrant optimize memory usage for large-dimensionality vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 4.7889, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. collections (BM25: 6.6443, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. indexing (BM25: 6.8079, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.3050, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. indexing (BM25: 6.8079, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. collections (BM25: 6.6443, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Вопрос: What is the purpose of quantization in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.3255, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. vectors (BM25: 5.1837, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. collections (BM25: 3.8279, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 7.3255, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. vectors (BM25: 5.1837, Релевантность: 5)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "3. collections (BM25: 4.4470, Релевантность: 2)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.UpdateCol...\n",
      "\n",
      "Вопрос: What trade-offs must be considered when using different storage options in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 10.7982, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. optimizer (BM25: 6.7817, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. collections (BM25: 7.4752, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 10.7982, Релевантность: 4)\n",
      "   ) client, err := qdrant.NewClient(&qdrant.Config{ Host: \"localhost\", Port: 6334, }) client.CreateCol...\n",
      "2. indexing (BM25: 9.8346, Релевантность: 3)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. points (BM25: 8.0310, Релевантность: 2)\n",
      "   The Qdrant API supports two ways of creating batches - record-oriented and column-oriented. Internal...\n",
      "Результаты сохранены в reranker_retrieval_results.csv\n",
      "\n",
      "Начало оценки только BM25 (без реранкера) для сравнения...\n",
      "Оценка BM25 для top_4...\n",
      "Всего загружено 292 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Внимание: 16 документов не содержат токенов после предобработки.\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 276\n",
      "Результаты сохранены в bm25_only_top4_results.csv\n",
      "Оценка BM25 для top_6...\n",
      "Всего загружено 292 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Внимание: 16 документов не содержат токенов после предобработки.\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 276\n",
      "Результаты сохранены в bm25_only_top6_results.csv\n",
      "\n",
      "Сравнение метрик BM25 и BM25+TinyBERT:\n",
      "Метрика              BM25            BM25+TinyBERT  \n",
      "--------------------------------------------------\n",
      "top_4_recall@4       1.0000          1.0000         \n",
      "top_4_precision@4    0.4625          0.4771         \n",
      "top_4_mrr@4          0.7458          0.7715         \n",
      "top_4_ndcg@4         0.8173          0.8638         \n",
      "top_6_recall@6       1.0000          1.0000         \n",
      "top_6_precision@6    0.4125          0.4222         \n",
      "top_6_mrr@6          0.7597          0.7739         \n",
      "top_6_ndcg@6         0.8440          0.8684         \n",
      "\n",
      "Реранкер улучшил 6 из 8 метрик (75.00%)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончания -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "# Класс для реранкинга с использованием модели TinyBERT\n",
    "class TinyBertReranker:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            print(\"Инициализация TinyBert реранкера...\")\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"nboost/pt-tinybert-msmarco\")\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(\"nboost/pt-tinybert-msmarco\").to(self.device)\n",
    "            self.model.eval()\n",
    "            print(f\"TinyBert реранкер успешно инициализирован (устройство: {self.device})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации TinyBert реранкера: {e}\")\n",
    "            raise\n",
    "\n",
    "    def rerank(self, query, documents, fragment_scores, max_seq_length=512):\n",
    "        \"\"\"\n",
    "        Переранжирует документы с использованием TinyBERT модели.\n",
    "        \n",
    "        Args:\n",
    "            query: Текст запроса\n",
    "            documents: Список текстов документов\n",
    "            fragment_scores: Исходные оценки документов (из BM25)\n",
    "            max_seq_length: Максимальная длина последовательности для токенизатора\n",
    "            \n",
    "        Returns:\n",
    "            Список кортежей (документ, исходная_оценка, новая_оценка)\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return []\n",
    "\n",
    "        # Подготовка входных данных\n",
    "        inputs = []\n",
    "        for doc in documents:\n",
    "            # Обрезаем документы, чтобы избежать слишком длинных последовательностей\n",
    "            tokenized = self.tokenizer.encode_plus(\n",
    "                query, \n",
    "                doc, \n",
    "                add_special_tokens=True,\n",
    "                max_length=max_seq_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            inputs.append(tokenized)\n",
    "\n",
    "        # Получение предсказаний\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for input_dict in inputs:\n",
    "                input_dict = {k: v.to(self.device) for k, v in input_dict.items()}\n",
    "                output = self.model(**input_dict)\n",
    "                # Для моделей ранжирования обычно берем последний скор (релевантность)\n",
    "                score = output.logits[0][1].item()  # Используем score релевантности\n",
    "                scores.append(score)\n",
    "\n",
    "        # Комбинирование результатов с исходными документами и оценками\n",
    "        ranked_results = list(zip(documents, fragment_scores, scores))\n",
    "        \n",
    "        # Сортировка по убыванию нового скора\n",
    "        ranked_results = sorted(ranked_results, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        return ranked_results\n",
    "\n",
    "class DocumentationQA_BM25:\n",
    "    def __init__(self):\n",
    "        self.bm25 = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.tokenized_corpus = []\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "        # Использование переменных из глобального контекста\n",
    "        self.stop_words = stop_words\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Предобработка текста: токенизация, удаление стоп-слов и стемминг\"\"\"\n",
    "        # Токенизация и приведение к нижнему регистру\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        # Удаление пунктуации и цифр\n",
    "        tokens = [token for token in tokens if token not in string.punctuation and not token.isdigit()]\n",
    "        # Удаление стоп-слов\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        # Стемминг\n",
    "        try:\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка стемминга: {e}. Пропускаем этап стемминга.\")\n",
    "        return tokens\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        \n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        \n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "        \n",
    "        # Токенизация и предобработка текстовых фрагментов для BM25\n",
    "        print(\"Начинаем токенизацию и предобработку текста...\")\n",
    "        self.tokenized_corpus = [self.preprocess_text(doc['text']) for doc in self.doc_paragraphs]\n",
    "        \n",
    "        # Проверка на пустые токенизированные документы\n",
    "        non_empty_docs = [(i, doc) for i, doc in enumerate(self.tokenized_corpus) if doc]\n",
    "        if len(non_empty_docs) < len(self.tokenized_corpus):\n",
    "            print(f\"Внимание: {len(self.tokenized_corpus) - len(non_empty_docs)} документов не содержат токенов после предобработки.\")\n",
    "            \n",
    "            # Отфильтровываем пустые документы\n",
    "            valid_indices = [i for i, _ in non_empty_docs]\n",
    "            self.tokenized_corpus = [self.tokenized_corpus[i] for i in valid_indices]\n",
    "            self.doc_paragraphs = [self.doc_paragraphs[i] for i in valid_indices]\n",
    "        \n",
    "        # Инициализация BM25\n",
    "        print(\"Инициализация BM25...\")\n",
    "        try:\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            print(f\"BM25 успешно инициализирован. Всего документов: {len(self.tokenized_corpus)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации BM25: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs(self, user_query, top_k=20):\n",
    "        \"\"\"Поиск похожих параграфов с использованием BM25\"\"\"\n",
    "        if not self.bm25:\n",
    "            print(\"Ошибка: BM25 не инициализирован!\")\n",
    "            return []\n",
    "            \n",
    "        # Предобработка запроса\n",
    "        tokenized_query = self.preprocess_text(user_query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            print(\"Предупреждение: запрос не содержит значимых токенов после предобработки!\")\n",
    "            return []\n",
    "                # Получение BM25 scores для всех документов\n",
    "        try:\n",
    "            scores = self.bm25.get_scores(tokenized_query)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении оценок BM25: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Индексы документов с наивысшими оценками\n",
    "        top_n = np.argsort(scores)[::-1][:top_k]\n",
    "        \n",
    "        # Возвращение текста, имени документа и оценки BM25\n",
    "        results = []\n",
    "        for i in top_n:\n",
    "            if scores[i] > 0:  # Добавление только если оценка больше 0\n",
    "                results.append((self.doc_paragraphs[i]['text'], self.doc_paragraphs[i]['name'], float(scores[i])))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_with_reranker(qa_system, reranker, question, initial_top_k=20, final_top_k=6):\n",
    "    \"\"\"\n",
    "    Получение релевантных фрагментов с использованием BM25 и последующего реранкинга\n",
    "    \n",
    "    Args:\n",
    "        qa_system: Экземпляр системы BM25\n",
    "        reranker: Экземпляр реранкера\n",
    "        question: Текст вопроса\n",
    "        initial_top_k: Количество фрагментов, получаемых из BM25\n",
    "        final_top_k: Количество фрагментов после реранкинга\n",
    "    \n",
    "    Returns:\n",
    "        Список отсортированных по релевантности фрагментов\n",
    "    \"\"\"\n",
    "    # Получаем исходные фрагменты с помощью BM25\n",
    "    initial_fragments = qa_system.search_similar_paragraphs(question, top_k=initial_top_k)\n",
    "    \n",
    "    if not initial_fragments:\n",
    "        print(f\"Предупреждение: BM25 не нашел фрагментов для запроса '{question}'\")\n",
    "        return []\n",
    "    \n",
    "    # Разделяем фрагменты на составляющие для реранкера\n",
    "    texts = [fragment[0] for fragment in initial_fragments]\n",
    "    names = [fragment[1] for fragment in initial_fragments]\n",
    "    scores = [fragment[2] for fragment in initial_fragments]\n",
    "    \n",
    "    # Применяем реранкер\n",
    "    try:\n",
    "        reranked_fragments = reranker.rerank(question, texts, scores)\n",
    "        \n",
    "        # Ограничиваем количество возвращаемых фрагментов\n",
    "        reranked_fragments = reranked_fragments[:final_top_k]\n",
    "        \n",
    "        # Восстанавливаем формат результатов с именами документов\n",
    "        result_fragments = [(text, names[texts.index(text)], orig_score, rerank_score) \n",
    "                           for text, orig_score, rerank_score in reranked_fragments]\n",
    "        \n",
    "        return result_fragments\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при реранкинге: {e}\")\n",
    "        # В случае ошибки возвращаем исходные результаты BM25\n",
    "        return [(text, name, score, 0.0) for text, name, score in initial_fragments[:final_top_k]]\n",
    "\n",
    "def calculate_metrics(retrieval_results, k_values=[4, 6]):\n",
    "    \"\"\"\n",
    "    Вычисление метрик эффективности ретривала для разных значений k\n",
    "    \n",
    "    Args:\n",
    "        retrieval_results: Результаты ретривала\n",
    "        k_values: Список значений k для вычисления метрик\n",
    "    \n",
    "    Returns:\n",
    "        Словарь метрик\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Инициализация метрик для всех значений k\n",
    "    for k in k_values:\n",
    "        metrics.update({\n",
    "            f'recall@{k}': [],\n",
    "            f'precision@{k}': [],\n",
    "            f'mrr@{k}': [],\n",
    "            f'ndcg@{k}': []\n",
    "        })\n",
    "    \n",
    "    # Добавляем recall@1 и precision@1\n",
    "    metrics['recall@1'] = []\n",
    "    metrics['precision@1'] = []\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Для каждого значения k вычисляем метрики\n",
    "            for k in k_values:\n",
    "                # Recall@k\n",
    "                relevant_at_k = sum(1 for f in retrieved_fragments[:min(k, len(retrieved_fragments))] if f[3] >= 4)\n",
    "                metrics[f'recall@{k}'].append(relevant_at_k / total_relevant)\n",
    "                \n",
    "                # Precision@k\n",
    "                metrics[f'precision@{k}'].append(relevant_at_k / min(k, len(retrieved_fragments)))\n",
    "                \n",
    "                # MRR@k (Mean Reciprocal Rank)\n",
    "                first_relevant_rank = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(k, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "                if first_relevant_rank > 0:\n",
    "                    metrics[f'mrr@{k}'].append(1.0 / first_relevant_rank)\n",
    "                else:\n",
    "                    metrics[f'mrr@{k}'].append(0.0)\n",
    "                \n",
    "                # nDCG@k\n",
    "                if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "                    # Определяем количество документов для оценки\n",
    "                    k_actual = min(k, len(sorted_fragments), len(retrieved_fragments))\n",
    "                    \n",
    "                    # Берем только первые k_actual документов\n",
    "                    true_relevance = np.array([f[3] for f in sorted_fragments[:k_actual]])\n",
    "                    predicted_order_relevance = np.array([f[3] for f in retrieved_fragments[:k_actual]])\n",
    "                    \n",
    "                    try:\n",
    "                        ndcg = ndcg_score([true_relevance], [predicted_order_relevance])\n",
    "                        metrics[f'ndcg@{k}'].append(ndcg)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Ошибка при вычислении nDCG@{k}: {e}\")\n",
    "                        metrics[f'ndcg@{k}'].append(0.0)\n",
    "                else:\n",
    "                    metrics[f'ndcg@{k}'].append(0.0)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            \n",
    "            for k in k_values:\n",
    "                metrics[f'recall@{k}'].append(1.0)\n",
    "                metrics[f'precision@{k}'].append(0.0)\n",
    "                metrics[f'mrr@{k}'].append(0.0)\n",
    "                metrics[f'ndcg@{k}'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "def run_evaluation_with_reranker(api_key, test_questions, k_values=[4, 6]):\n",
    "    \"\"\"\n",
    "    Запуск оценки системы с BM25 и реранкером на наборе тестовых вопросов\n",
    "    \n",
    "    Args:\n",
    "        api_key: API ключ для оценки релевантности\n",
    "        test_questions: Список тестовых вопросов\n",
    "        k_values: Список значений k для оценки\n",
    "    \n",
    "    Returns:\n",
    "        Метрики и результаты оценки\n",
    "    \"\"\"\n",
    "    # Инициализация системы BM25\n",
    "    qa_system = DocumentationQA_BM25()\n",
    "    qa_system.initialize_database()\n",
    "    \n",
    "    # Инициализация реранкера\n",
    "    reranker = TinyBertReranker()\n",
    "    \n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "    \n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        # Получение фрагментов с помощью BM25 и реранкера\n",
    "        # Базовая модель отбирает 20 фрагментов, затем реранкер выбирает лучшие\n",
    "        max_k = max(k_values)  # Максимальное k из запрошенных\n",
    "        reranked_fragments = get_relevant_fragments_with_reranker(\n",
    "            qa_system, reranker, question, initial_top_k=20, final_top_k=max_k\n",
    "        )\n",
    "        \n",
    "        # Результаты для текущего вопроса\n",
    "        result = {'question': question, 'fragments': []}\n",
    "        \n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, bm25_score, rerank_score in reranked_fragments:\n",
    "            # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, bm25_score, relevance_score))\n",
    "        \n",
    "        retrieval_results.append(result)\n",
    "    \n",
    "    # Отдельные метрики для каждого значения k\n",
    "    metrics_results = {}\n",
    "    for k in k_values:\n",
    "        # Для каждого k создаем копию результатов, но ограничиваем количество фрагментов до k\n",
    "        k_results = []\n",
    "        for result in retrieval_results:\n",
    "            k_result = {\n",
    "                'question': result['question'],\n",
    "                'fragments': result['fragments'][:k] if result['fragments'] else []\n",
    "            }\n",
    "            k_results.append(k_result)\n",
    "        \n",
    "        # Вычисление метрик для текущего k\n",
    "        k_metrics = calculate_metrics(k_results, [k])\n",
    "        metrics_results[f'top_{k}'] = k_metrics\n",
    "    \n",
    "    # Объединение всех метрик\n",
    "    combined_metrics = {}\n",
    "    for k, metrics in metrics_results.items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            combined_metrics[f\"{k}_{metric_name}\"] = value\n",
    "    \n",
    "    return combined_metrics, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, bm25_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'bm25_score': bm25_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "        df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "        \n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "        \n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "        \n",
    "        # Определяем значения k для оценки\n",
    "        k_values = [4, 6]\n",
    "        \n",
    "        # Запуск оценки\n",
    "        print(\"Начало оценки системы с BM25 и реранкером TinyBERT...\")\n",
    "        metrics, results = run_evaluation_with_reranker(api_key, test_questions, k_values)\n",
    "        \n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки системы:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            \n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "                \n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "            \n",
    "            # Сортировка по BM25\n",
    "            sorted_by_bm25 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по BM25:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_bm25[:min(3, len(sorted_by_bm25))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "        \n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(results, \"reranker_retrieval_results.csv\")\n",
    "        \n",
    "        # Проведем сравнение с исходной версией без реранкера\n",
    "        print(\"\\nНачало оценки только BM25 (без реранкера) для сравнения...\")\n",
    "        \n",
    "        # Функция для оценки BM25 без реранкера\n",
    "        def run_evaluation_bm25_only(api_key, test_questions, top_k):\n",
    "            \"\"\"Запуск оценки только BM25 системы на наборе тестовых вопросов\"\"\"\n",
    "            # Инициализация системы BM25\n",
    "            qa_system = DocumentationQA_BM25()\n",
    "            qa_system.initialize_database()\n",
    "            \n",
    "            # Результаты для последующей оценки\n",
    "            retrieval_results = []\n",
    "            \n",
    "            # Обработка каждого вопроса\n",
    "            for question in test_questions:\n",
    "                # Получение фрагментов с помощью BM25\n",
    "                fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "                \n",
    "                # Результаты для текущего вопроса\n",
    "                result = {'question': question, 'fragments': []}\n",
    "                \n",
    "                # Оценка релевантности для каждого фрагмента\n",
    "                for text, name, score in fragments:\n",
    "                    # Используем сохраненные оценки релевантности, если есть\n",
    "                    found = False\n",
    "                    for r in results:\n",
    "                        if r['question'] == question:\n",
    "                            for t, n, _, rel_score in r['fragments']:\n",
    "                                if t == text and n == name:\n",
    "                                    result['fragments'].append((text, name, score, rel_score))\n",
    "                                    found = True\n",
    "                                    break\n",
    "                        if found:\n",
    "                            break\n",
    "                    \n",
    "                    # Если не нашли сохраненную оценку, запрашиваем новую\n",
    "                    if not found:\n",
    "                        time.sleep(2)\n",
    "                        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                        result['fragments'].append((text, name, score, relevance_score))\n",
    "                \n",
    "                retrieval_results.append(result)\n",
    "            \n",
    "            # Вычисление метрик\n",
    "            metrics_results = calculate_metrics(retrieval_results, k_values)\n",
    "            \n",
    "            return metrics_results, retrieval_results\n",
    "        \n",
    "        # Запускаем оценку BM25 отдельно для каждого значения k\n",
    "        bm25_metrics = {}\n",
    "        for k in k_values:\n",
    "            print(f\"Оценка BM25 для top_{k}...\")\n",
    "            k_metrics, k_results = run_evaluation_bm25_only(api_key, test_questions, k)\n",
    "            \n",
    "            # Добавляем префикс к метрикам\n",
    "            for metric, value in k_metrics.items():\n",
    "                if f\"@{k}\" in metric:  # Добавляем только метрики для текущего k\n",
    "                    bm25_metrics[f\"top_{k}_{metric}\"] = value\n",
    "            \n",
    "            # Сохраняем результаты BM25\n",
    "            save_results_to_csv(k_results, f\"bm25_only_top{k}_results.csv\")\n",
    "        \n",
    "        # Сравнение метрик\n",
    "        print(\"\\nСравнение метрик BM25 и BM25+TinyBERT:\")\n",
    "        print(\"{:<20} {:<15} {:<15}\".format(\"Метрика\", \"BM25\", \"BM25+TinyBERT\"))\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                \n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    \n",
    "                    print(\"{:<20} {:<15.4f} {:<15.4f}\".format(\n",
    "                        bm25_key, bm25_value, reranker_value\n",
    "                    ))\n",
    "        \n",
    "        # Анализ улучшений\n",
    "        total_improvements = 0\n",
    "        total_metrics = 0\n",
    "        \n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                \n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    \n",
    "                    if reranker_value > bm25_value:\n",
    "                        total_improvements += 1\n",
    "                    \n",
    "                    total_metrics += 1\n",
    "        \n",
    "        if total_metrics > 0:\n",
    "            improvement_percentage = (total_improvements / total_metrics) * 100\n",
    "            print(f\"\\nРеранкер улучшил {total_improvements} из {total_metrics} метрик ({improvement_percentage:.2f}%)\")\n",
    "        \n",
    "        return metrics, results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\sekho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало оценки системы с BM25 и реранкером BGE...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n",
      "Инициализация BGE реранкера...\n",
      "BGE реранкер успешно инициализирован (устройство: cpu)\n",
      "\n",
      "Результаты оценки системы с BGE реранкером:\n",
      "top_4_recall@4: 1.0000\n",
      "top_4_precision@4: 0.4979\n",
      "top_4_mrr@4: 0.7833\n",
      "top_4_ndcg@4: 0.8452\n",
      "top_4_recall@1: 0.5035\n",
      "top_4_precision@1: 0.7083\n",
      "top_6_recall@6: 1.0000\n",
      "top_6_precision@6: 0.4194\n",
      "top_6_mrr@6: 0.7701\n",
      "top_6_ndcg@6: 0.8391\n",
      "top_6_recall@1: 0.4346\n",
      "top_6_precision@1: 0.6833\n",
      "\n",
      "Детальный анализ результатов:\n",
      "\n",
      "Вопрос: What is a collection in the context of Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 1.0890, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. vectors (BM25: 1.0080, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. indexing (BM25: 0.9732, Релевантность: 4)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 5.0586, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. search (BM25: 3.6047, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. collections (BM25: 1.0890, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What must be true about the dimensionality of vectors within a single collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 15.5227, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 9.3378, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. vectors (BM25: 7.6818, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 15.5227, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 9.3378, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. vectors (BM25: 7.6818, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Вопрос: How does Qdrant support different metrics for comparing vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 12.4336, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 7.5117, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. vectors (BM25: 8.1823, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 12.4336, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. vectors (BM25: 8.1823, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. search (BM25: 7.5117, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: When should multiple collections be created instead of just one?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 3.9666, Релевантность: 5)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "2. vectors (BM25: 3.5607, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. explore (BM25: 5.0853, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.9305, Релевантность: 3)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "2. storage (BM25: 5.2823, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. explore (BM25: 5.0853, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Вопрос: What are some parameters that can be tuned for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.4136, Релевантность: 5)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "2. collections (BM25: 5.6781, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. collections (BM25: 1.5060, Релевантность: 4)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.6781, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. search (BM25: 1.6843, Релевантность: 4)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "3. collections (BM25: 1.5060, Релевантность: 4)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "\n",
      "Вопрос: What happens if different types of vectors are used within a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.1337, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "2. collections (BM25: 6.9553, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. explore (BM25: 7.0639, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 8.5023, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 7.2396, Релевантность: 2)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "3. vectors (BM25: 7.1337, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Вопрос: How can the existence of a collection in Qdrant be checked?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 5.1198, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. search (BM25: 2.1454, Релевантность: 3)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. collections (BM25: 3.8758, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.1198, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. collections (BM25: 3.8758, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. points (BM25: 3.6280, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What is the purpose of the payload in vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.4534, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. collections (BM25: 2.4824, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. storage (BM25: 2.3913, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 2.7189, Релевантность: 2)\n",
      "   Upsert points: upsert or UpsertOperation Delete points: delete_points or DeleteOperation Update vect...\n",
      "2. collections (BM25: 2.4824, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. indexing (BM25: 2.4534, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: Can collections be updated after their creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 4.0727, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. collections (BM25: 2.8290, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. collections (BM25: 2.9557, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 5.6827, Релевантность: 2)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 4.0727, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. filtering (BM25: 3.6790, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Вопрос: How does the choice of metric influence search results in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.7689, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. collections (BM25: 8.8186, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 3.8370, Релевантность: 4)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 8.8186, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 8.7689, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. search (BM25: 5.9068, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What Stack of APIs does Qdrant provide for data exploration?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 12.3530, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. search (BM25: 6.9773, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. points (BM25: 6.1248, Релевантность: 4)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 12.3530, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. search (BM25: 6.9773, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. points (BM25: 6.1248, Релевантность: 4)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Вопрос: How does the Recommendation API enhance the search functionality?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 4.8602, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 5.0539, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. indexing (BM25: 2.7326, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 8.2409, Релевантность: 3)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "2. explore (BM25: 5.0539, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. explore (BM25: 4.8602, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the default strategy for recommendations in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 7.9926, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 4.4195, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. vectors (BM25: 2.4980, Релевантность: 3)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.9926, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 4.4195, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. indexing (BM25: 2.9617, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What is the purpose of the 'best_score' strategy introduced in Qdrant v1.6.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 11.1105, Релевантность: 5)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "2. explore (BM25: 3.2545, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "3. explore (BM25: 4.8864, Релевантность: 3)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 11.1105, Релевантность: 5)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "2. explore (BM25: 4.8864, Релевантность: 3)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "3. explore (BM25: 3.9300, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: How can users find the most dissimilar vectors using only negative examples?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 19.6720, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. explore (BM25: 11.5217, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 6.3146, Релевантность: 4)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 19.6720, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. explore (BM25: 11.5217, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 7.3943, Релевантность: 3)\n",
      "   The formula for the discovery score can be expressed as: $$ \\text{rank}(v^+, v^-) = \\begin{cases} 1,...\n",
      "\n",
      "Вопрос: What can be specified in the recommendation request when a collection is created with multiple vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 12.7135, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. points (BM25: 5.5009, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. search (BM25: 5.9639, Релевантность: 5)\n",
      "   Since the filter parameter is specified, the search is performed only among those points that satisf...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 12.7135, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. collections (BM25: 7.8676, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. explore (BM25: 7.1788, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: What is the function of the 'lookup_from' parameter in the recommendation request?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 6.8864, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. search (BM25: 3.1316, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. explore (BM25: 5.2026, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.0831, Релевантность: 2)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "2. explore (BM25: 6.8864, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "3. explore (BM25: 5.2026, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: How does the Discovery API differ from the Recommendation API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 9.3817, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. explore (BM25: 7.5201, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 6.0997, Релевантность: 2)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 9.3817, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. explore (BM25: 9.2109, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. explore (BM25: 7.5201, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the significance of using a context in Discovery search?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 13.7591, Релевантность: 5)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. explore (BM25: 8.2644, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. search (BM25: 6.8553, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 13.7591, Релевантность: 5)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. explore (BM25: 8.2644, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. explore (BM25: 7.3500, Релевантность: 4)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "\n",
      "Вопрос: Can the Distance Matrix API be used for clustering similar vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 19.1436, Релевантность: 5)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. collections (BM25: 9.0542, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 5.4621, Релевантность: 3)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 19.1436, Релевантность: 5)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. vectors (BM25: 10.7981, Релевантность: 3)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. collections (BM25: 9.0542, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What types of conditions can you set when filtering points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.9067, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 4.2579, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. payload (BM25: 6.7188, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.1984, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 6.9067, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. payload (BM25: 6.7188, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: What logical operations are available when combining filtering conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 8.7133, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 6.6278, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. hybrid-queries (BM25: 4.9891, Релевантность: 3)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 8.7133, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 6.6278, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 6.3885, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the function of the 'must' clause in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 1.9208, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 1.9208, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What does the 'should' clause do in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 1.9208, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 1.9208, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: How does the 'must_not' clause work in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 5.2575, Релевантность: 5)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "2. filtering (BM25: 6.4321, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. explore (BM25: 1.9878, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 6.4321, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 5.2575, Релевантность: 5)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "3. filtering (BM25: 2.5026, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Вопрос: Can you filter using nested fields in Qdrant, and how?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 9.6050, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 3.8647, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. indexing (BM25: 6.1808, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 9.6050, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 6.1808, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. payload (BM25: 6.0456, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What condition would you use to check if a field has multiple values in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 10.5600, Релевантность: 5)\n",
      "   Example: {{< code-snippet path=\"/documentation/headless/snippets/scroll-points/with-nested-clauses-f...\n",
      "2. payload (BM25: 8.3040, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. payload (BM25: 12.0091, Релевантность: 4)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 12.0091, Релевантность: 4)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. filtering (BM25: 10.5600, Релевантность: 5)\n",
      "   Example: {{< code-snippet path=\"/documentation/headless/snippets/scroll-points/with-nested-clauses-f...\n",
      "3. payload (BM25: 8.3040, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: How can you check if a field exists with no value in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 5.6179, Релевантность: 4)\n",
      "   For example, given the data: json [ { \"id\": 1, \"name\": \"product A\", \"comments\": [\"Very good!\", \"Exce...\n",
      "2. points (BM25: 3.2066, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. payload (BM25: 3.4220, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 6.2341, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. filtering (BM25: 5.6179, Релевантность: 4)\n",
      "   For example, given the data: json [ { \"id\": 1, \"name\": \"product A\", \"comments\": [\"Very good!\", \"Exce...\n",
      "3. indexing (BM25: 4.8405, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What is the purpose of the 'has_id' condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 2.7878, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. points (BM25: 2.4515, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. filtering (BM25: 2.9495, Релевантность: 3)\n",
      "   To retrieve only the points which are matching the conditions on an array element basis, that is the...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 3.1173, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. filtering (BM25: 2.9495, Релевантность: 3)\n",
      "   To retrieve only the points which are matching the conditions on an array element basis, that is the...\n",
      "3. filtering (BM25: 2.7878, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Вопрос: How do you filter records using geographic conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 4.5636, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 5.2804, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. storage (BM25: 4.5026, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 5.9091, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. points (BM25: 5.5228, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. indexing (BM25: 5.2804, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.7530, Релевантность: 2)\n",
      "   word - splits the string into words, separated by spaces, punctuation marks, and special characters....\n",
      "2. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. explore (BM25: 2.7047, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. payload (BM25: 3.2274, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. vectors (BM25: 3.1445, Релевантность: 2)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 3.3168, Релевантность: 2)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. hybrid-queries (BM25: 3.3295, Релевантность: 2)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 7.0638, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 5.0183, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 10.2142, Релевантность: 3)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "3. hybrid-queries (BM25: 2.4480, Релевантность: 2)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 10.2142, Релевантность: 3)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "2. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 6.2248, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. hybrid-queries (BM25: 6.6193, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 6.6193, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7749, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. hybrid-queries (BM25: 5.2734, Релевантность: 4)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. payload (BM25: 7.1816, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 6.6966, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 5.3020, Релевантность: 5)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "2. search (BM25: 5.2531, Релевантность: 3)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. hybrid-queries (BM25: 2.2424, Релевантность: 2)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 5.3020, Релевантность: 5)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "2. search (BM25: 5.2531, Релевантность: 3)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. indexing (BM25: 3.2081, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. search (BM25: 4.1261, Релевантность: 4)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. search (BM25: 4.1261, Релевантность: 4)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 6.9169, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. search (BM25: 6.9169, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. search (BM25: 4.0892, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 4.6817, Релевантность: 2)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.2741, Релевантность: 2)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. vectors (BM25: 5.7799, Релевантность: 2)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.7530, Релевантность: 2)\n",
      "   word - splits the string into words, separated by spaces, punctuation marks, and special characters....\n",
      "2. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. explore (BM25: 2.7047, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. payload (BM25: 3.2274, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. vectors (BM25: 3.1445, Релевантность: 2)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 3.3295, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. search (BM25: 3.3168, Релевантность: 2)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 7.0638, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 5.0183, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 2.4480, Релевантность: 2)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. hybrid-queries (BM25: 10.2142, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 10.2142, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "2. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 6.2248, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. hybrid-queries (BM25: 6.6193, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 6.6193, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7749, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. hybrid-queries (BM25: 5.2734, Релевантность: 4)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. payload (BM25: 7.1816, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 6.6966, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 5.3020, Релевантность: 4)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "2. search (BM25: 5.2531, Релевантность: 3)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. hybrid-queries (BM25: 2.2424, Релевантность: 2)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 5.3020, Релевантность: 4)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "2. search (BM25: 5.2531, Релевантность: 3)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. indexing (BM25: 3.2081, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. search (BM25: 4.1261, Релевантность: 4)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. search (BM25: 4.1261, Релевантность: 4)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 6.9169, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. search (BM25: 6.9169, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. search (BM25: 4.0892, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. payload (BM25: 7.2741, Релевантность: 2)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.2741, Релевантность: 2)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. vectors (BM25: 5.7799, Релевантность: 2)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: Why is it more efficient to apply changes in batches in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 4.7152, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. storage (BM25: 9.6866, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. explore (BM25: 4.1423, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.6866, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. vectors (BM25: 5.3388, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. points (BM25: 4.7152, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Вопрос: What does Qdrant use to handle data changes during segment optimization?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 9.8738, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. optimizer (BM25: 15.9941, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. vectors (BM25: 7.6294, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 15.9941, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. storage (BM25: 9.8738, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. vectors (BM25: 7.6294, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: What is the purpose of the Vacuum Optimizer in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 8.0756, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. vectors (BM25: 2.0798, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.0756, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. vectors (BM25: 2.0798, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: What criteria determine when to trigger the Vacuum Optimizer?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 10.4333, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 5.4687, Релевантность: 4)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "3. optimizer (BM25: 5.4476, Релевантность: 3)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 10.4333, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. collections (BM25: 9.7869, Релевантность: 2)\n",
      "   Grey collection status Available as of v1.9.0 A collection may have the grey ⚫ status or show \"optim...\n",
      "3. optimizer (BM25: 5.4687, Релевантность: 4)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "\n",
      "Вопрос: What does the Merge Optimizer do in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 6.4405, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 8.6262, Релевантность: 5)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "3. vectors (BM25: 2.0798, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.6262, Релевантность: 5)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "2. optimizer (BM25: 6.4405, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: How does the Indexing Optimizer determine when to enable indexes in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 7.5414, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. indexing (BM25: 6.9239, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. collections (BM25: 4.5669, Релевантность: 4)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.8979, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. optimizer (BM25: 7.5414, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. indexing (BM25: 6.9239, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What happens to segments larger than the specified memmap_threshold in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 8.1146, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 7.3632, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. storage (BM25: 6.0142, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.1146, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 7.3632, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. storage (BM25: 6.0142, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Вопрос: What can the user configure in the Qdrant configuration file related to optimizers?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.2347, Релевантность: 5)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. optimizer (BM25: 7.2735, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. optimizer (BM25: 6.4919, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 7.2735, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. optimizer (BM25: 6.4919, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. indexing (BM25: 5.7091, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: Why might a user choose to disable indexing during initial data loading in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 8.6414, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. optimizer (BM25: 13.2349, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. optimizer (BM25: 9.2556, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 13.2349, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. optimizer (BM25: 9.2556, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. collections (BM25: 8.6414, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Вопрос: What is the primary challenge faced by Qdrant regarding deleted records?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 9.0975, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. points (BM25: 2.3196, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. search (BM25: 3.1863, Релевантность: 2)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 9.0975, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. payload (BM25: 7.0204, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. optimizer (BM25: 4.1751, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What is the term used in Qdrant for storing additional information along with vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 12.2243, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 8.9817, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. vectors (BM25: 5.0915, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 12.2243, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 8.9817, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. vectors (BM25: 8.3258, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: What data format does Qdrant allow for the representation of payload information?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 7.5202, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. points (BM25: 3.9124, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "3. payload (BM25: 4.3419, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 9.5342, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. payload (BM25: 7.5202, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. payload (BM25: 4.3419, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: What happens during filtering if the stored value type does not fit the filtering condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 13.9429, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 7.0815, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 11.0662, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 13.9429, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 11.0662, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. points (BM25: 9.8157, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What type of numbers does Qdrant support for integer values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.0567, Релевантность: 5)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "2. vectors (BM25: 6.3962, Релевантность: 2)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. indexing (BM25: 4.3815, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.0567, Релевантность: 5)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "2. vectors (BM25: 6.3962, Релевантность: 2)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. points (BM25: 4.9938, Релевантность: 2)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "\n",
      "Вопрос: What are the two methods to update payloads mentioned in the text?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 6.6745, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. points (BM25: 3.2751, Релевантность: 4)\n",
      "   Upsert points: upsert or UpsertOperation Delete points: delete_points or DeleteOperation Update vect...\n",
      "3. points (BM25: 6.4759, Релевантность: 3)\n",
      "   REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/update-vectors/simple/\" >...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 6.6745, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. points (BM25: 6.4759, Релевантность: 3)\n",
      "   REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/update-vectors/simple/\" >...\n",
      "3. points (BM25: 4.3155, Релевантность: 3)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "\n",
      "Вопрос: Which method is used to remove all payload keys from specified points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 12.5477, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. payload (BM25: 12.5344, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/set-payload/by-filter/\" >}} Available as of ...\n",
      "3. payload (BM25: 8.7402, Релевантность: 4)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 12.7707, Релевантность: 3)\n",
      "   REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/update-vectors/simple/\" >...\n",
      "2. payload (BM25: 12.5477, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. payload (BM25: 12.5344, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/set-payload/by-filter/\" >}} Available as of ...\n",
      "\n",
      "Вопрос: What type of indexing does Qdrant allow for payload fields to improve search efficiency?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 9.5424, Релевантность: 5)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. payload (BM25: 10.7626, Релевантность: 5)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. indexing (BM25: 6.8085, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 10.7626, Релевантность: 5)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. indexing (BM25: 9.5424, Релевантность: 5)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. payload (BM25: 7.7662, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: What is faceting in the context of Qdrant, and what can it be used for?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.4496, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. explore (BM25: 5.9466, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. hybrid-queries (BM25: 2.2207, Релевантность: 2)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.4496, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. explore (BM25: 5.9466, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. search (BM25: 4.1143, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What should you do before using faceting on a field in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 11.3079, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. indexing (BM25: 4.7521, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. payload (BM25: 4.9625, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 11.3079, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. payload (BM25: 5.8962, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. payload (BM25: 4.9625, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What will the response contain when performing a facet count for a field?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 16.2581, Релевантность: 5)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "2. payload (BM25: 16.3856, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "3. indexing (BM25: 2.6535, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 16.3856, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. payload (BM25: 16.2581, Релевантность: 5)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. points (BM25: 8.2393, Релевантность: 2)\n",
      "   Evaluation of results size for faceted search Determining the number of pages for pagination Debuggi...\n",
      "\n",
      "Вопрос: What is the primary function of the Qdrant Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 3.3295, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. search (BM25: 4.3158, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. hybrid-queries (BM25: 3.9914, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 4.3158, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. hybrid-queries (BM25: 3.9914, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. hybrid-queries (BM25: 3.3295, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: Which similarity search method is referred to as k-NN?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.0470, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. explore (BM25: 2.0413, Релевантность: 2)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "3. search (BM25: 6.1102, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 8.0470, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. search (BM25: 6.1102, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. collections (BM25: 4.5917, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What types of metrics does Qdrant support for estimating vector similarity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 13.7283, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. collections (BM25: 11.9817, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. vectors (BM25: 6.4998, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 13.7283, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. collections (BM25: 11.9817, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. vectors (BM25: 9.0193, Релевантность: 3)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Вопрос: What does the 'limit' parameter specify in a search query?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.3058, Релевантность: 5)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "2. search (BM25: 1.9320, Релевантность: 3)\n",
      "   Pagination Search and recommendation APIs allow to skip first results of the search and return only ...\n",
      "3. indexing (BM25: 2.6313, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 4.3058, Релевантность: 5)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "2. search (BM25: 3.8188, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 2.6313, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "\n",
      "Вопрос: In which version of Qdrant is the batch search API available?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 6.5637, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. search (BM25: 2.7350, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. hybrid-queries (BM25: 2.1666, Релевантность: 2)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 6.5637, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. points (BM25: 6.0282, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. vectors (BM25: 4.4039, Релевантность: 2)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Вопрос: How can you filter search results based on a specific payload key using the Qdrant search API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 9.4258, Релевантность: 4)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "2. payload (BM25: 5.3814, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. search (BM25: 6.6428, Релевантность: 4)\n",
      "   Since the filter parameter is specified, the search is performed only among those points that satisf...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 11.8158, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. points (BM25: 9.4258, Релевантность: 4)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. search (BM25: 7.1418, Релевантность: 4)\n",
      "   Example: {{< code-snippet path=\"/documentation/headless/snippets/query-points/with-payload-and-vecto...\n",
      "\n",
      "Вопрос: What is the default scoring metric for sparse queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 14.1910, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. explore (BM25: 4.2856, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. vectors (BM25: 5.1100, Релевантность: 3)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 14.1910, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 6.7486, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "3. search (BM25: 6.3846, Релевантность: 2)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "\n",
      "Вопрос: What is the purpose of the 'with_lookup' parameter in the grouping API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 5.5881, Релевантность: 5)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "2. search (BM25: 7.8625, Релевантность: 5)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "3. search (BM25: 4.1588, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 7.8625, Релевантность: 5)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "2. search (BM25: 6.4168, Релевантность: 2)\n",
      "   Pagination Search and recommendation APIs allow to skip first results of the search and return only ...\n",
      "3. search (BM25: 5.8046, Релевантность: 2)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "\n",
      "Вопрос: What does the 'offset' parameter do when searching with Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 1.3024, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "2. search (BM25: 1.5060, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. indexing (BM25: 1.0961, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 1.5060, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "2. indexing (BM25: 1.4234, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. points (BM25: 1.3024, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is a unique feature of the random sampling API in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.9963, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "2. search (BM25: 7.6751, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. points (BM25: 7.6119, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.9963, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "2. search (BM25: 7.6751, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. points (BM25: 7.6119, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Вопрос: What is a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 2.0096, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. points (BM25: 2.2218, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. filtering (BM25: 1.7833, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 2.2218, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. collections (BM25: 2.0096, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 1.9294, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What identifier types does Qdrant support for points?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 4.5664, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. points (BM25: 6.2612, Релевантность: 3)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. collections (BM25: 4.6373, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 6.2612, Релевантность: 3)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. collections (BM25: 4.6373, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. payload (BM25: 4.5664, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: How can you modify a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 5.8282, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "2. payload (BM25: 4.0977, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. points (BM25: 2.2218, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 6.0762, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/set-payload/by-filter/\" >}} Available as of ...\n",
      "2. points (BM25: 5.8282, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "3. indexing (BM25: 5.3314, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. vectors (BM25: 4.4753, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. collections (BM25: 4.9390, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: Can multiple types of vectors be attached to a single point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 11.0010, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. vectors (BM25: 6.5772, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. points (BM25: 6.6010, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 11.0010, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. collections (BM25: 9.2935, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. points (BM25: 6.6010, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What does the batch loading feature in Qdrant do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 7.5903, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. explore (BM25: 4.1423, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. points (BM25: 2.2404, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 7.5903, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. points (BM25: 5.9151, Релевантность: 4)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. explore (BM25: 4.1423, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: What is the purpose of the update_vectors method in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.3015, Релевантность: 4)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "2. points (BM25: 2.2404, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. payload (BM25: 3.7650, Релевантность: 3)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 3.7650, Релевантность: 3)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. collections (BM25: 2.8594, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 2.5284, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: How does Qdrant handle deleting vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 4.3685, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. optimizer (BM25: 8.8528, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. payload (BM25: 3.0547, Релевантность: 2)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.8528, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. payload (BM25: 5.1885, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. collections (BM25: 4.4609, Релевантность: 2)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Вопрос: What response is received when an API call is made with wait=false in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 14.9439, Релевантность: 5)\n",
      "   The following example snippet makes use of all operations. REST API (Schema): {{< code-snippet path=...\n",
      "2. payload (BM25: 5.7672, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. search (BM25: 2.8926, Релевантность: 2)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 14.9439, Релевантность: 5)\n",
      "   The following example snippet makes use of all operations. REST API (Schema): {{< code-snippet path=...\n",
      "2. payload (BM25: 5.7672, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. points (BM25: 3.5884, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the Scroll API used for in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 8.2893, Релевантность: 5)\n",
      "   The single point can also be retrieved via the API: REST API (Schema): {{< code-snippet path=\"/docum...\n",
      "2. search (BM25: 4.8495, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. search (BM25: 2.9367, Релевантность: 2)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 8.2893, Релевантность: 5)\n",
      "   The single point can also be retrieved via the API: REST API (Schema): {{< code-snippet path=\"/docum...\n",
      "2. search (BM25: 4.8495, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. explore (BM25: 3.8573, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What are snapshots in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 0.4689, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. payload (BM25: 0.5247, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. payload (BM25: 0.5247, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. vectors (BM25: 0.4783, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: How are snapshots created in a distributed deployment?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 1.5513, Релевантность: 2)\n",
      "   Internally, these options do not differ and are made only for the convenience of interaction. Create...\n",
      "2. storage (BM25: 1.8451, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. collections (BM25: 10.4641, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 10.4641, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. collections (BM25: 5.2664, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "\n",
      "Вопрос: What is the purpose of using snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 6.7486, Релевантность: 3)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. indexing (BM25: 1.8013, Релевантность: 3)\n",
      "   Principal Index Available as of v1.11.0 Similar to the tenant index, the principal index is used to ...\n",
      "3. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 6.7486, Релевантность: 3)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. collections (BM25: 1.8275, Релевантность: 2)\n",
      "   Each named vector in this mode has its distance and size: {{< code-snippet path=\"/documentation/head...\n",
      "\n",
      "Вопрос: What is the difference between snapshots and backups in Qdrant Cloud?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. storage (BM25: 1.6579, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 5.6111, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "3. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Вопрос: What does the API endpoint /collections/{collection_name}/snapshots do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 5.0185, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. collections (BM25: 5.5187, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. points (BM25: 3.6899, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 6.2778, Релевантность: 2)\n",
      "   For example, the user could mark some specific search results as irrelevant, or we want to search on...\n",
      "2. collections (BM25: 5.5187, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. points (BM25: 5.0185, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Вопрос: What command is used to list snapshots for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 9.6772, Релевантность: 2)\n",
      "   For example, you can switch underlying collection with the following command: {{< code-snippet path=...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. collections (BM25: 5.7139, Релевантность: 1)\n",
      "   The following command enables indexing for segments that have more than 10000 kB of vectors stored: ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 9.6772, Релевантность: 2)\n",
      "   For example, you can switch underlying collection with the following command: {{< code-snippet path=...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.7486, Релевантность: 1)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Вопрос: What limitations exist when restoring snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 16.3414, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 9.6198, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 5.6111, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 16.3414, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 9.6198, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 8.3318, Релевантность: 2)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: How can you recover a snapshot from a URL?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 18.4029, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 5.4096, Релевантность: 3)\n",
      "   # Bucket region (e.g. eu-central-1) region: your_bucket_region_here\n",
      "\n",
      "# Storage access key # Can be s...\n",
      "3. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 18.4029, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.0582, Релевантность: 2)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: What is the significance of snapshot priority during recovery?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 20.3394, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "3. snapshots (BM25: 4.8099, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 20.3394, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.0582, Релевантность: 1)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: Where are snapshots stored by default?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.6957, Релевантность: 4)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "2. snapshots (BM25: 6.0210, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 9.6350, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 9.6350, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 7.6957, Релевантность: 4)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "3. snapshots (BM25: 6.0210, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Вопрос: What is the structure of data storage within a collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.5046, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 4.7661, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 7.4339, Релевантность: 4)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 7.5046, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. indexing (BM25: 7.4339, Релевантность: 4)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "3. storage (BM25: 4.7661, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: What types of segments are there in Qdrant, and what operations can be performed on them?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 5.3322, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. optimizer (BM25: 7.9314, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. points (BM25: 3.9939, Релевантность: 4)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.6232, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. optimizer (BM25: 7.9314, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. storage (BM25: 5.3322, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What is the difference between in-memory storage and memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 12.5578, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 11.3333, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. optimizer (BM25: 13.4819, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 16.6942, Релевантность: 3)\n",
      "   With sufficient RAM, it is almost as fast as in-memory storage. Configuring Memmap storage There are...\n",
      "2. optimizer (BM25: 13.4819, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 12.5578, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What parameter is used to configure memmap storage for vectors during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 13.8406, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 9.6760, Релевантность: 5)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. storage (BM25: 9.8900, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 13.8406, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 11.5136, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. collections (BM25: 10.7060, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Вопрос: What is the recommended approach for using memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 10.0219, Релевантность: 5)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. optimizer (BM25: 9.2003, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 8.6518, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 10.0219, Релевантность: 5)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. optimizer (BM25: 9.2003, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 8.6518, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: How does Qdrant handle the versioning of data and ensure data integrity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 17.1389, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. points (BM25: 5.2740, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. optimizer (BM25: 5.8280, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 17.1389, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. optimizer (BM25: 5.8280, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. points (BM25: 5.2740, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What types of payload storage does Qdrant support, and what are their characteristics?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.4630, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 5.0280, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. payload (BM25: 3.4133, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 7.4630, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 5.0280, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. payload (BM25: 4.0831, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: What should be done if large payload values are attached in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 8.3367, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. payload (BM25: 2.5046, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. payload (BM25: 2.7522, Релевантность: 3)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.3367, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. search (BM25: 3.8931, Релевантность: 2)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. collections (BM25: 2.8329, Релевантность: 3)\n",
      "   Each named vector in this mode has its distance and size: {{< code-snippet path=\"/documentation/head...\n",
      "\n",
      "Вопрос: What configuration parameter is used to specify the type of payload storage during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 10.8914, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. storage (BM25: 11.0561, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 7.0541, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 11.0561, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 10.8914, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. storage (BM25: 8.7018, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Вопрос: What is the purpose of the memmap_threshold option in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 3.8049, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 8.2835, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. optimizer (BM25: 3.2696, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.2835, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. storage (BM25: 3.8049, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. optimizer (BM25: 3.2696, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What are vectors in the context of Qdrant Vector Search engine?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.7150, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 4.7846, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. explore (BM25: 7.6994, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 7.7150, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. explore (BM25: 7.6994, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. indexing (BM25: 7.0692, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: How does a vector representation relate to the similarity of objects?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 11.6458, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. collections (BM25: 3.9776, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 10.3046, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 11.6458, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. search (BM25: 10.3046, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. vectors (BM25: 9.3341, Релевантность: 3)\n",
      "   Multiple representation of the same object - For example, you can store multiple embeddings for pict...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. collections (BM25: 3.3267, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. collections (BM25: 4.9390, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What is the difference between dense vectors and sparse vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 12.2252, Релевантность: 5)\n",
      "   It looks like this: ```json // A piece of a real-world dense vector [ -0.013052909, 0.020387933, -0....\n",
      "2. points (BM25: 11.0384, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "3. collections (BM25: 12.0111, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 13.5084, Релевантность: 2)\n",
      "   There is a difference in how Uint8 vectors are handled for dense and sparse vectors. Dense vectors a...\n",
      "2. vectors (BM25: 12.2252, Релевантность: 5)\n",
      "   It looks like this: ```json // A piece of a real-world dense vector [ -0.013052909, 0.020387933, -0....\n",
      "3. collections (BM25: 12.0111, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Вопрос: What configuration must be set to create a collection with sparse vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 10.4859, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. indexing (BM25: 8.8826, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "3. indexing (BM25: 8.5180, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 10.4859, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. indexing (BM25: 8.8826, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "3. indexing (BM25: 8.5180, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: What are multivectors and what scenarios are they useful in?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 10.4006, Релевантность: 4)\n",
      "   To create a collection with sparse vectors: {{< code-snippet path=\"/documentation/headless/snippets/...\n",
      "2. points (BM25: 4.1124, Релевантность: 4)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. vectors (BM25: 7.7166, Релевантность: 3)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 10.4006, Релевантность: 4)\n",
      "   To create a collection with sparse vectors: {{< code-snippet path=\"/documentation/headless/snippets/...\n",
      "2. vectors (BM25: 7.7166, Релевантность: 3)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. explore (BM25: 4.5276, Релевантность: 2)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Вопрос: What datatype is used by default for vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 10.2729, Релевантность: 5)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "2. collections (BM25: 8.5777, Релевантность: 5)\n",
      "   Each named vector in this mode has its distance and size: {{< code-snippet path=\"/documentation/head...\n",
      "3. explore (BM25: 4.8230, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 10.2729, Релевантность: 5)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "2. collections (BM25: 8.5777, Релевантность: 5)\n",
      "   Each named vector in this mode has its distance and size: {{< code-snippet path=\"/documentation/head...\n",
      "3. vectors (BM25: 7.5085, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: How does Qdrant optimize memory usage for large-dimensionality vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 3.9300, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. vectors (BM25: 6.3952, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "3. collections (BM25: 4.3391, Релевантность: 4)\n",
      "   Each named vector in this mode has its distance and size: {{< code-snippet path=\"/documentation/head...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.4527, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. vectors (BM25: 6.3952, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "3. collections (BM25: 4.5314, Релевантность: 3)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Вопрос: What is the purpose of quantization in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 5.7756, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. collections (BM25: 2.4435, Релевантность: 4)\n",
      "   Each named vector in this mode has its distance and size: {{< code-snippet path=\"/documentation/head...\n",
      "3. hybrid-queries (BM25: 3.1370, Релевантность: 4)\n",
      "   First, use a smaller and cheaper representation to get a large list of candidates. Then, re-score th...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 5.7756, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. collections (BM25: 3.8183, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. hybrid-queries (BM25: 3.1370, Релевантность: 4)\n",
      "   First, use a smaller and cheaper representation to get a large list of candidates. Then, re-score th...\n",
      "\n",
      "Вопрос: What trade-offs must be considered when using different storage options in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 9.5951, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 4.9955, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. vectors (BM25: 8.0490, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.5951, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. vectors (BM25: 8.0490, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. collections (BM25: 6.1852, Релевантность: 2)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "Результаты сохранены в bge_reranker_results.csv\n",
      "\n",
      "Начало оценки только BM25 (без реранкера) для сравнения...\n",
      "Оценка BM25 для top_4...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 823\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 765\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_values:\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОценка BM25 для top_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 765\u001b[0m     k_metrics, k_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation_bm25_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_questions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;66;03m# Добавляем префикс к метрикам\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m k_metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[1], line 751\u001b[0m, in \u001b[0;36mmain.<locals>.run_evaluation_bm25_only\u001b[1;34m(api_key, test_questions, top_k)\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m    750\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 751\u001b[0m         relevance_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_relevance_with_claude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m         result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfragments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((text, name, score, relevance_score))\n\u001b[0;32m    754\u001b[0m retrieval_results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[1], line 344\u001b[0m, in \u001b[0;36mevaluate_relevance_with_claude\u001b[1;34m(question, fragment_text, api_key)\u001b[0m\n\u001b[0;32m    337\u001b[0m request_json \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: api_key\n\u001b[0;32m    340\u001b[0m }\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# Отправляем запрос и дожидаемся ответа\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# Проверяем, отправился ли запрос\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import ndcg_score\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "# Явная установка директории для загрузки NLTK данных\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Загрузка необходимых ресурсов NLTK с явным указанием пути\n",
    "try:\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('stopwords', download_dir=nltk_data_dir, quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    print(\"Не удалось загрузить ресурсы NLTK. Используем упрощенную токенизацию.\")\n",
    "    \n",
    "    # Упрощенная имплементация токенизации без зависимостей NLTK\n",
    "    def word_tokenize(text):\n",
    "        \"\"\"Простая токенизация по пробелам и пунктуации\"\"\"\n",
    "        # Заменяем пунктуацию на пробелы\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ')\n",
    "        # Разбиваем по пробелам и фильтруем пустые токены\n",
    "        return [token for token in text.lower().split() if token]\n",
    "    \n",
    "    # Пустой набор стоп-слов\n",
    "    stop_words = set()\n",
    "    \n",
    "    # Упрощенный стеммер\n",
    "    class SimplePorterStemmer:\n",
    "        \"\"\"Очень упрощенная версия стеммера - убирает только окончания -ing, -ed, -s\"\"\"\n",
    "        def stem(self, word):\n",
    "            if word.endswith('ing'):\n",
    "                return word[:-3]\n",
    "            elif word.endswith('ed') and len(word) > 3:\n",
    "                return word[:-2]\n",
    "            elif word.endswith('s') and len(word) > 2:\n",
    "                return word[:-1]\n",
    "            return word\n",
    "    \n",
    "    PorterStemmer = SimplePorterStemmer\n",
    "\n",
    "# Класс для реранкинга с использованием модели BGE Reranker\n",
    "class BGEReranker:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            print(\"Инициализация BGE реранкера...\")\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-base\")\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-base\").to(self.device)\n",
    "            self.model.eval()\n",
    "            print(f\"BGE реранкер успешно инициализирован (устройство: {self.device})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации BGE реранкера: {e}\")\n",
    "            raise\n",
    "\n",
    "    def rerank(self, query, documents, fragment_scores, max_seq_length=512):\n",
    "        \"\"\"\n",
    "        Переранжирует документы с использованием BGE Reranker модели.\n",
    "        \n",
    "        Args:\n",
    "            query: Текст запроса\n",
    "            documents: Список текстов документов\n",
    "            fragment_scores: Исходные оценки документов (из BM25)\n",
    "            max_seq_length: Максимальная длина последовательности для токенизатора\n",
    "            \n",
    "        Returns:\n",
    "            Список кортежей (документ, исходная_оценка, новая_оценка)\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return []\n",
    "\n",
    "        # Подготовка входных данных\n",
    "        inputs = []\n",
    "        for doc in documents:\n",
    "            # Обрезаем документы, чтобы избежать слишком длинных последовательностей\n",
    "            tokenized = self.tokenizer.encode_plus(\n",
    "                query, \n",
    "                doc, \n",
    "                add_special_tokens=True,\n",
    "                max_length=max_seq_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            inputs.append(tokenized)\n",
    "\n",
    "        # Получение предсказаний\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for input_dict in inputs:\n",
    "                input_dict = {k: v.to(self.device) for k, v in input_dict.items()}\n",
    "                output = self.model(**input_dict)\n",
    "                # BGE Reranker выдает скор релевантности как один скаляр\n",
    "                score = output.logits[0].item()\n",
    "                scores.append(score)\n",
    "\n",
    "        # Комбинирование результатов с исходными документами и оценками\n",
    "        ranked_results = list(zip(documents, fragment_scores, scores))\n",
    "        \n",
    "        # Сортировка по убыванию нового скора\n",
    "        ranked_results = sorted(ranked_results, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        return ranked_results\n",
    "\n",
    "class DocumentationQA_BM25:\n",
    "    def __init__(self):\n",
    "        self.bm25 = None\n",
    "        self.doc_paragraphs = []\n",
    "        self.tokenized_corpus = []\n",
    "        self.md_list = [\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/collections.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/explore.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/filtering.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/hybrid-queries.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/indexing.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/optimizer.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/payload.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/search.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/points.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/snapshots.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/storage.md',\n",
    "            'https://raw.githubusercontent.com/qdrant/landing_page/master/qdrant-landing/content/documentation/concepts/vectors.md'\n",
    "        ]\n",
    "        # Использование переменных из глобального контекста\n",
    "        self.stop_words = stop_words\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Предобработка текста: токенизация, удаление стоп-слов и стемминг\"\"\"\n",
    "        # Токенизация и приведение к нижнему регистру\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        # Удаление пунктуации и цифр\n",
    "        tokens = [token for token in tokens if token not in string.punctuation and not token.isdigit()]\n",
    "        # Удаление стоп-слов\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        # Стемминг\n",
    "        try:\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка стемминга: {e}. Пропускаем этап стемминга.\")\n",
    "        return tokens\n",
    "\n",
    "    def extract_text_from_md(self, url, max_characters=1500, new_after_n_chars=1000, overlap=0):\n",
    "        \"\"\"Извлечение текста из Markdown файла и разбиение на параграфы\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            html_content = markdown.markdown(response.text)\n",
    "            soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "            text = soup.get_text()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении документа {url}: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Разделение на смысловые элементы\n",
    "        raw_paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "        paragraphs = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for p in raw_paragraphs:\n",
    "            # Нормализация пробелов\n",
    "            cleaned_p = re.sub(r'\\s+', ' ', p).strip()\n",
    "            \n",
    "            # Пропуск слишком коротких фрагментов\n",
    "            if len(cleaned_p.split()) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Определение, является ли текущий параграф заголовком\n",
    "            is_title = len(cleaned_p.split()) < 10 and not cleaned_p.endswith(('.', '?', '!'))\n",
    "            \n",
    "            # Если новый параграф - заголовок или текущий чанк станет слишком большим\n",
    "            if is_title or len(current_chunk) + len(cleaned_p) > new_after_n_chars:\n",
    "                # Сохранение предыдущего чанка, если он не пустой\n",
    "                if current_chunk:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "            \n",
    "            # Если параграф слишком большой, разбиваем его на части\n",
    "            if len(cleaned_p) > max_characters:\n",
    "                # Разбиение на предложения\n",
    "                sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', cleaned_p)\n",
    "                \n",
    "                sentence_chunk = \"\"\n",
    "                for sentence in sentences:\n",
    "                    if len(sentence_chunk) + len(sentence) > max_characters:\n",
    "                        paragraphs.append(sentence_chunk)\n",
    "                        # Добавление перекрытия, если задано\n",
    "                        if overlap > 0:\n",
    "                            words = sentence_chunk.split()\n",
    "                            overlap_text = ' '.join(words[-min(len(words), overlap//5):])\n",
    "                            sentence_chunk = overlap_text + \" \" + sentence\n",
    "                        else:\n",
    "                            sentence_chunk = sentence\n",
    "                    else:\n",
    "                        sentence_chunk = (sentence_chunk + \" \" + sentence).strip() if sentence_chunk else sentence\n",
    "                \n",
    "                if sentence_chunk:\n",
    "                    paragraphs.append(sentence_chunk)\n",
    "            else:\n",
    "                # Добавление параграфа к текущему чанку\n",
    "                current_chunk = (current_chunk + \"\\n\\n\" + cleaned_p).strip() if current_chunk else cleaned_p\n",
    "                \n",
    "                # Если чанк превысил максимальный размер, сохраняем его\n",
    "                if len(current_chunk) > max_characters:\n",
    "                    paragraphs.append(current_chunk)\n",
    "                    current_chunk = \"\"\n",
    "        \n",
    "        # Добавление последнего чанка, если он не пустой\n",
    "        if current_chunk:\n",
    "            paragraphs.append(current_chunk)\n",
    "        \n",
    "        return paragraphs\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"Инициализация базы данных: загрузка и предобработка документов\"\"\"\n",
    "        # Обработка всех документов\n",
    "        self.doc_paragraphs = []\n",
    "        for url in self.md_list:\n",
    "            paragraphs = self.extract_text_from_md(url)\n",
    "            name = url.split('concepts/')[1].split('.md')[0]\n",
    "\n",
    "            if name == 'collections':\n",
    "                paragraphs = [p for p in paragraphs if '/ Collections' not in p]\n",
    "            else:\n",
    "                paragraphs = [p for p in paragraphs if f'/{name}' not in p]\n",
    "\n",
    "            for paragraph in paragraphs:\n",
    "                self.doc_paragraphs.append({\n",
    "                    'name': name,\n",
    "                    'text': paragraph\n",
    "                })\n",
    "        \n",
    "        print(f\"Всего загружено {len(self.doc_paragraphs)} фрагментов.\")\n",
    "        \n",
    "        if not self.doc_paragraphs:\n",
    "            raise ValueError(\"Не удалось загрузить ни одного документа!\")\n",
    "        \n",
    "        # Токенизация и предобработка текстовых фрагментов для BM25\n",
    "        print(\"Начинаем токенизацию и предобработку текста...\")\n",
    "        self.tokenized_corpus = [self.preprocess_text(doc['text']) for doc in self.doc_paragraphs]\n",
    "        \n",
    "        # Проверка на пустые токенизированные документы\n",
    "        non_empty_docs = [(i, doc) for i, doc in enumerate(self.tokenized_corpus) if doc]\n",
    "        if len(non_empty_docs) < len(self.tokenized_corpus):\n",
    "            print(f\"Внимание: {len(self.tokenized_corpus) - len(non_empty_docs)} документов не содержат токенов после предобработки.\")\n",
    "            \n",
    "            # Отфильтровываем пустые документы\n",
    "            valid_indices = [i for i, _ in non_empty_docs]\n",
    "            self.tokenized_corpus = [self.tokenized_corpus[i] for i in valid_indices]\n",
    "            self.doc_paragraphs = [self.doc_paragraphs[i] for i in valid_indices]\n",
    "        \n",
    "        # Инициализация BM25\n",
    "        print(\"Инициализация BM25...\")\n",
    "        try:\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            print(f\"BM25 успешно инициализирован. Всего документов: {len(self.tokenized_corpus)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации BM25: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search_similar_paragraphs(self, user_query, top_k=20):\n",
    "        \"\"\"Поиск похожих параграфов с использованием BM25\"\"\"\n",
    "        if not self.bm25:\n",
    "            print(\"Ошибка: BM25 не инициализирован!\")\n",
    "            return []\n",
    "            \n",
    "        # Предобработка запроса\n",
    "        tokenized_query = self.preprocess_text(user_query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            print(\"Предупреждение: запрос не содержит значимых токенов после предобработки!\")\n",
    "            return []\n",
    "                # Получение BM25 scores для всех документов\n",
    "        try:\n",
    "            scores = self.bm25.get_scores(tokenized_query)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении оценок BM25: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Индексы документов с наивысшими оценками\n",
    "        top_n = np.argsort(scores)[::-1][:top_k]\n",
    "        \n",
    "        # Возвращение текста, имени документа и оценки BM25\n",
    "        results = []\n",
    "        for i in top_n:\n",
    "            if scores[i] > 0:  # Добавление только если оценка больше 0\n",
    "                results.append((self.doc_paragraphs[i]['text'], self.doc_paragraphs[i]['name'], float(scores[i])))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Функция для оценки релевантности с использованием API\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    \"\"\"Оценивает релевантность фрагмента к вопросу через API Claude\"\"\"\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    # Ограничиваем длину фрагмента для запроса\n",
    "    max_fragment_length = 4000\n",
    "    if len(fragment_text) > max_fragment_length:\n",
    "        fragment_text = fragment_text[:max_fragment_length] + \"...\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "def get_relevant_fragments_with_reranker(qa_system, reranker, question, initial_top_k=20, final_top_k=6):\n",
    "    \"\"\"\n",
    "    Получение релевантных фрагментов с использованием BM25 и последующего реранкинга\n",
    "    \n",
    "    Args:\n",
    "        qa_system: Экземпляр системы BM25\n",
    "        reranker: Экземпляр реранкера\n",
    "        question: Текст вопроса\n",
    "        initial_top_k: Количество фрагментов, получаемых из BM25\n",
    "        final_top_k: Количество фрагментов после реранкинга\n",
    "    \n",
    "    Returns:\n",
    "        Список отсортированных по релевантности фрагментов\n",
    "    \"\"\"\n",
    "    # Получаем исходные фрагменты с помощью BM25\n",
    "    initial_fragments = qa_system.search_similar_paragraphs(question, top_k=initial_top_k)\n",
    "    \n",
    "    if not initial_fragments:\n",
    "        print(f\"Предупреждение: BM25 не нашел фрагментов для запроса '{question}'\")\n",
    "        return []\n",
    "    \n",
    "    # Разделяем фрагменты на составляющие для реранкера\n",
    "    texts = [fragment[0] for fragment in initial_fragments]\n",
    "    names = [fragment[1] for fragment in initial_fragments]\n",
    "    scores = [fragment[2] for fragment in initial_fragments]\n",
    "    \n",
    "    # Применяем реранкер\n",
    "    try:\n",
    "        reranked_fragments = reranker.rerank(question, texts, scores)\n",
    "        \n",
    "        # Ограничиваем количество возвращаемых фрагментов\n",
    "        reranked_fragments = reranked_fragments[:final_top_k]\n",
    "        \n",
    "        # Восстанавливаем формат результатов с именами документов\n",
    "        result_fragments = [(text, names[texts.index(text)], orig_score, rerank_score) \n",
    "                           for text, orig_score, rerank_score in reranked_fragments]\n",
    "        \n",
    "        return result_fragments\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при реранкинге: {e}\")\n",
    "        # В случае ошибки возвращаем исходные результаты BM25\n",
    "        return [(text, name, score, 0.0) for text, name, score in initial_fragments[:final_top_k]]\n",
    "\n",
    "def calculate_metrics(retrieval_results, k_values=[4, 6]):\n",
    "    \"\"\"\n",
    "    Вычисление метрик эффективности ретривала для разных значений k\n",
    "    \n",
    "    Args:\n",
    "        retrieval_results: Результаты ретривала\n",
    "        k_values: Список значений k для вычисления метрик\n",
    "    \n",
    "    Returns:\n",
    "        Словарь метрик\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Инициализация метрик для всех значений k\n",
    "    for k in k_values:\n",
    "        metrics.update({\n",
    "            f'recall@{k}': [],\n",
    "            f'precision@{k}': [],\n",
    "            f'mrr@{k}': [],\n",
    "            f'ndcg@{k}': []\n",
    "        })\n",
    "    \n",
    "    # Добавляем recall@1 и precision@1\n",
    "    metrics['recall@1'] = []\n",
    "    metrics['precision@1'] = []\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        if not fragments:\n",
    "            print(f\"Предупреждение: для вопроса '{result['question']}' не найдено фрагментов\")\n",
    "            # Пропускаем вычисление метрик для этого запроса\n",
    "            continue\n",
    "            \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1 if len(retrieved_fragments) >= 1 else 0)\n",
    "            \n",
    "            # Для каждого значения k вычисляем метрики\n",
    "            for k in k_values:\n",
    "                # Recall@k\n",
    "                relevant_at_k = sum(1 for f in retrieved_fragments[:min(k, len(retrieved_fragments))] if f[3] >= 4)\n",
    "                metrics[f'recall@{k}'].append(relevant_at_k / total_relevant)\n",
    "                \n",
    "                # Precision@k\n",
    "                metrics[f'precision@{k}'].append(relevant_at_k / min(k, len(retrieved_fragments)))\n",
    "                \n",
    "                # MRR@k (Mean Reciprocal Rank)\n",
    "                first_relevant_rank = next((i + 1 for i, f in enumerate(retrieved_fragments[:min(k, len(retrieved_fragments))]) if f[3] >= 4), 0)\n",
    "                if first_relevant_rank > 0:\n",
    "                    metrics[f'mrr@{k}'].append(1.0 / first_relevant_rank)\n",
    "                else:\n",
    "                    metrics[f'mrr@{k}'].append(0.0)\n",
    "                \n",
    "                # nDCG@k\n",
    "                if len(sorted_fragments) >= 1 and len(retrieved_fragments) >= 1:\n",
    "                    # Определяем количество документов для оценки\n",
    "                    k_actual = min(k, len(sorted_fragments), len(retrieved_fragments))\n",
    "                    \n",
    "                    # Берем только первые k_actual документов\n",
    "                    true_relevance = np.array([f[3] for f in sorted_fragments[:k_actual]])\n",
    "                    predicted_order_relevance = np.array([f[3] for f in retrieved_fragments[:k_actual]])\n",
    "                    \n",
    "                    try:\n",
    "                        ndcg = ndcg_score([true_relevance], [predicted_order_relevance])\n",
    "                        metrics[f'ndcg@{k}'].append(ndcg)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Ошибка при вычислении nDCG@{k}: {e}\")\n",
    "                        metrics[f'ndcg@{k}'].append(0.0)\n",
    "                else:\n",
    "                    metrics[f'ndcg@{k}'].append(0.0)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            \n",
    "            for k in k_values:\n",
    "                metrics[f'recall@{k}'].append(1.0)\n",
    "                metrics[f'precision@{k}'].append(0.0)\n",
    "                metrics[f'mrr@{k}'].append(0.0)\n",
    "                metrics[f'ndcg@{k}'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "def run_evaluation_with_reranker(api_key, test_questions, k_values=[4, 6]):\n",
    "    \"\"\"\n",
    "    Запуск оценки системы с BM25 и реранкером на наборе тестовых вопросов\n",
    "    \n",
    "    Args:\n",
    "        api_key: API ключ для оценки релевантности\n",
    "        test_questions: Список тестовых вопросов\n",
    "        k_values: Список значений k для оценки\n",
    "    \n",
    "    Returns:\n",
    "        Метрики и результаты оценки\n",
    "    \"\"\"\n",
    "    # Инициализация системы BM25\n",
    "    qa_system = DocumentationQA_BM25()\n",
    "    qa_system.initialize_database()\n",
    "    \n",
    "    # Инициализация реранкера\n",
    "    reranker = TinyBertReranker()\n",
    "    \n",
    "    # Результаты для последующей оценки\n",
    "    retrieval_results = []\n",
    "    \n",
    "    # Обработка каждого вопроса\n",
    "    for question in test_questions:\n",
    "        # Получение фрагментов с помощью BM25 и реранкера\n",
    "        # Базовая модель отбирает 20 фрагментов, затем реранкер выбирает лучшие\n",
    "        max_k = max(k_values)  # Максимальное k из запрошенных\n",
    "        reranked_fragments = get_relevant_fragments_with_reranker(\n",
    "            qa_system, reranker, question, initial_top_k=20, final_top_k=max_k\n",
    "        )\n",
    "        \n",
    "        # Результаты для текущего вопроса\n",
    "        result = {'question': question, 'fragments': []}\n",
    "        \n",
    "        # Оценка релевантности для каждого фрагмента\n",
    "        for text, name, bm25_score, rerank_score in reranked_fragments:\n",
    "            # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "            result['fragments'].append((text, name, bm25_score, relevance_score))\n",
    "        \n",
    "        retrieval_results.append(result)\n",
    "    \n",
    "    # Отдельные метрики для каждого значения k\n",
    "    metrics_results = {}\n",
    "    for k in k_values:\n",
    "        # Для каждого k создаем копию результатов, но ограничиваем количество фрагментов до k\n",
    "        k_results = []\n",
    "        for result in retrieval_results:\n",
    "            k_result = {\n",
    "                'question': result['question'],\n",
    "                'fragments': result['fragments'][:k] if result['fragments'] else []\n",
    "            }\n",
    "            k_results.append(k_result)\n",
    "        \n",
    "        # Вычисление метрик для текущего k\n",
    "        k_metrics = calculate_metrics(k_results, [k])\n",
    "        metrics_results[f'top_{k}'] = k_metrics\n",
    "    \n",
    "    # Объединение всех метрик\n",
    "    combined_metrics = {}\n",
    "    for k, metrics in metrics_results.items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            combined_metrics[f\"{k}_{metric_name}\"] = value\n",
    "    \n",
    "    return combined_metrics, retrieval_results\n",
    "\n",
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"Сохранение результатов в CSV файл\"\"\"\n",
    "    rows = []\n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        for text, name, bm25_score, relevance in result['fragments']:\n",
    "            rows.append({\n",
    "                'question': question,\n",
    "                'document': name,\n",
    "                'bm25_score': bm25_score,\n",
    "                'relevance_score': relevance,\n",
    "                'text': text[:200]  # Ограничиваем длину текста для CSV\n",
    "            })\n",
    "    \n",
    "        df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Результаты сохранены в {filename}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "        \n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "        \n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "        \n",
    "        # Определяем значения k для оценки\n",
    "        k_values = [4, 6]\n",
    "        \n",
    "        # Запуск оценки системы с BGE реранкером\n",
    "        print(\"Начало оценки системы с BM25 и реранкером BGE...\")\n",
    "        \n",
    "        # Инициализация QA системы с BM25\n",
    "        qa_system = DocumentationQA_BM25()\n",
    "        qa_system.initialize_database()\n",
    "        \n",
    "        # Инициализация BGE реранкера\n",
    "        reranker = BGEReranker()\n",
    "        \n",
    "        # Результаты для последующей оценки\n",
    "        retrieval_results = []\n",
    "        \n",
    "        # Обработка каждого вопроса\n",
    "        for question in test_questions:\n",
    "            # Получение фрагментов с помощью BM25 и реранкера\n",
    "            # Базовая модель отбирает 20 фрагментов, затем реранкер выбирает лучшие\n",
    "            max_k = max(k_values)  # Максимальное k из запрошенных\n",
    "            reranked_fragments = get_relevant_fragments_with_reranker(\n",
    "                qa_system, reranker, question, initial_top_k=20, final_top_k=max_k\n",
    "            )\n",
    "            \n",
    "            # Результаты для текущего вопроса\n",
    "            result = {'question': question, 'fragments': []}\n",
    "            \n",
    "            # Оценка релевантности для каждого фрагмента\n",
    "            for text, name, bm25_score, rerank_score in reranked_fragments:\n",
    "                # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "                time.sleep(2)\n",
    "                relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                result['fragments'].append((text, name, bm25_score, relevance_score))\n",
    "            \n",
    "            retrieval_results.append(result)\n",
    "        \n",
    "        # Отдельные метрики для каждого значения k\n",
    "        metrics_results = {}\n",
    "        for k in k_values:\n",
    "            # Для каждого k создаем копию результатов, но ограничиваем количество фрагментов до k\n",
    "            k_results = []\n",
    "            for result in retrieval_results:\n",
    "                k_result = {\n",
    "                    'question': result['question'],\n",
    "                    'fragments': result['fragments'][:k] if result['fragments'] else []\n",
    "                }\n",
    "                k_results.append(k_result)\n",
    "            \n",
    "            # Вычисление метрик для текущего k\n",
    "            k_metrics = calculate_metrics(k_results, [k])\n",
    "            metrics_results[f'top_{k}'] = k_metrics\n",
    "        \n",
    "        # Объединение всех метрик\n",
    "        metrics = {}\n",
    "        for k, k_metrics in metrics_results.items():\n",
    "            for metric_name, value in k_metrics.items():\n",
    "                metrics[f\"{k}_{metric_name}\"] = value\n",
    "        \n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки системы с BGE реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in retrieval_results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            \n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "                \n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "            \n",
    "            # Сортировка по BM25\n",
    "            sorted_by_bm25 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по BM25:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_bm25[:min(3, len(sorted_by_bm25))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "        \n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(retrieval_results, \"bge_reranker_results.csv\")\n",
    "        \n",
    "        # Проведем сравнение с исходной версией без реранкера\n",
    "        print(\"\\nНачало оценки только BM25 (без реранкера) для сравнения...\")\n",
    "        \n",
    "        # Функция для оценки BM25 без реранкера\n",
    "        def run_evaluation_bm25_only(api_key, test_questions, top_k):\n",
    "            \"\"\"Запуск оценки только BM25 системы на наборе тестовых вопросов\"\"\"\n",
    "            # Инициализация системы BM25\n",
    "            qa_system = DocumentationQA_BM25()\n",
    "            qa_system.initialize_database()\n",
    "            \n",
    "            # Результаты для последующей оценки\n",
    "            retrieval_results = []\n",
    "            \n",
    "            # Обработка каждого вопроса\n",
    "            for question in test_questions:\n",
    "                # Получение фрагментов с помощью BM25\n",
    "                fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "                \n",
    "                # Результаты для текущего вопроса\n",
    "                result = {'question': question, 'fragments': []}\n",
    "                \n",
    "                # Оценка релевантности для каждого фрагмента\n",
    "                for text, name, score in fragments:\n",
    "                    # Используем сохраненные оценки релевантности, если есть\n",
    "                    found = False\n",
    "                    for r in retrieval_results:\n",
    "                        if r['question'] == question:\n",
    "                            for t, n, _, rel_score in r['fragments']:\n",
    "                                if t == text and n == name:\n",
    "                                    result['fragments'].append((text, name, score, rel_score))\n",
    "                                    found = True\n",
    "                                    break\n",
    "                        if found:\n",
    "                            break\n",
    "                    \n",
    "                    # Если не нашли сохраненную оценку, запрашиваем новую\n",
    "                    if not found:\n",
    "                        time.sleep(2)\n",
    "                        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                        result['fragments'].append((text, name, score, relevance_score))\n",
    "                \n",
    "                retrieval_results.append(result)\n",
    "            \n",
    "            # Вычисление метрик\n",
    "            metrics_results = calculate_metrics(retrieval_results, k_values)\n",
    "            \n",
    "            return metrics_results, retrieval_results\n",
    "        \n",
    "        # Запускаем оценку BM25 отдельно для каждого значения k\n",
    "        bm25_metrics = {}\n",
    "        for k in k_values:\n",
    "            print(f\"Оценка BM25 для top_{k}...\")\n",
    "            k_metrics, k_results = run_evaluation_bm25_only(api_key, test_questions, k)\n",
    "            \n",
    "            # Добавляем префикс к метрикам\n",
    "            for metric, value in k_metrics.items():\n",
    "                if f\"@{k}\" in metric:  # Добавляем только метрики для текущего k\n",
    "                    bm25_metrics[f\"top_{k}_{metric}\"] = value\n",
    "            \n",
    "            # Сохраняем результаты BM25\n",
    "            save_results_to_csv(k_results, f\"bm25_only_top{k}_results.csv\")\n",
    "        \n",
    "        # Сравнение метрик\n",
    "        print(\"\\nСравнение метрик BM25 и BM25+BGE:\")\n",
    "        print(\"{:<20} {:<15} {:<15}\".format(\"Метрика\", \"BM25\", \"BM25+BGE\"))\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                \n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    \n",
    "                    print(\"{:<20} {:<15.4f} {:<15.4f}\".format(\n",
    "                        bm25_key, bm25_value, reranker_value\n",
    "                    ))\n",
    "        \n",
    "        # Анализ улучшений\n",
    "        total_improvements = 0\n",
    "        total_metrics = 0\n",
    "        \n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                \n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    \n",
    "                    if reranker_value > bm25_value:\n",
    "                        total_improvements += 1\n",
    "                    \n",
    "                    total_metrics += 1\n",
    "        \n",
    "        if total_metrics > 0:\n",
    "            improvement_percentage = (total_improvements / total_metrics) * 100\n",
    "            print(f\"\\nРеранкер BGE улучшил {total_improvements} из {total_metrics} метрик ({improvement_percentage:.2f}%)\")\n",
    "        \n",
    "        return metrics, retrieval_results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало оценки системы с BM25 и реранкером CrossEncoder MS Marco MiniLM...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n",
      "Инициализация CrossEncoder реранкера (cross-encoder/ms-marco-MiniLM-L-12-v2)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bcf784d74a4e34928a85a1fc561761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sekho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sekho\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4300538114c747e0957d4e3718ab352c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79d0ccf46274574b07cbaa19a054a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3691a9b07246f590d9462eb477fa4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042f0f8707724fd4aed3e540bb34b359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec43d23bf60491cbca754f03019aa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/732 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEncoder реранкер успешно инициализирован\n",
      "\n",
      "Результаты оценки системы с CrossEncoder MS Marco реранкером:\n",
      "top_4_recall@4: 1.0000\n",
      "top_4_precision@4: 0.4458\n",
      "top_4_mrr@4: 0.7576\n",
      "top_4_ndcg@4: 0.8143\n",
      "top_4_recall@1: 0.5590\n",
      "top_4_precision@1: 0.6917\n",
      "top_6_recall@6: 1.0000\n",
      "top_6_precision@6: 0.3903\n",
      "top_6_mrr@6: 0.7565\n",
      "top_6_ndcg@6: 0.8275\n",
      "top_6_recall@1: 0.4601\n",
      "top_6_precision@1: 0.6750\n",
      "\n",
      "Детальный анализ результатов:\n",
      "\n",
      "Вопрос: What is a collection in the context of Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 1.0890, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 1.0226, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. indexing (BM25: 1.1448, Релевантность: 3)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 1.2770, Релевантность: 3)\n",
      "   Grey collection status Available as of v1.9.0 A collection may have the grey ⚫ status or show \"optim...\n",
      "2. indexing (BM25: 1.1448, Релевантность: 3)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "3. collections (BM25: 1.0890, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What must be true about the dimensionality of vectors within a single collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 15.5227, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. vectors (BM25: 7.6818, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "3. collections (BM25: 9.3378, Релевантность: 3)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 15.5227, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. collections (BM25: 9.3378, Релевантность: 3)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. vectors (BM25: 7.6818, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Вопрос: How does Qdrant support different metrics for comparing vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 12.4336, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 5.9917, Релевантность: 4)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. vectors (BM25: 8.1823, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 12.4336, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. vectors (BM25: 8.1823, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. indexing (BM25: 6.1398, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: When should multiple collections be created instead of just one?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 3.9666, Релевантность: 5)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "2. explore (BM25: 5.0853, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "3. vectors (BM25: 3.5607, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.9305, Релевантность: 2)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "2. collections (BM25: 5.2275, Релевантность: 3)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. explore (BM25: 5.0853, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Вопрос: What are some parameters that can be tuned for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 1.9562, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "2. optimizer (BM25: 1.7396, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. collections (BM25: 5.6781, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.6781, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. collections (BM25: 1.9562, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. collections (BM25: 1.9499, Релевантность: 4)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: What happens if different types of vectors are used within a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 6.9553, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. collections (BM25: 8.5023, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. collections (BM25: 5.4498, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.6464, Релевантность: 4)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. collections (BM25: 8.5023, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. collections (BM25: 7.2396, Релевантность: 2)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "\n",
      "Вопрос: How can the existence of a collection in Qdrant be checked?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 5.1198, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. collections (BM25: 1.2770, Релевантность: 3)\n",
      "   Grey collection status Available as of v1.9.0 A collection may have the grey ⚫ status or show \"optim...\n",
      "3. collections (BM25: 3.8758, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.1198, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. collections (BM25: 3.8758, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. points (BM25: 3.6280, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What is the purpose of the payload in vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.4534, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 2.3978, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. collections (BM25: 2.4824, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 2.5731, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. vectors (BM25: 2.5246, Релевантность: 3)\n",
      "   Multiple representation of the same object - For example, you can store multiple embeddings for pict...\n",
      "3. collections (BM25: 2.4824, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: Can collections be updated after their creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 3.8210, Релевантность: 5)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. collections (BM25: 2.8290, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. collections (BM25: 2.4183, Релевантность: 3)\n",
      "   If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 5.6827, Релевантность: 2)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 5.5801, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. collections (BM25: 3.8210, Релевантность: 5)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: How does the choice of metric influence search results in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.7689, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. search (BM25: 5.9068, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. collections (BM25: 8.8186, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 8.8186, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 8.7689, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. search (BM25: 5.9068, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What Stack of APIs does Qdrant provide for data exploration?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 12.3530, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. points (BM25: 6.1248, Релевантность: 3)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. search (BM25: 6.9773, Релевантность: 3)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 12.3530, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. search (BM25: 6.9773, Релевантность: 3)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. points (BM25: 6.1248, Релевантность: 3)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Вопрос: How does the Recommendation API enhance the search functionality?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 4.8602, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 5.0539, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. explore (BM25: 2.8507, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 8.2409, Релевантность: 2)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "2. explore (BM25: 5.0539, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. explore (BM25: 4.8602, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the default strategy for recommendations in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 7.9926, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 8.4780, Релевантность: 5)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "3. explore (BM25: 4.4195, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 8.4780, Релевантность: 5)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "2. explore (BM25: 7.9926, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 4.4195, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: What is the purpose of the 'best_score' strategy introduced in Qdrant v1.6.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 11.1105, Релевантность: 5)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "2. explore (BM25: 3.2545, Релевантность: 4)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "3. explore (BM25: 4.8864, Релевантность: 3)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 11.1105, Релевантность: 5)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "2. explore (BM25: 4.8864, Релевантность: 3)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "3. explore (BM25: 3.9300, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: How can users find the most dissimilar vectors using only negative examples?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 19.6720, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. explore (BM25: 11.5217, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 10.7737, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 19.6720, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. explore (BM25: 11.5217, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 10.7737, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "\n",
      "Вопрос: What can be specified in the recommendation request when a collection is created with multiple vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 12.7135, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. search (BM25: 5.9639, Релевантность: 5)\n",
      "   Since the filter parameter is specified, the search is performed only among those points that satisf...\n",
      "3. vectors (BM25: 6.4691, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 12.7135, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. collections (BM25: 8.4182, Релевантность: 3)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "3. collections (BM25: 7.8676, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Вопрос: What is the function of the 'lookup_from' parameter in the recommendation request?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 6.8864, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "2. search (BM25: 3.1316, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. explore (BM25: 5.2026, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.0831, Релевантность: 1)\n",
      "   We can directly associate the score function to a loss function, where 0.0 is the maximum score a po...\n",
      "2. explore (BM25: 6.8864, Релевантность: 5)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "3. explore (BM25: 5.2026, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: How does the Discovery API differ from the Recommendation API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 9.3817, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. explore (BM25: 7.5201, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 9.2109, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 9.3817, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. explore (BM25: 9.2109, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. explore (BM25: 7.5201, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the significance of using a context in Discovery search?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 13.7591, Релевантность: 5)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. explore (BM25: 8.2644, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. search (BM25: 6.8553, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 13.7591, Релевантность: 5)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. explore (BM25: 8.2644, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "3. explore (BM25: 7.3500, Релевантность: 4)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "\n",
      "Вопрос: Can the Distance Matrix API be used for clustering similar vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 19.1436, Релевантность: 5)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. collections (BM25: 9.0542, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. vectors (BM25: 8.6176, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 19.1436, Релевантность: 5)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. vectors (BM25: 10.7981, Релевантность: 3)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. collections (BM25: 9.0542, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What types of conditions can you set when filtering points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.9067, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 4.2579, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. indexing (BM25: 7.1984, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.1984, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 6.9067, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. payload (BM25: 6.7188, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: What logical operations are available when combining filtering conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 8.7133, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 6.6278, Релевантность: 3)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. hybrid-queries (BM25: 4.9891, Релевантность: 3)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 8.7133, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 6.6278, Релевантность: 3)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 6.3885, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the function of the 'must' clause in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.2904, Релевантность: 4)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "3. indexing (BM25: 1.9208, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.2904, Релевантность: 4)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "3. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: What does the 'should' clause do in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.2904, Релевантность: 5)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "2. filtering (BM25: 7.5931, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. points (BM25: 1.6317, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 6.2904, Релевантность: 5)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "3. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: How does the 'must_not' clause work in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 5.2575, Релевантность: 5)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "2. filtering (BM25: 6.4321, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. indexing (BM25: 2.1870, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 6.4321, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. filtering (BM25: 5.2575, Релевантность: 5)\n",
      "   In this sense, must is equivalent to the operator AND. Should Example: {{< code-snippet path=\"/docum...\n",
      "3. search (BM25: 2.6515, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: Can you filter using nested fields in Qdrant, and how?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 3.8647, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 9.6050, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 6.1808, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 9.6050, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 6.1808, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. payload (BM25: 6.0456, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What condition would you use to check if a field has multiple values in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.3040, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. payload (BM25: 5.5626, Релевантность: 4)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "3. indexing (BM25: 6.1713, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 8.9518, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. payload (BM25: 8.3040, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 7.6190, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: How can you check if a field exists with no value in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 3.2066, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "2. payload (BM25: 3.4220, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. indexing (BM25: 4.8405, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.6284, Релевантность: 2)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. indexing (BM25: 4.8405, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 4.2623, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What is the purpose of the 'has_id' condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 2.7878, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. points (BM25: 2.4515, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. payload (BM25: 3.1173, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 3.1173, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 2.9911, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. filtering (BM25: 2.7878, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Вопрос: How do you filter records using geographic conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 4.5636, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 4.8513, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 5.2804, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 5.5228, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "2. payload (BM25: 5.3497, Релевантность: 3)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 5.2804, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. payload (BM25: 3.2274, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 4.2904, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. indexing (BM25: 4.0014, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "3. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 3.2111, Релевантность: 3)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. search (BM25: 5.0183, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 7.0638, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 5.0183, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 10.2142, Релевантность: 3)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "3. hybrid-queries (BM25: 2.4480, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 10.2142, Релевантность: 3)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "2. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 6.2248, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 6.6193, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 6.6193, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7415, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. indexing (BM25: 4.7749, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. payload (BM25: 7.1816, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 6.6966, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 2.6706, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 2.3794, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 3.2081, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. search (BM25: 2.6706, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. explore (BM25: 4.1107, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. collections (BM25: 6.7948, Релевантность: 1)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. hybrid-queries (BM25: 6.5588, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. hybrid-queries (BM25: 6.5588, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. search (BM25: 4.0892, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. vectors (BM25: 5.7799, Релевантность: 2)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. optimizer (BM25: 6.2815, Релевантность: 1)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. vectors (BM25: 5.7799, Релевантность: 2)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. explore (BM25: 7.7615, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. payload (BM25: 3.2274, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 4.2904, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. indexing (BM25: 4.0014, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "3. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 5.0183, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. search (BM25: 7.0638, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 12.3266, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 7.0638, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 5.0183, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 2.4480, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. hybrid-queries (BM25: 10.2142, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 10.2142, Релевантность: 2)\n",
      "   Distribution-Based Score Fusion (available as of v1.11.0)\n",
      "\n",
      "Normalizes the scores of the points in ea...\n",
      "2. hybrid-queries (BM25: 7.6531, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 6.2248, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 6.6193, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 6.6193, Релевантность: 5)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 5.4690, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. hybrid-queries (BM25: 4.1378, Релевантность: 5)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7415, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. indexing (BM25: 4.7749, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.2882, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. payload (BM25: 7.1816, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 6.6966, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 2.6706, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 2.3794, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 3.2081, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. search (BM25: 2.6706, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. explore (BM25: 4.1107, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 8.1620, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. collections (BM25: 6.7948, Релевантность: 1)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. search (BM25: 4.4203, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. explore (BM25: 9.0057, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. hybrid-queries (BM25: 6.5588, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.9170, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. explore (BM25: 9.0057, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. hybrid-queries (BM25: 6.5588, Релевантность: 3)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. search (BM25: 4.0892, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. optimizer (BM25: 6.2815, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 6.9551, Релевантность: 2)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "2. optimizer (BM25: 6.2815, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. vectors (BM25: 5.7799, Релевантность: 2)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "2. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. hybrid-queries (BM25: 13.7354, Релевантность: 4)\n",
      "   To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, s...\n",
      "2. search (BM25: 13.6844, Релевантность: 5)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: Why is it more efficient to apply changes in batches in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 4.7152, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. storage (BM25: 9.6866, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. optimizer (BM25: 3.3958, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.6866, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. indexing (BM25: 5.4162, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. vectors (BM25: 5.3388, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: What does Qdrant use to handle data changes during segment optimization?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 9.8738, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. optimizer (BM25: 15.9941, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. collections (BM25: 7.5650, Релевантность: 4)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 15.9941, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. storage (BM25: 9.8738, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. vectors (BM25: 7.6294, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: What is the purpose of the Vacuum Optimizer in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 8.0756, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. collections (BM25: 2.9358, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. optimizer (BM25: 2.7303, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.0756, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. collections (BM25: 2.9358, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Вопрос: What criteria determine when to trigger the Vacuum Optimizer?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 10.4333, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 5.4687, Релевантность: 4)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "3. optimizer (BM25: 5.4476, Релевантность: 3)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 10.4333, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. collections (BM25: 9.7869, Релевантность: 2)\n",
      "   Grey collection status Available as of v1.9.0 A collection may have the grey ⚫ status or show \"optim...\n",
      "3. optimizer (BM25: 5.4687, Релевантность: 4)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "\n",
      "Вопрос: What does the Merge Optimizer do in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 8.6262, Релевантность: 5)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "2. optimizer (BM25: 6.4405, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. collections (BM25: 2.9358, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.6262, Релевантность: 5)\n",
      "   On the other hand, too many small segments lead to suboptimal search performance. The merge optimize...\n",
      "2. optimizer (BM25: 6.4405, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: How does the Indexing Optimizer determine when to enable indexes in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 7.5414, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. indexing (BM25: 6.9239, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. collections (BM25: 4.5669, Релевантность: 4)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.8979, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. optimizer (BM25: 7.5414, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. indexing (BM25: 6.9239, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What happens to segments larger than the specified memmap_threshold in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 8.1146, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 7.3632, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. storage (BM25: 6.0142, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.1146, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 7.3632, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. storage (BM25: 6.0142, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Вопрос: What can the user configure in the Qdrant configuration file related to optimizers?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 7.2735, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. optimizer (BM25: 6.4919, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. indexing (BM25: 5.7091, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 7.4965, Релевантность: 3)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. optimizer (BM25: 7.2735, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. optimizer (BM25: 6.4919, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Вопрос: Why might a user choose to disable indexing during initial data loading in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 13.2349, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. collections (BM25: 8.6414, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "3. optimizer (BM25: 9.2556, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 13.2349, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. optimizer (BM25: 9.2556, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. collections (BM25: 8.6414, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Вопрос: What is the primary challenge faced by Qdrant regarding deleted records?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 9.0975, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. collections (BM25: 2.6373, Релевантность: 4)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. points (BM25: 2.3196, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 9.0975, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. optimizer (BM25: 4.1751, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 3.2376, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What is the term used in Qdrant for storing additional information along with vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 12.2243, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 8.9817, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 9.4711, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 12.2243, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 9.4711, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. indexing (BM25: 8.9817, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What data format does Qdrant allow for the representation of payload information?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 7.5202, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. payload (BM25: 4.3419, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. indexing (BM25: 4.2530, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 9.5342, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. payload (BM25: 7.5202, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 6.4896, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Вопрос: What happens during filtering if the stored value type does not fit the filtering condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 13.9429, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 11.0662, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. indexing (BM25: 7.0815, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 13.9429, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 11.0662, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. points (BM25: 9.8157, Релевантность: 2)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Вопрос: What type of numbers does Qdrant support for integer values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.0567, Релевантность: 5)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "2. payload (BM25: 4.0506, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. points (BM25: 5.7109, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.0567, Релевантность: 5)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "2. points (BM25: 5.7109, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. optimizer (BM25: 4.6569, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What are the two methods to update payloads mentioned in the text?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 6.6745, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. points (BM25: 3.2751, Релевантность: 4)\n",
      "   Upsert points: upsert or UpsertOperation Delete points: delete_points or DeleteOperation Update vect...\n",
      "3. points (BM25: 5.3294, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 6.6745, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. points (BM25: 6.4759, Релевантность: 3)\n",
      "   REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/update-vectors/simple/\" >...\n",
      "3. storage (BM25: 5.4671, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: Which method is used to remove all payload keys from specified points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 12.5477, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. payload (BM25: 12.5344, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/set-payload/by-filter/\" >}} Available as of ...\n",
      "3. payload (BM25: 8.7402, Релевантность: 4)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 12.5477, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. payload (BM25: 12.5344, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/set-payload/by-filter/\" >}} Available as of ...\n",
      "3. payload (BM25: 8.7402, Релевантность: 4)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What type of indexing does Qdrant allow for payload fields to improve search efficiency?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.8085, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 9.5424, Релевантность: 5)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. payload (BM25: 10.7626, Релевантность: 5)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 10.7626, Релевантность: 5)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. indexing (BM25: 9.5424, Релевантность: 5)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. indexing (BM25: 6.8085, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What is faceting in the context of Qdrant, and what can it be used for?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.4496, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. indexing (BM25: 2.0987, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. explore (BM25: 1.9859, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.4496, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. explore (BM25: 7.8942, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. vectors (BM25: 2.3286, Релевантность: 1)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Вопрос: What should you do before using faceting on a field in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 11.3079, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. indexing (BM25: 4.7521, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 4.1221, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 11.3079, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. payload (BM25: 4.9625, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. indexing (BM25: 4.8149, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What will the response contain when performing a facet count for a field?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 16.2581, Релевантность: 5)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "2. payload (BM25: 16.3856, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "3. points (BM25: 8.2393, Релевантность: 2)\n",
      "   Evaluation of results size for faceted search Determining the number of pages for pagination Debuggi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 16.3856, Релевантность: 5)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. payload (BM25: 16.2581, Релевантность: 5)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. points (BM25: 8.2393, Релевантность: 2)\n",
      "   Evaluation of results size for faceted search Determining the number of pages for pagination Debuggi...\n",
      "\n",
      "Вопрос: What is the primary function of the Qdrant Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 3.9914, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "2. search (BM25: 4.3158, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. search (BM25: 3.8669, Релевантность: 4)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 4.3158, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. hybrid-queries (BM25: 3.9914, Релевантность: 4)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 3.8669, Релевантность: 4)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "\n",
      "Вопрос: Which similarity search method is referred to as k-NN?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 8.0470, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. search (BM25: 6.1102, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. search (BM25: 3.6996, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 8.0470, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. search (BM25: 6.1102, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. search (BM25: 3.6996, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What types of metrics does Qdrant support for estimating vector similarity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 11.9817, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 13.7283, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. vectors (BM25: 6.4998, Релевантность: 4)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 13.7283, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. collections (BM25: 11.9817, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 10.0473, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What does the 'limit' parameter specify in a search query?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.3058, Релевантность: 5)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "2. search (BM25: 1.9320, Релевантность: 3)\n",
      "   Pagination Search and recommendation APIs allow to skip first results of the search and return only ...\n",
      "3. search (BM25: 3.8188, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 4.3058, Релевантность: 5)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "2. search (BM25: 3.8188, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. search (BM25: 3.4880, Релевантность: 2)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "\n",
      "Вопрос: In which version of Qdrant is the batch search API available?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 6.5637, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. search (BM25: 2.7350, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. explore (BM25: 2.7719, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 6.5637, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "2. points (BM25: 6.0282, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. indexing (BM25: 4.4784, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Вопрос: How can you filter search results based on a specific payload key using the Qdrant search API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 8.0163, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. points (BM25: 9.4258, Релевантность: 4)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. payload (BM25: 5.3814, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 11.8158, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. points (BM25: 9.4258, Релевантность: 4)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "3. payload (BM25: 8.9155, Релевантность: 3)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "\n",
      "Вопрос: What is the default scoring metric for sparse queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 14.1910, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 5.1822, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. indexing (BM25: 6.7486, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 14.1910, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 6.7486, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "3. search (BM25: 6.3846, Релевантность: 2)\n",
      "   All the regular attributes of a search request are of course available. {{< code-snippet path=\"/docu...\n",
      "\n",
      "Вопрос: What is the purpose of the 'with_lookup' parameter in the grouping API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 7.8625, Релевантность: 5)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "2. search (BM25: 5.5881, Релевантность: 5)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "3. search (BM25: 4.1588, Релевантность: 4)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 7.8625, Релевантность: 5)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "2. search (BM25: 6.4168, Релевантность: 2)\n",
      "   Pagination Search and recommendation APIs allow to skip first results of the search and return only ...\n",
      "3. search (BM25: 5.5881, Релевантность: 5)\n",
      "   Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or...\n",
      "\n",
      "Вопрос: What does the 'offset' parameter do when searching with Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 1.3024, Релевантность: 3)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "2. hybrid-queries (BM25: 1.1522, Релевантность: 2)\n",
      "   Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of many named vectors p...\n",
      "3. search (BM25: 1.3451, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 1.5299, Релевантность: 2)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. search (BM25: 1.5060, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "3. search (BM25: 1.3451, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What is a unique feature of the random sampling API in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 9.9963, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "2. search (BM25: 7.6751, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. explore (BM25: 11.1001, Релевантность: 4)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 11.1001, Релевантность: 4)\n",
      "   Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance bet...\n",
      "2. search (BM25: 9.9963, Релевантность: 5)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "3. search (BM25: 7.6751, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2783, Релевантность: 4)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. collections (BM25: 2.4240, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "3. points (BM25: 2.2218, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 2.4240, Релевантность: 3)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "2. points (BM25: 2.2783, Релевантность: 4)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. points (BM25: 2.2218, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What identifier types does Qdrant support for points?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 4.5664, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. points (BM25: 6.2612, Релевантность: 3)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. payload (BM25: 2.9425, Релевантность: 2)\n",
      "   Let's look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 6.2612, Релевантность: 3)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. collections (BM25: 4.6373, Релевантность: 2)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. payload (BM25: 4.5664, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: How can you modify a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 5.8282, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "2. points (BM25: 2.2218, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. payload (BM25: 4.0977, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 5.8282, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "2. payload (BM25: 4.0977, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. collections (BM25: 2.4240, Релевантность: 2)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. collections (BM25: 3.3267, Релевантность: 5)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. collections (BM25: 4.9390, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: Can multiple types of vectors be attached to a single point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 11.0010, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. points (BM25: 6.6010, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. vectors (BM25: 6.5772, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 11.0010, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. collections (BM25: 9.2935, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. points (BM25: 6.6010, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What does the batch loading feature in Qdrant do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 7.5903, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. points (BM25: 2.2404, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. explore (BM25: 4.1423, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 7.5903, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. points (BM25: 5.9151, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. explore (BM25: 4.1423, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: What is the purpose of the update_vectors method in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2404, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. points (BM25: 2.3015, Релевантность: 4)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "3. collections (BM25: 0.5229, Релевантность: 2)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 2.3015, Релевантность: 4)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "2. points (BM25: 2.2404, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. points (BM25: 0.5720, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Вопрос: How does Qdrant handle deleting vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 8.8528, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. points (BM25: 4.3685, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. storage (BM25: 4.9409, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 8.8528, Релевантность: 5)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "2. payload (BM25: 5.1885, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. storage (BM25: 4.9409, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What response is received when an API call is made with wait=false in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 14.9439, Релевантность: 5)\n",
      "   The following example snippet makes use of all operations. REST API (Schema): {{< code-snippet path=...\n",
      "2. collections (BM25: 3.5351, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. payload (BM25: 5.7672, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 14.9439, Релевантность: 5)\n",
      "   The following example snippet makes use of all operations. REST API (Schema): {{< code-snippet path=...\n",
      "2. payload (BM25: 5.7672, Релевантность: 2)\n",
      "   REST API (Facet) {{< code-snippet path=\"/documentation/headless/snippets/facet-counts/simple-with-fi...\n",
      "3. explore (BM25: 4.6776, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the Scroll API used for in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 3.8573, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. points (BM25: 3.0208, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. explore (BM25: 2.9218, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 3.8573, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. payload (BM25: 3.7415, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. points (BM25: 3.0208, Релевантность: 2)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "\n",
      "Вопрос: What are snapshots in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. payload (BM25: 0.5247, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. indexing (BM25: 0.4689, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. payload (BM25: 0.5247, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. vectors (BM25: 0.4773, Релевантность: 1)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Вопрос: How are snapshots created in a distributed deployment?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 6.0582, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "2. collections (BM25: 10.4641, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "3. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 10.4641, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.0582, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: What is the purpose of using snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 6.7486, Релевантность: 3)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 7.1910, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 7.1910, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "3. snapshots (BM25: 6.7486, Релевантность: 3)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Вопрос: What is the difference between snapshots and backups in Qdrant Cloud?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. collections (BM25: 2.0031, Релевантность: 1)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 5.2536, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. collections (BM25: 2.0031, Релевантность: 1)\n",
      "   The above counts are not exact, but should be considered approximate. Depending on how you use Qdran...\n",
      "\n",
      "Вопрос: What does the API endpoint /collections/{collection_name}/snapshots do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 5.5187, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. points (BM25: 3.6899, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. storage (BM25: 1.3570, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.5187, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. points (BM25: 5.0185, Релевантность: 1)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. points (BM25: 3.6899, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What command is used to list snapshots for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 9.6772, Релевантность: 2)\n",
      "   For example, you can switch underlying collection with the following command: {{< code-snippet path=...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 7.1910, Релевантность: 2)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 9.6772, Релевантность: 2)\n",
      "   For example, you can switch underlying collection with the following command: {{< code-snippet path=...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 7.1910, Релевантность: 2)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: What limitations exist when restoring snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 16.3414, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 8.3318, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "3. storage (BM25: 3.6208, Релевантность: 3)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 16.3414, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 9.6198, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "3. snapshots (BM25: 8.3318, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: How can you recover a snapshot from a URL?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 18.4029, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 5.4096, Релевантность: 3)\n",
      "   # Bucket region (e.g. eu-central-1) region: your_bucket_region_here\n",
      "\n",
      "# Storage access key # Can be s...\n",
      "3. snapshots (BM25: 5.6111, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 18.4029, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.0582, Релевантность: 2)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: What is the significance of snapshot priority during recovery?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 20.3394, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "3. snapshots (BM25: 4.8099, Релевантность: 2)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 20.3394, Релевантность: 2)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.0582, Релевантность: 1)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: Where are snapshots stored by default?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.6957, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "2. snapshots (BM25: 9.6350, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. optimizer (BM25: 3.1172, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 9.6350, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. snapshots (BM25: 8.1684, Релевантность: 1)\n",
      "   The default priority may not be best for all situations. The available snapshot recovery priorities ...\n",
      "3. snapshots (BM25: 7.6957, Релевантность: 3)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: What is the structure of data storage within a collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.5046, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 4.7661, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. storage (BM25: 4.8401, Релевантность: 4)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 8.6337, Релевантность: 3)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. storage (BM25: 7.5046, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 7.4339, Релевантность: 4)\n",
      "   Vector Index A vector index is a data structure built on vectors through a specific mathematical mod...\n",
      "\n",
      "Вопрос: What types of segments are there in Qdrant, and what operations can be performed on them?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 5.3322, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 8.6232, Релевантность: 4)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. optimizer (BM25: 7.9314, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.6232, Релевантность: 4)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. optimizer (BM25: 7.9314, Релевантность: 4)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. storage (BM25: 5.3322, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What is the difference between in-memory storage and memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 11.3333, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 12.5578, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. optimizer (BM25: 13.4819, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 16.6942, Релевантность: 3)\n",
      "   With sufficient RAM, it is almost as fast as in-memory storage. Configuring Memmap storage There are...\n",
      "2. optimizer (BM25: 13.4819, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 12.5578, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What parameter is used to configure memmap storage for vectors during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 13.8406, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. collections (BM25: 10.7060, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "3. storage (BM25: 9.6760, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 13.8406, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 11.5136, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. collections (BM25: 10.7060, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Вопрос: What is the recommended approach for using memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 10.0219, Релевантность: 5)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. optimizer (BM25: 9.2003, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 8.6518, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 10.0219, Релевантность: 5)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. optimizer (BM25: 9.2003, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "3. storage (BM25: 8.6518, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: How does Qdrant handle the versioning of data and ensure data integrity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 17.1389, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. points (BM25: 5.2740, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. optimizer (BM25: 5.8280, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 17.1389, Релевантность: 5)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "2. indexing (BM25: 6.7065, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "3. optimizer (BM25: 5.8280, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Вопрос: What types of payload storage does Qdrant support, and what are their characteristics?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.4630, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 5.0280, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. payload (BM25: 3.4133, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 7.4630, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 5.0280, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 4.7926, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What should be done if large payload values are attached in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 8.3367, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. payload (BM25: 2.5046, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. search (BM25: 4.3934, Релевантность: 4)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.3367, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. search (BM25: 4.3934, Релевантность: 4)\n",
      "   Only keyword and integer payload values are supported for the group_by parameter. Payload values wit...\n",
      "3. search (BM25: 3.8931, Релевантность: 2)\n",
      "   json { \"result\": { \"groups\": [ { \"id\": 1, \"hits\": [ { \"id\": 0, \"score\": 0.91 }, { \"id\": 1, \"score\": ...\n",
      "\n",
      "Вопрос: What configuration parameter is used to specify the type of payload storage during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 11.0561, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 10.8914, Релевантность: 4)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. collections (BM25: 6.4346, Релевантность: 4)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 11.0561, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 10.8914, Релевантность: 4)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. storage (BM25: 8.7018, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Вопрос: What is the purpose of the memmap_threshold option in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 3.2696, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. storage (BM25: 3.8049, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. storage (BM25: 8.2835, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.2835, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. storage (BM25: 3.8049, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. optimizer (BM25: 3.2696, Релевантность: 5)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: What are vectors in the context of Qdrant Vector Search engine?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 7.7150, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 4.7846, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. explore (BM25: 9.1646, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 9.1646, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. vectors (BM25: 7.7150, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. explore (BM25: 7.6994, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/query-points-explore/recommend-lookup-from/\"...\n",
      "\n",
      "Вопрос: How does a vector representation relate to the similarity of objects?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 11.6458, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. collections (BM25: 3.9776, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. search (BM25: 10.3046, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 11.6458, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. search (BM25: 10.3046, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. vectors (BM25: 9.3341, Релевантность: 3)\n",
      "   Multiple representation of the same object - For example, you can store multiple embeddings for pict...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "3. vectors (BM25: 4.4753, Релевантность: 5)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 6.6364, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. vectors (BM25: 6.3942, Релевантность: 5)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. collections (BM25: 4.9390, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "\n",
      "Вопрос: What is the difference between dense vectors and sparse vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 11.0384, Релевантность: 5)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "2. vectors (BM25: 12.2252, Релевантность: 5)\n",
      "   It looks like this: ```json // A piece of a real-world dense vector [ -0.013052909, 0.020387933, -0....\n",
      "3. collections (BM25: 12.0111, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 13.5084, Релевантность: 3)\n",
      "   There is a difference in how Uint8 vectors are handled for dense and sparse vectors. Dense vectors a...\n",
      "2. vectors (BM25: 12.2252, Релевантность: 5)\n",
      "   It looks like this: ```json // A piece of a real-world dense vector [ -0.013052909, 0.020387933, -0....\n",
      "3. collections (BM25: 12.0111, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "\n",
      "Вопрос: What configuration must be set to create a collection with sparse vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 10.4859, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. indexing (BM25: 8.8826, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "3. vectors (BM25: 7.4755, Релевантность: 3)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 10.4859, Релевантность: 4)\n",
      "   Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-clas...\n",
      "2. indexing (BM25: 8.8826, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "3. collections (BM25: 8.1771, Релевантность: 2)\n",
      "   Default parameters for the optional collection parameters are defined in configuration file. See sch...\n",
      "\n",
      "Вопрос: What are multivectors and what scenarios are they useful in?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 10.4006, Релевантность: 4)\n",
      "   To create a collection with sparse vectors: {{< code-snippet path=\"/documentation/headless/snippets/...\n",
      "2. vectors (BM25: 7.7166, Релевантность: 3)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. explore (BM25: 4.5276, Релевантность: 2)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 10.4006, Релевантность: 4)\n",
      "   To create a collection with sparse vectors: {{< code-snippet path=\"/documentation/headless/snippets/...\n",
      "2. vectors (BM25: 7.7166, Релевантность: 3)\n",
      "   In order to use multivectors, we need to specify a function that will be used to compare between mat...\n",
      "3. explore (BM25: 4.5276, Релевантность: 2)\n",
      "   To use this algorithm, you need to set \"strategy\": \"best_score\" in the recommendation request. Using...\n",
      "\n",
      "Вопрос: What datatype is used by default for vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 10.2729, Релевантность: 5)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "2. explore (BM25: 4.8230, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. optimizer (BM25: 5.6560, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 10.2729, Релевантность: 5)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "2. vectors (BM25: 7.5085, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. optimizer (BM25: 5.6560, Релевантность: 2)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "\n",
      "Вопрос: How does Qdrant optimize memory usage for large-dimensionality vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 4.5897, Релевантность: 4)\n",
      "   ``` Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used...\n",
      "2. indexing (BM25: 7.4527, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "3. vectors (BM25: 3.9300, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.4527, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. optimizer (BM25: 6.4027, Релевантность: 3)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. vectors (BM25: 6.3952, Релевантность: 4)\n",
      "   To create a collection with named vectors, you need to specify a configuration for each vector: {{< ...\n",
      "\n",
      "Вопрос: What is the purpose of quantization in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 5.7756, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. collections (BM25: 3.8183, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. collections (BM25: 3.7295, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 5.7756, Релевантность: 5)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "2. collections (BM25: 3.8183, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. collections (BM25: 3.7295, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: What trade-offs must be considered when using different storage options in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 9.5951, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 4.9955, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. vectors (BM25: 8.0490, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.5951, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. vectors (BM25: 8.0490, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. indexing (BM25: 6.5892, Релевантность: 3)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "Результаты сохранены в cross_encoder_msmarco_reranker_results.csv\n",
      "\n",
      "Начало оценки только BM25 (без реранкера) для сравнения...\n",
      "Оценка BM25 для top_4...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 267\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 267\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 209\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_values:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОценка BM25 для top_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 209\u001b[0m     k_metrics, k_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation_bm25_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_questions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# Добавляем префикс к метрикам\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m k_metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[2], line 195\u001b[0m, in \u001b[0;36mmain.<locals>.run_evaluation_bm25_only\u001b[1;34m(api_key, test_questions, top_k)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m    194\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m         relevance_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_relevance_with_claude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m         result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfragments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((text, name, score, relevance_score))\n\u001b[0;32m    198\u001b[0m retrieval_results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[1], line 344\u001b[0m, in \u001b[0;36mevaluate_relevance_with_claude\u001b[1;34m(question, fragment_text, api_key)\u001b[0m\n\u001b[0;32m    337\u001b[0m request_json \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: api_key\n\u001b[0;32m    340\u001b[0m }\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# Отправляем запрос и дожидаемся ответа\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# Проверяем, отправился ли запрос\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Класс для реранкинга с использованием CrossEncoder модели\n",
    "class CrossEncoderReranker:\n",
    "    def __init__(self, model_name=\"cross-encoder/ms-marco-MiniLM-L-12-v2\"):\n",
    "        try:\n",
    "            print(f\"Инициализация CrossEncoder реранкера ({model_name})...\")\n",
    "            from sentence_transformers import CrossEncoder\n",
    "            self.model = CrossEncoder(model_name)\n",
    "            print(f\"CrossEncoder реранкер успешно инициализирован\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации CrossEncoder реранкера: {e}\")\n",
    "            raise\n",
    "\n",
    "    def rerank(self, query, documents, fragment_scores, batch_size=32):\n",
    "        \"\"\"\n",
    "        Переранжирует документы с использованием CrossEncoder модели.\n",
    "        \n",
    "        Args:\n",
    "            query: Текст запроса\n",
    "            documents: Список текстов документов\n",
    "            fragment_scores: Исходные оценки документов (из BM25)\n",
    "            batch_size: Размер батча для инференса\n",
    "            \n",
    "        Returns:\n",
    "            Список кортежей (документ, исходная_оценка, новая_оценка)\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return []\n",
    "\n",
    "        # Подготовка входных данных в формате для CrossEncoder\n",
    "        sentence_pairs = [[query, doc] for doc in documents]\n",
    "        \n",
    "        # Получение предсказаний\n",
    "        try:\n",
    "            scores = self.model.predict(sentence_pairs, batch_size=batch_size)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении предсказаний от CrossEncoder: {e}\")\n",
    "            # В случае ошибки возвращаем исходные результаты\n",
    "            return list(zip(documents, fragment_scores, fragment_scores))\n",
    "\n",
    "        # Комбинирование результатов с исходными документами и оценками\n",
    "        ranked_results = list(zip(documents, fragment_scores, scores))\n",
    "        \n",
    "        # Сортировка по убыванию нового скора\n",
    "        ranked_results = sorted(ranked_results, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        return ranked_results\n",
    "    \n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "        \n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "        \n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "        \n",
    "        # Определяем значения k для оценки\n",
    "        k_values = [4, 6]\n",
    "        \n",
    "        # Запуск оценки системы с CrossEncoder реранкером\n",
    "        print(\"Начало оценки системы с BM25 и реранкером CrossEncoder MS Marco MiniLM...\")\n",
    "        \n",
    "        # Инициализация QA системы с BM25\n",
    "        qa_system = DocumentationQA_BM25()\n",
    "        qa_system.initialize_database()\n",
    "        \n",
    "        # Инициализация CrossEncoder реранкера\n",
    "        reranker = CrossEncoderReranker(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
    "        \n",
    "        # Результаты для последующей оценки\n",
    "        retrieval_results = []\n",
    "        \n",
    "        # Обработка каждого вопроса\n",
    "        for question in test_questions:\n",
    "            # Получение фрагментов с помощью BM25 и реранкера\n",
    "            # Базовая модель отбирает 20 фрагментов, затем реранкер выбирает лучшие\n",
    "            max_k = max(k_values)  # Максимальное k из запрошенных\n",
    "            reranked_fragments = get_relevant_fragments_with_reranker(\n",
    "                qa_system, reranker, question, initial_top_k=20, final_top_k=max_k\n",
    "            )\n",
    "            \n",
    "            # Результаты для текущего вопроса\n",
    "            result = {'question': question, 'fragments': []}\n",
    "            \n",
    "            # Оценка релевантности для каждого фрагмента\n",
    "            for text, name, bm25_score, rerank_score in reranked_fragments:\n",
    "                # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "                time.sleep(2)\n",
    "                relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                result['fragments'].append((text, name, bm25_score, relevance_score))\n",
    "            \n",
    "            retrieval_results.append(result)\n",
    "        \n",
    "        # Отдельные метрики для каждого значения k\n",
    "        metrics_results = {}\n",
    "        for k in k_values:\n",
    "            # Для каждого k создаем копию результатов, но ограничиваем количество фрагментов до k\n",
    "            k_results = []\n",
    "            for result in retrieval_results:\n",
    "                k_result = {\n",
    "                    'question': result['question'],\n",
    "                    'fragments': result['fragments'][:k] if result['fragments'] else []\n",
    "                }\n",
    "                k_results.append(k_result)\n",
    "            \n",
    "            # Вычисление метрик для текущего k\n",
    "            k_metrics = calculate_metrics(k_results, [k])\n",
    "            metrics_results[f'top_{k}'] = k_metrics\n",
    "        \n",
    "        # Объединение всех метрик\n",
    "        metrics = {}\n",
    "        for k, k_metrics in metrics_results.items():\n",
    "            for metric_name, value in k_metrics.items():\n",
    "                metrics[f\"{k}_{metric_name}\"] = value\n",
    "        \n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки системы с CrossEncoder MS Marco реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in retrieval_results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            \n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "                \n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "            \n",
    "            # Сортировка по BM25\n",
    "            sorted_by_bm25 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по BM25:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_bm25[:min(3, len(sorted_by_bm25))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "        \n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(retrieval_results, \"cross_encoder_msmarco_reranker_results.csv\")\n",
    "        \n",
    "        # Проведем сравнение с исходной версией без реранкера\n",
    "        print(\"\\nНачало оценки только BM25 (без реранкера) для сравнения...\")\n",
    "        \n",
    "        # Функция для оценки BM25 без реранкера\n",
    "        def run_evaluation_bm25_only(api_key, test_questions, top_k):\n",
    "            \"\"\"Запуск оценки только BM25 системы на наборе тестовых вопросов\"\"\"\n",
    "            # Инициализация системы BM25\n",
    "            qa_system = DocumentationQA_BM25()\n",
    "            qa_system.initialize_database()\n",
    "            \n",
    "            # Результаты для последующей оценки\n",
    "            retrieval_results = []\n",
    "            \n",
    "            # Обработка каждого вопроса\n",
    "            for question in test_questions:\n",
    "                # Получение фрагментов с помощью BM25\n",
    "                fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "                \n",
    "                # Результаты для текущего вопроса\n",
    "                result = {'question': question, 'fragments': []}\n",
    "                \n",
    "                # Оценка релевантности для каждого фрагмента\n",
    "                for text, name, score in fragments:\n",
    "                    # Используем сохраненные оценки релевантности, если есть\n",
    "                    found = False\n",
    "                    for r in retrieval_results:\n",
    "                        if r['question'] == question:\n",
    "                            for t, n, _, rel_score in r['fragments']:\n",
    "                                if t == text and n == name:\n",
    "                                    result['fragments'].append((text, name, score, rel_score))\n",
    "                                    found = True\n",
    "                                    break\n",
    "                        if found:\n",
    "                            break\n",
    "                    \n",
    "                    # Если не нашли сохраненную оценку, запрашиваем новую\n",
    "                    if not found:\n",
    "                        time.sleep(2)\n",
    "                        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                        result['fragments'].append((text, name, score, relevance_score))\n",
    "                \n",
    "                retrieval_results.append(result)\n",
    "            \n",
    "            # Вычисление метрик\n",
    "            metrics_results = calculate_metrics(retrieval_results, k_values)\n",
    "            \n",
    "            return metrics_results, retrieval_results\n",
    "        \n",
    "        # Запускаем оценку BM25 отдельно для каждого значения k\n",
    "        bm25_metrics = {}\n",
    "        for k in k_values:\n",
    "            print(f\"Оценка BM25 для top_{k}...\")\n",
    "            k_metrics, k_results = run_evaluation_bm25_only(api_key, test_questions, k)\n",
    "            \n",
    "            # Добавляем префикс к метрикам\n",
    "            for metric, value in k_metrics.items():\n",
    "                if f\"@{k}\" in metric:  # Добавляем только метрики для текущего k\n",
    "                    bm25_metrics[f\"top_{k}_{metric}\"] = value\n",
    "            \n",
    "            # Сохраняем результаты BM25\n",
    "            save_results_to_csv(k_results, f\"bm25_only_top{k}_results.csv\")\n",
    "        \n",
    "        # Сравнение метрик\n",
    "        print(\"\\nСравнение метрик BM25 и BM25+CrossEncoder:\")\n",
    "        print(\"{:<20} {:<15} {:<15}\".format(\"Метрика\", \"BM25\", \"BM25+CrossEncoder\"))\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                \n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    \n",
    "                    print(\"{:<20} {:<15.4f} {:<15.4f}\".format(\n",
    "                        bm25_key, bm25_value, reranker_value\n",
    "                    ))\n",
    "        \n",
    "        # Анализ улучшений\n",
    "        total_improvements = 0\n",
    "        total_metrics = 0\n",
    "        \n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                \n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    \n",
    "                    if reranker_value > bm25_value:\n",
    "                        total_improvements += 1\n",
    "                    \n",
    "                    total_metrics += 1\n",
    "        \n",
    "        if total_metrics > 0:\n",
    "            improvement_percentage = (total_improvements / total_metrics) * 100\n",
    "            print(f\"\\nРеранкер MS Marco CrossEncoder улучшил {total_improvements} из {total_metrics} метрик ({improvement_percentage:.2f}%)\")\n",
    "        \n",
    "        return metrics, retrieval_results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало оценки системы с BM25 и реранкером sentence-transformers/msmarco-distilbert-base-tas-b...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n",
      "Инициализация CrossEncoder реранкера (sentence-transformers/msmarco-distilbert-base-tas-b)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-tas-b and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEncoder реранкер успешно инициализирован\n",
      "\n",
      "Результаты оценки системы с sentence-transformers/msmarco-distilbert-base-tas-b реранкером:\n",
      "top_4_recall@4: 1.0000\n",
      "top_4_precision@4: 0.2042\n",
      "top_4_mrr@4: 0.3528\n",
      "top_4_ndcg@4: 0.4552\n",
      "top_4_recall@1: 0.6924\n",
      "top_4_precision@1: 0.2667\n",
      "top_6_recall@6: 1.0000\n",
      "top_6_precision@6: 0.2083\n",
      "top_6_mrr@6: 0.4122\n",
      "top_6_ndcg@6: 0.5256\n",
      "top_6_recall@1: 0.6168\n",
      "top_6_precision@1: 0.3167\n",
      "\n",
      "Детальный анализ результатов:\n",
      "\n",
      "Вопрос: What is a collection in the context of Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 1.1910, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "2. indexing (BM25: 0.9407, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. collections (BM25: 1.0687, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 6.2949, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. explore (BM25: 5.8024, Релевантность: 2)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "3. collections (BM25: 1.1910, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "\n",
      "Вопрос: What must be true about the dimensionality of vectors within a single collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 6.2145, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. collections (BM25: 4.8172, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. indexing (BM25: 5.0423, Релевантность: 2)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 6.2145, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. points (BM25: 5.6402, Релевантность: 2)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "3. indexing (BM25: 5.0423, Релевантность: 2)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Вопрос: How does Qdrant support different metrics for comparing vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 12.4336, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 8.2487, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. explore (BM25: 3.9086, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 12.4336, Релевантность: 5)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "2. search (BM25: 8.2487, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 6.1398, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: When should multiple collections be created instead of just one?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 4.7079, Релевантность: 3)\n",
      "   To create a collection with sparse vectors: {{< code-snippet path=\"/documentation/headless/snippets/...\n",
      "2. points (BM25: 3.4520, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. explore (BM25: 3.4692, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 5.2823, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. vectors (BM25: 4.7079, Релевантность: 3)\n",
      "   To create a collection with sparse vectors: {{< code-snippet path=\"/documentation/headless/snippets/...\n",
      "3. explore (BM25: 3.4692, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What are some parameters that can be tuned for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 1.5060, Релевантность: 5)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "2. indexing (BM25: 1.4136, Релевантность: 5)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. indexing (BM25: 1.6731, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 1.9375, Релевантность: 4)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "2. optimizer (BM25: 1.7396, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. indexing (BM25: 1.6731, Релевантность: 4)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Вопрос: What happens if different types of vectors are used within a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 5.4063, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 5.5406, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. vectors (BM25: 6.6912, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.6464, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. vectors (BM25: 6.6912, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. explore (BM25: 5.9855, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Вопрос: How can the existence of a collection in Qdrant be checked?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 3.8758, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "2. indexing (BM25: 2.5312, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 2.9977, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 3.8758, Релевантность: 3)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "2. points (BM25: 3.6280, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. storage (BM25: 2.9977, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: What is the purpose of the payload in vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.4534, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 2.3978, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. vectors (BM25: 2.2004, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 2.5731, Релевантность: 3)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. collections (BM25: 2.4824, Релевантность: 4)\n",
      "   title: Collections weight: 30 aliases: - ../collections - /concepts/collections/ - /documentation/fr...\n",
      "3. indexing (BM25: 2.4534, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: Can collections be updated after their creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2904, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. payload (BM25: 2.6788, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. collections (BM25: 3.8210, Релевантность: 5)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 4.0727, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. collections (BM25: 3.8210, Релевантность: 5)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. filtering (BM25: 3.6790, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Вопрос: How does the choice of metric influence search results in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 3.2375, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 3.2579, Релевантность: 4)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "3. search (BM25: 1.2858, Релевантность: 3)\n",
      "   hnsw_ef - value that specifies ef parameter of the HNSW algorithm. exact - option to not use the app...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 3.5570, Релевантность: 3)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "2. indexing (BM25: 3.2579, Релевантность: 4)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "3. indexing (BM25: 3.2375, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What Stack of APIs does Qdrant provide for data exploration?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 4.4886, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. points (BM25: 4.1788, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. explore (BM25: 4.4619, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 4.4886, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. explore (BM25: 4.4619, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. points (BM25: 4.1788, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: How does the Recommendation API enhance the search functionality?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.7326, Релевантность: 4)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. explore (BM25: 2.8507, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "3. payload (BM25: 3.3576, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 4.7151, Релевантность: 2)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. storage (BM25: 3.7386, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. payload (BM25: 3.3576, Релевантность: 3)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What is the default strategy for recommendations in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.5564, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. explore (BM25: 6.7928, Релевантность: 2)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "3. search (BM25: 4.0043, Релевантность: 2)\n",
      "   The strategy selection process relies heavily on heuristics and can vary from release to release. Ho...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 6.7928, Релевантность: 2)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "2. search (BM25: 4.0043, Релевантность: 2)\n",
      "   The strategy selection process relies heavily on heuristics and can vary from release to release. Ho...\n",
      "3. search (BM25: 3.1986, Релевантность: 2)\n",
      "   planning is performed for each segment independently (see storage for more information about segment...\n",
      "\n",
      "Вопрос: What is the purpose of the 'best_score' strategy introduced in Qdrant v1.6.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 4.8864, Релевантность: 3)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "2. indexing (BM25: 2.5564, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. payload (BM25: 0.5247, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 4.8864, Релевантность: 3)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "2. explore (BM25: 3.9300, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. collections (BM25: 3.3745, Релевантность: 1)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: How can users find the most dissimilar vectors using only negative examples?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 11.5217, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 10.7737, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "3. indexing (BM25: 5.8984, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 11.5217, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 10.7737, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "3. vectors (BM25: 6.2749, Релевантность: 2)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Вопрос: What can be specified in the recommendation request when a collection is created with multiple vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 5.5009, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. explore (BM25: 6.7671, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 6.1096, Релевантность: 4)\n",
      "   Since the preprocessing step happens very fast, the performance of this strategy is on-par with regu...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 6.7671, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. payload (BM25: 6.7490, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. collections (BM25: 6.4638, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: What is the function of the 'lookup_from' parameter in the recommendation request?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 2.8909, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. indexing (BM25: 3.3312, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. search (BM25: 2.6785, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 3.5772, Релевантность: 1)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "2. payload (BM25: 3.4336, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. indexing (BM25: 3.3312, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: How does the Discovery API differ from the Recommendation API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 7.5201, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. collections (BM25: 4.4520, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. payload (BM25: 3.8903, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.5201, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. storage (BM25: 5.0956, Релевантность: 1)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. payload (BM25: 4.9385, Релевантность: 1)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What is the significance of using a context in Discovery search?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 6.8553, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. storage (BM25: 4.5319, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. payload (BM25: 3.4934, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 6.8553, Релевантность: 4)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. storage (BM25: 4.5319, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. payload (BM25: 3.4934, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: Can the Distance Matrix API be used for clustering similar vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. vectors (BM25: 8.6176, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. search (BM25: 6.0364, Релевантность: 3)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. explore (BM25: 6.1040, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. vectors (BM25: 8.6176, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "2. explore (BM25: 6.1040, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. search (BM25: 6.0364, Релевантность: 3)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: What types of conditions can you set when filtering points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 6.9067, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 7.1984, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 4.5768, Релевантность: 4)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 7.1984, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 6.9067, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. storage (BM25: 6.1071, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: What logical operations are available when combining filtering conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 3.4168, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. indexing (BM25: 5.5377, Релевантность: 3)\n",
      "   keyword - for keyword payload, affects Match filtering conditions. integer - for integer payload, af...\n",
      "3. filtering (BM25: 5.2268, Релевантность: 3)\n",
      "   For example, given the data: json [ { \"id\": 1, \"name\": \"product A\", \"comments\": [\"Very good!\", \"Exce...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.5377, Релевантность: 3)\n",
      "   keyword - for keyword payload, affects Match filtering conditions. integer - for integer payload, af...\n",
      "2. indexing (BM25: 5.4874, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 5.2268, Релевантность: 3)\n",
      "   For example, given the data: json [ { \"id\": 1, \"name\": \"product A\", \"comments\": [\"Very good!\", \"Exce...\n",
      "\n",
      "Вопрос: What is the function of the 'must' clause in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 1.9208, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 1.6845, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 5)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. payload (BM25: 3.0131, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. payload (BM25: 2.0327, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: What does the 'should' clause do in Qdrant filtering?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 1.9208, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 1.6845, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 7.5931, Релевантность: 3)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "2. indexing (BM25: 1.9208, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 1.6845, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: How does the 'must_not' clause work in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.1870, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 2.5026, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "3. indexing (BM25: 0.5555, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. filtering (BM25: 2.5026, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "2. indexing (BM25: 2.3301, Релевантность: 1)\n",
      "   N is the total number of documents in the collection. n is the number of documents containing non-ze...\n",
      "3. explore (BM25: 2.2921, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Вопрос: Can you filter using nested fields in Qdrant, and how?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 9.6050, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 4.8081, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. hybrid-queries (BM25: 5.3124, Релевантность: 3)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 9.6050, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 6.1808, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. hybrid-queries (BM25: 5.3124, Релевантность: 3)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "\n",
      "Вопрос: What condition would you use to check if a field has multiple values in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.3040, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 6.0528, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 7.6434, Релевантность: 3)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.7004, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 8.9518, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. payload (BM25: 8.3040, Релевантность: 4)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: How can you check if a field exists with no value in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 3.3070, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. indexing (BM25: 4.8405, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 6.2341, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 6.2341, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 5.1100, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "3. indexing (BM25: 4.8405, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What is the purpose of the 'has_id' condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. filtering (BM25: 2.6014, Релевантность: 3)\n",
      "   For example, given the data: json [ { \"id\": 1, \"name\": \"product A\", \"comments\": [\"Very good!\", \"Exce...\n",
      "2. indexing (BM25: 1.7696, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 2.2523, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 3.1173, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. filtering (BM25: 3.0371, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "3. filtering (BM25: 2.6014, Релевантность: 3)\n",
      "   For example, given the data: json [ { \"id\": 1, \"name\": \"product A\", \"comments\": [\"Very good!\", \"Exce...\n",
      "\n",
      "Вопрос: How do you filter records using geographic conditions in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.8513, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 4.5636, Релевантность: 4)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "3. indexing (BM25: 5.0411, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.2804, Релевантность: 3)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. indexing (BM25: 5.0411, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. indexing (BM25: 4.8513, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 3.5599, Релевантность: 3)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 2.8747, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 3.5599, Релевантность: 3)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. payload (BM25: 3.2274, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 2.8200, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "2. search (BM25: 2.4106, Релевантность: 2)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "3. payload (BM25: 2.9999, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 3.0852, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. payload (BM25: 2.9999, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. points (BM25: 2.9879, Релевантность: 1)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 3.0432, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "2. explore (BM25: 2.4246, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. search (BM25: 2.3023, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 4.2112, Релевантность: 1)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. payload (BM25: 4.0559, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. indexing (BM25: 3.0432, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 2.9218, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. indexing (BM25: 2.9786, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 2.8512, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 3.5353, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 2.9786, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. explore (BM25: 2.9218, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7415, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. filtering (BM25: 4.7664, Релевантность: 4)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "3. explore (BM25: 7.1373, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.1373, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. hybrid-queries (BM25: 5.2734, Релевантность: 4)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. search (BM25: 5.0398, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 3.3985, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. filtering (BM25: 3.1127, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 4.2209, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 3.3985, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 3.6401, Релевантность: 3)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "2. explore (BM25: 4.1107, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. points (BM25: 3.7872, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 5.2705, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. storage (BM25: 4.2935, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. explore (BM25: 4.1107, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. points (BM25: 4.8766, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. payload (BM25: 5.0259, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 5.6020, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. payload (BM25: 5.3009, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.4258, Релевантность: 2)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "2. search (BM25: 6.4942, Релевантность: 2)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "3. search (BM25: 4.8868, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.2741, Релевантность: 2)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. search (BM25: 6.4942, Релевантность: 2)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "3. search (BM25: 4.8868, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. search (BM25: 9.2299, Релевантность: 3)\n",
      "   Since the filter parameter is specified, the search is performed only among those points that satisf...\n",
      "3. search (BM25: 6.7802, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.2299, Релевантность: 3)\n",
      "   Since the filter parameter is specified, the search is performed only among those points that satisf...\n",
      "2. hybrid-queries (BM25: 8.5829, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What new feature was introduced in Qdrant version 1.10.0?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. points (BM25: 2.8747, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 3.5599, Релевантность: 2)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. collections (BM25: 3.3745, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. payload (BM25: 3.2274, Релевантность: 2)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "\n",
      "Вопрос: What is the role of the prefetch parameter in Qdrant's Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. hybrid-queries (BM25: 2.8200, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "2. search (BM25: 2.4106, Релевантность: 2)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "3. payload (BM25: 2.9999, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 3.0852, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. payload (BM25: 2.9999, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. points (BM25: 2.9879, Релевантность: 1)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What are the two fusion methods available in Qdrant for hybrid searches?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 3.0432, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "2. search (BM25: 2.3023, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. explore (BM25: 2.4246, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 4.2112, Релевантность: 1)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. payload (BM25: 4.0559, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. indexing (BM25: 3.0432, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: What is the benefit of using multi-stage queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 2.9218, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. indexing (BM25: 2.9786, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 2.8512, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 3.5353, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 2.9786, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. explore (BM25: 2.9218, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Вопрос: How does one filter points in Qdrant queries based on payload values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7415, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. explore (BM25: 7.1373, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. hybrid-queries (BM25: 5.2734, Релевантность: 4)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.1373, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. hybrid-queries (BM25: 5.2734, Релевантность: 4)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. search (BM25: 5.0398, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What is the purpose of the group_by field in Qdrant queries?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 3.3985, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. filtering (BM25: 3.1127, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 4.2209, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. indexing (BM25: 4.0023, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 3.3985, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: How can you reference a point ID from a different collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 3.6401, Релевантность: 3)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "2. explore (BM25: 4.1107, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. points (BM25: 3.7872, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 5.2705, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. storage (BM25: 4.2935, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. explore (BM25: 4.1107, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: Can you perform a query using a point ID as an input in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. points (BM25: 4.8766, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. payload (BM25: 5.0259, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 9.0057, Релевантность: 5)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. explore (BM25: 5.6020, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. payload (BM25: 5.3009, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What is the maximum number of groups you can limit a query to in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.4258, Релевантность: 2)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "2. search (BM25: 6.4942, Релевантность: 2)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "3. search (BM25: 4.8793, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.2741, Релевантность: 2)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. search (BM25: 6.4942, Релевантность: 2)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "3. search (BM25: 4.8868, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "\n",
      "Вопрос: What is the command for fetching results using the default vector from a point ID in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 6.8208, Релевантность: 3)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. search (BM25: 6.7802, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 9.2299, Релевантность: 2)\n",
      "   Since the filter parameter is specified, the search is performed only among those points that satisf...\n",
      "2. hybrid-queries (BM25: 8.5829, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. explore (BM25: 8.4714, Релевантность: 3)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: Why is it more efficient to apply changes in batches in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 2.7767, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. points (BM25: 3.3744, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. indexing (BM25: 5.4162, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.4162, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. points (BM25: 3.3744, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. payload (BM25: 3.1199, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What does Qdrant use to handle data changes during segment optimization?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 8.6880, Релевантность: 4)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. storage (BM25: 5.8508, Релевантность: 3)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. storage (BM25: 7.4433, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 8.6880, Релевантность: 4)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. storage (BM25: 7.4433, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 6.1713, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What is the purpose of the Vacuum Optimizer in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.6837, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. indexing (BM25: 1.6876, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.2271, Релевантность: 2)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "2. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. collections (BM25: 2.0044, Релевантность: 1)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "\n",
      "Вопрос: What criteria determine when to trigger the Vacuum Optimizer?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.0687, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 2.7547, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. optimizer (BM25: 1.9632, Релевантность: 2)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 4.4597, Релевантность: 1)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "2. indexing (BM25: 4.0687, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 2.7547, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What does the Merge Optimizer do in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.6837, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. collections (BM25: 1.6000, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 3.3102, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. collections (BM25: 2.0044, Релевантность: 1)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "3. optimizer (BM25: 1.9632, Релевантность: 2)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "\n",
      "Вопрос: How does the Indexing Optimizer determine when to enable indexes in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 6.9239, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. optimizer (BM25: 6.1839, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. storage (BM25: 3.5097, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 6.9239, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. collections (BM25: 6.7220, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. optimizer (BM25: 6.1839, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "\n",
      "Вопрос: What happens to segments larger than the specified memmap_threshold in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 6.0142, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 7.3632, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. indexing (BM25: 4.3001, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 7.3632, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. storage (BM25: 6.0142, Релевантность: 4)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. indexing (BM25: 4.3001, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What can the user configure in the Qdrant configuration file related to optimizers?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 5.7091, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. collections (BM25: 4.4789, Релевантность: 4)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "3. search (BM25: 5.2460, Релевантность: 4)\n",
      "   planning is performed for each segment independently (see storage for more information about segment...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 8.1109, Релевантность: 4)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "2. optimizer (BM25: 7.4965, Релевантность: 3)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. indexing (BM25: 5.7091, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: Why might a user choose to disable indexing during initial data loading in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. optimizer (BM25: 13.2349, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. storage (BM25: 6.5075, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 7.7587, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. optimizer (BM25: 13.2349, Релевантность: 5)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "2. indexing (BM25: 7.7587, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 6.5075, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: What is the primary challenge faced by Qdrant regarding deleted records?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.3196, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. storage (BM25: 3.2376, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. payload (BM25: 2.2935, Релевантность: 2)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.0204, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. storage (BM25: 3.2376, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. points (BM25: 2.3196, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What is the term used in Qdrant for storing additional information along with vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 8.9817, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. payload (BM25: 12.2243, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "3. search (BM25: 8.4525, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 12.2243, Релевантность: 5)\n",
      "   Payload One of the significant features of Qdrant is the ability to store additional information alo...\n",
      "2. indexing (BM25: 8.9817, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. search (BM25: 8.4525, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What data format does Qdrant allow for the representation of payload information?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 5.1487, Релевантность: 4)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. payload (BM25: 4.3419, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. storage (BM25: 3.6955, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 6.4896, Релевантность: 2)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "2. points (BM25: 5.1487, Релевантность: 4)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. payload (BM25: 4.3419, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: What happens during filtering if the stored value type does not fit the filtering condition in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 8.1757, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 7.0815, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 6.0068, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.1757, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 7.0815, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. filtering (BM25: 6.0068, Релевантность: 2)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Вопрос: What type of numbers does Qdrant support for integer values?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 5.6282, Релевантность: 3)\n",
      "   See Full Text match for examples of querying with full-text index. Parameterized index Available as ...\n",
      "2. storage (BM25: 4.8596, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 4.3815, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.6282, Релевантность: 3)\n",
      "   See Full Text match for examples of querying with full-text index. Parameterized index Available as ...\n",
      "2. storage (BM25: 4.8596, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. search (BM25: 4.5055, Релевантность: 1)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What are the two methods to update payloads mentioned in the text?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 6.6745, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. storage (BM25: 5.4671, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. points (BM25: 5.3294, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 6.6745, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. storage (BM25: 5.4671, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. points (BM25: 5.3294, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: Which method is used to remove all payload keys from specified points in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. payload (BM25: 8.7402, Релевантность: 4)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. points (BM25: 6.7927, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. indexing (BM25: 7.2523, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 8.7402, Релевантность: 4)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. indexing (BM25: 7.2523, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 6.7927, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What type of indexing does Qdrant allow for payload fields to improve search efficiency?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 6.5890, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 6.8085, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. payload (BM25: 7.7662, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 7.7662, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "2. indexing (BM25: 6.8085, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 6.5890, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: What is faceting in the context of Qdrant, and what can it be used for?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.0987, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 2.1011, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. indexing (BM25: 2.0852, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 7.8942, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. explore (BM25: 7.2260, Релевантность: 1)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "3. indexing (BM25: 2.1011, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What should you do before using faceting on a field in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 4.7521, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 4.1509, Релевантность: 3)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 4.8149, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 4.8149, Релевантность: 3)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. indexing (BM25: 4.7521, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 4.7378, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Вопрос: What will the response contain when performing a facet count for a field?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.6535, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 4.9000, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. hybrid-queries (BM25: 2.7594, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 4.9000, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. payload (BM25: 2.8582, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. payload (BM25: 2.8072, Релевантность: 1)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: What is the primary function of the Qdrant Query API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.3158, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. explore (BM25: 2.3403, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. points (BM25: 2.6107, Релевантность: 3)\n",
      "   The single point can also be retrieved via the API: REST API (Schema): {{< code-snippet path=\"/docum...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 4.3540, Релевантность: 2)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "2. search (BM25: 4.3158, Релевантность: 4)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. payload (BM25: 3.6123, Релевантность: 2)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Вопрос: Which similarity search method is referred to as k-NN?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 6.1102, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. indexing (BM25: 3.4222, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. search (BM25: 3.6996, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 6.1102, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. points (BM25: 4.9817, Релевантность: 1)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. search (BM25: 3.6996, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "\n",
      "Вопрос: What types of metrics does Qdrant support for estimating vector similarity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 10.0473, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 7.2547, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "3. storage (BM25: 4.9041, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 10.0473, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 8.6665, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 7.2547, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What does the 'limit' parameter specify in a search query?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.9034, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. payload (BM25: 1.9893, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "3. search (BM25: 2.8362, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 2.9034, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. search (BM25: 2.8362, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. collections (BM25: 2.1555, Релевантность: 1)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: In which version of Qdrant is the batch search API available?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 4.8247, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. storage (BM25: 2.1691, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. indexing (BM25: 4.4784, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 4.8247, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. indexing (BM25: 4.4784, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "3. indexing (BM25: 3.6503, Релевантность: 1)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Вопрос: How can you filter search results based on a specific payload key using the Qdrant search API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 8.0163, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. explore (BM25: 7.6331, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. indexing (BM25: 6.4343, Релевантность: 4)\n",
      "   You can find more information on why this happens in our blog post. Qdrant solves this problem by ex...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 8.0163, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. explore (BM25: 7.6331, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. explore (BM25: 6.6503, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What is the default scoring metric for sparse queries in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 14.1910, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. explore (BM25: 4.2856, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. explore (BM25: 6.8639, Релевантность: 2)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 14.1910, Релевантность: 5)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. explore (BM25: 6.8639, Релевантность: 2)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "3. indexing (BM25: 6.7486, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What is the purpose of the 'with_lookup' parameter in the grouping API?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 2.4697, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. search (BM25: 3.5465, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. collections (BM25: 2.5563, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 3.6986, Релевантность: 2)\n",
      "   Consider having points with the following payloads: json [ { \"id\": 0, \"payload\": { \"chunk_part\": 0, ...\n",
      "2. search (BM25: 3.5465, Релевантность: 2)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "3. search (BM25: 2.6628, Релевантность: 2)\n",
      "   Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step...\n",
      "\n",
      "Вопрос: What does the 'offset' parameter do when searching with Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.1306, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. indexing (BM25: 1.4062, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. collections (BM25: 1.4511, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 1.5299, Релевантность: 2)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. collections (BM25: 1.4511, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. indexing (BM25: 1.4062, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: What is a unique feature of the random sampling API in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 7.6751, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. indexing (BM25: 2.4715, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. points (BM25: 7.6119, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 7.6751, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. points (BM25: 7.6119, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. hybrid-queries (BM25: 3.9213, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "\n",
      "Вопрос: What is a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2218, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. hybrid-queries (BM25: 1.8125, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "3. filtering (BM25: 1.7833, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 2.2218, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. points (BM25: 2.1797, Релевантность: 2)\n",
      "   Available as of v1.7.0 Points can contain dense and sparse vectors. A sparse vector is an array in w...\n",
      "3. hybrid-queries (BM25: 1.8125, Релевантность: 2)\n",
      "   Apply filters to the payload fields, to only get the points that match the filter. Order the results...\n",
      "\n",
      "Вопрос: What identifier types does Qdrant support for points?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 3.3888, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 3.4731, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 3.4359, Релевантность: 2)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 4.6497, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. storage (BM25: 3.4731, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. filtering (BM25: 3.4557, Релевантность: 2)\n",
      "   To retrieve only the points which are matching the conditions on an array element basis, that is the...\n",
      "\n",
      "Вопрос: How can you modify a point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2218, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. payload (BM25: 4.0977, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. indexing (BM25: 5.3314, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.3314, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "2. payload (BM25: 4.0977, Релевантность: 5)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. points (BM25: 2.2218, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 3.4359, Релевантность: 4)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "2. search (BM25: 4.1530, Релевантность: 3)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. storage (BM25: 4.9041, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 4.9041, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. search (BM25: 4.1530, Релевантность: 3)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 3.9959, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: Can multiple types of vectors be attached to a single point in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 6.6010, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. indexing (BM25: 5.1317, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. storage (BM25: 6.9365, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 6.9365, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. points (BM25: 6.6010, Релевантность: 5)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. explore (BM25: 5.4930, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What does the batch loading feature in Qdrant do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2404, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. optimizer (BM25: 3.2365, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. points (BM25: 5.9151, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 5.9151, Релевантность: 3)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. optimizer (BM25: 3.2365, Релевантность: 4)\n",
      "   ``` In addition to the configuration file, you can also set optimizer parameters separately for each...\n",
      "3. storage (BM25: 2.6699, Релевантность: 2)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Вопрос: What is the purpose of the update_vectors method in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.2404, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. payload (BM25: 3.7650, Релевантность: 3)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. points (BM25: 3.8772, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 3.8772, Релевантность: 2)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "2. payload (BM25: 3.7650, Релевантность: 3)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "3. indexing (BM25: 2.5176, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: How does Qdrant handle deleting vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 4.3685, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. storage (BM25: 4.9409, Релевантность: 4)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. payload (BM25: 3.0547, Релевантность: 2)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 5.1885, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "2. storage (BM25: 4.9409, Релевантность: 4)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. points (BM25: 4.3685, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What response is received when an API call is made with wait=false in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 3.5351, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. explore (BM25: 4.6776, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. search (BM25: 2.3051, Релевантность: 2)\n",
      "   Search groups REST API (Schema): {{< code-snippet path=\"/documentation/headless/snippets/query-group...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 4.6776, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "2. collections (BM25: 3.5351, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. storage (BM25: 3.4438, Релевантность: 1)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What is the Scroll API used for in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.8495, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. collections (BM25: 3.3686, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. explore (BM25: 2.9218, Релевантность: 2)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 4.8495, Релевантность: 5)\n",
      "   | | | | --- | --- | | Nearest Neighbors Search | Vector Similarity Search, also known as k-NN | | Se...\n",
      "2. explore (BM25: 3.8573, Релевантность: 2)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. payload (BM25: 3.7415, Релевантность: 2)\n",
      "   Delete payload keys Delete specific payload keys from points. REST API (Schema): {{< code-snippet pa...\n",
      "\n",
      "Вопрос: What are snapshots in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. indexing (BM25: 0.4689, Релевантность: 2)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. indexing (BM25: 0.5555, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. indexing (BM25: 0.5555, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. search (BM25: 0.5287, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Вопрос: How are snapshots created in a distributed deployment?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 1.3161, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. collections (BM25: 5.2664, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. storage (BM25: 1.8451, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 10.4641, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "2. collections (BM25: 5.2664, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "3. storage (BM25: 1.8451, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "\n",
      "Вопрос: What is the purpose of using snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.7825, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. collections (BM25: 1.6935, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. vectors (BM25: 1.8502, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 1.8724, Релевантность: 1)\n",
      "   N is the total number of documents in the collection. n is the number of documents containing non-ze...\n",
      "2. vectors (BM25: 1.8502, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. indexing (BM25: 1.7825, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Вопрос: What is the difference between snapshots and backups in Qdrant Cloud?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.5093, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "2. storage (BM25: 1.6579, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 1.8613, Релевантность: 1)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 1.8613, Релевантность: 1)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "2. search (BM25: 1.7444, Релевантность: 1)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "3. storage (BM25: 1.6579, Релевантность: 2)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What does the API endpoint /collections/{collection_name}/snapshots do?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 3.6899, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. storage (BM25: 1.3570, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. search (BM25: 1.7672, Релевантность: 2)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 5.5187, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. points (BM25: 5.0185, Релевантность: 1)\n",
      "   Parallelization A retry mechanism Lazy batching support\n",
      "\n",
      "For example, you can read your data directl...\n",
      "3. points (BM25: 3.6899, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Вопрос: What command is used to list snapshots for a collection?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 2.7780, Релевантность: 1)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "2. collections (BM25: 2.4772, Релевантность: 1)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. vectors (BM25: 3.7308, Релевантность: 1)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. payload (BM25: 6.0643, Релевантность: 1)\n",
      "   Payload schema example: json { \"payload_schema\": { \"property1\": { \"data_type\": \"keyword\" }, \"propert...\n",
      "2. vectors (BM25: 3.7308, Релевантность: 1)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "3. indexing (BM25: 2.7780, Релевантность: 1)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Вопрос: What limitations exist when restoring snapshots?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 2.9347, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. collections (BM25: 1.8599, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. indexing (BM25: 2.8364, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 2.9347, Релевантность: 2)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. indexing (BM25: 2.8364, Релевантность: 2)\n",
      "   Payload index may occupy some additional memory, so it is recommended to only use index for those fi...\n",
      "3. collections (BM25: 2.6848, Релевантность: 1)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/update-collection/vectors-to-disk-named/\" >}...\n",
      "\n",
      "Вопрос: How can you recover a snapshot from a URL?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 18.4029, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 5.4096, Релевантность: 3)\n",
      "   # Bucket region (e.g. eu-central-1) region: your_bucket_region_here\n",
      "\n",
      "# Storage access key # Can be s...\n",
      "3. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 18.4029, Релевантность: 4)\n",
      "   Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server...\n",
      "2. snapshots (BM25: 7.2560, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "3. snapshots (BM25: 6.0582, Релевантность: 2)\n",
      "   In case of limited capacity or a slow network attached disk, you can specify a separate location for...\n",
      "\n",
      "Вопрос: What is the significance of snapshot priority during recovery?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. optimizer (BM25: 2.9507, Релевантность: 2)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "3. storage (BM25: 2.9387, Релевантность: 1)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. snapshots (BM25: 7.2560, Релевантность: 3)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "2. optimizer (BM25: 4.8382, Релевантность: 1)\n",
      "   # Large segments might require disproportionately long indexation times, # therefore it makes sense ...\n",
      "3. optimizer (BM25: 2.9507, Релевантность: 2)\n",
      "   The availability is achieved by wrapping the segment into a proxy that transparently handles data ch...\n",
      "\n",
      "Вопрос: Where are snapshots stored by default?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 2.5942, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. explore (BM25: 1.9064, Релевантность: 1)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "3. filtering (BM25: 1.3971, Релевантность: 1)\n",
      "   Configuration is defined during the index creation and describe at full-text index. If there is no f...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 2.5942, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. explore (BM25: 2.2425, Релевантность: 1)\n",
      "   * When providing ids as examples, they will be excluded from the results. * Score is always in desce...\n",
      "3. explore (BM25: 1.9064, Релевантность: 1)\n",
      "   The performance of best_score strategy will be linearly impacted by the amount of examples.\n",
      "\n",
      "Since w...\n",
      "\n",
      "Вопрос: What is the structure of data storage within a collection in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.5046, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 4.7661, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 4.7046, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 8.6337, Релевантность: 3)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. storage (BM25: 7.5046, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. storage (BM25: 4.7661, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Вопрос: What types of segments are there in Qdrant, and what operations can be performed on them?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 5.3322, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. indexing (BM25: 4.6278, Релевантность: 4)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. explore (BM25: 3.4954, Релевантность: 3)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 5.8164, Релевантность: 2)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "2. storage (BM25: 5.3322, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 4.9250, Релевантность: 2)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "\n",
      "Вопрос: What is the difference between in-memory storage and memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 12.5578, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 11.3333, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. storage (BM25: 8.6069, Релевантность: 3)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 12.5578, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. storage (BM25: 11.3333, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. storage (BM25: 8.6069, Релевантность: 3)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "\n",
      "Вопрос: What parameter is used to configure memmap storage for vectors during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 11.5136, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 5.9538, Релевантность: 3)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. indexing (BM25: 5.9153, Релевантность: 3)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 11.5136, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. vectors (BM25: 6.6150, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. collections (BM25: 6.4848, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "\n",
      "Вопрос: What is the recommended approach for using memmap storage in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.9736, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "2. storage (BM25: 7.1320, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. storage (BM25: 8.6518, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.6518, Релевантность: 4)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 7.9736, Релевантность: 5)\n",
      "   There are two ways to do this:\n",
      "\n",
      "You can set the threshold globally in the configuration file. The pa...\n",
      "3. storage (BM25: 7.1320, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: How does Qdrant handle the versioning of data and ensure data integrity?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 5.2740, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "2. collections (BM25: 2.9662, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "3. storage (BM25: 3.2144, Релевантность: 3)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 6.7065, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "2. points (BM25: 5.2740, Релевантность: 4)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "3. snapshots (BM25: 3.5023, Релевантность: 2)\n",
      "   replica: (default) prefer existing data over the snapshot. snapshot: prefer snapshot data over exist...\n",
      "\n",
      "Вопрос: What types of payload storage does Qdrant support, and what are their characteristics?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 7.4630, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 5.0280, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 4.3633, Релевантность: 4)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 7.4630, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. search (BM25: 7.4363, Релевантность: 2)\n",
      "   The fetched vector(s) must match the characteristics of the using vector, otherwise, an error will b...\n",
      "3. storage (BM25: 5.0280, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "\n",
      "Вопрос: What should be done if large payload values are attached in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 8.3367, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 3.2607, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "3. payload (BM25: 2.5046, Релевантность: 4)\n",
      "   UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for st...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 8.3367, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. collections (BM25: 3.5690, Релевантность: 4)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "3. storage (BM25: 3.2607, Релевантность: 4)\n",
      "   Set up on_disk option for the vectors in the collection create API:\n",
      "\n",
      "Available as of v1.2.0 {{< code...\n",
      "\n",
      "Вопрос: What configuration parameter is used to specify the type of payload storage during collection creation?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 7.0541, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. storage (BM25: 11.0561, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 6.3360, Релевантность: 4)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 11.0561, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 10.8914, Релевантность: 4)\n",
      "   You can specify the desired type of payload storage with configuration file or with collection param...\n",
      "3. indexing (BM25: 7.0541, Релевантность: 5)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Вопрос: What is the purpose of the memmap_threshold option in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 1.9059, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "2. indexing (BM25: 2.6498, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "3. points (BM25: 1.8128, Релевантность: 1)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 2.6498, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. collections (BM25: 2.5329, Релевантность: 1)\n",
      "   For search efficiency, Cosine similarity is implemented as dot-product over normalized vectors. Vect...\n",
      "3. indexing (BM25: 1.9059, Релевантность: 2)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What are vectors in the context of Qdrant Vector Search engine?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 7.0692, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "2. explore (BM25: 9.1646, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "3. points (BM25: 4.4701, Релевантность: 3)\n",
      "   Record-oriented format: python client.upload_points( collection_name=\"{collection_name}\", points=[ m...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. explore (BM25: 9.1646, Релевантность: 4)\n",
      "   Still, in this case, they need to be provided in the form of positive-negative pairs. Discovery API ...\n",
      "2. indexing (BM25: 7.0692, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. indexing (BM25: 6.9996, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: How does a vector representation relate to the similarity of objects?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 10.3046, Релевантность: 5)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. explore (BM25: 4.4200, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "3. filtering (BM25: 4.1722, Релевантность: 2)\n",
      "   Filtering With Qdrant, you can set conditions when searching or retrieving points. For example, you ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. search (BM25: 10.3046, Релевантность: 5)\n",
      "   Similarity search Searching for the nearest vectors is at the core of many representational learning...\n",
      "2. vectors (BM25: 5.8116, Релевантность: 2)\n",
      "   {{< code-snippet path=\"/documentation/headless/snippets/create-collection/datatype-uint8-sparse-and-...\n",
      "3. explore (BM25: 4.4200, Релевантность: 4)\n",
      "   Explore the data After mastering the concepts in search, you can start exploring your data in other ...\n",
      "\n",
      "Вопрос: What types of vectors does Qdrant support?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. search (BM25: 4.1530, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "2. indexing (BM25: 3.4359, Релевантность: 4)\n",
      "   On-disk payload index might affect cold requests latency, as it requires additional disk I/O operati...\n",
      "3. indexing (BM25: 3.9013, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 4.9041, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. search (BM25: 4.1530, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 3.9959, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What is the difference between dense vectors and sparse vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. points (BM25: 8.6746, Релевантность: 5)\n",
      "   That means that in every request UUID string could be used instead of numerical id. Example: {{< cod...\n",
      "2. indexing (BM25: 6.2019, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. vectors (BM25: 7.1227, Релевантность: 4)\n",
      "   Vectors Vectors (or embeddings) are the core concept of the Qdrant Vector Search engine. Vectors def...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 10.4523, Релевантность: 3)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. search (BM25: 9.4532, Релевантность: 4)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 8.8533, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What configuration must be set to create a collection with sparse vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. indexing (BM25: 8.8826, Релевантность: 5)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. indexing (BM25: 8.5180, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. indexing (BM25: 7.1339, Релевантность: 4)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 8.8826, Релевантность: 5)\n",
      "   A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms. All ...\n",
      "2. indexing (BM25: 8.5180, Релевантность: 4)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "3. indexing (BM25: 7.1339, Релевантность: 4)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Вопрос: What are multivectors and what scenarios are they useful in?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 3.8829, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. indexing (BM25: 3.3264, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "3. indexing (BM25: 1.8724, Релевантность: 1)\n",
      "   N is the total number of documents in the collection. n is the number of documents containing non-ze...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. points (BM25: 4.5014, Релевантность: 1)\n",
      "   Qdrant therefore requires a payload index which supports Range filtering conditions on the field use...\n",
      "2. storage (BM25: 3.8829, Релевантность: 2)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "3. indexing (BM25: 3.3264, Релевантность: 2)\n",
      "   keyword integer float datetime uuid text geo\n",
      "\n",
      "The list will be extended in future versions. Tenant I...\n",
      "\n",
      "Вопрос: What datatype is used by default for vectors in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 4.0082, Релевантность: 2)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. search (BM25: 5.4721, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 5.1569, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.5106, Релевантность: 2)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "2. search (BM25: 5.4721, Релевантность: 2)\n",
      "   There are however important differences between dense and sparse vector search: | Index| Sparse Quer...\n",
      "3. indexing (BM25: 5.1569, Релевантность: 2)\n",
      "   # Larger the value - more accurate the search, more time required to build index. ef_construct: 100 ...\n",
      "\n",
      "Вопрос: How does Qdrant optimize memory usage for large-dimensionality vectors?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 3.9314, Релевантность: 4)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. indexing (BM25: 5.5141, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "3. collections (BM25: 5.0939, Релевантность: 3)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. indexing (BM25: 5.5141, Релевантность: 3)\n",
      "   Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It ...\n",
      "2. collections (BM25: 5.0939, Релевантность: 3)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "3. collections (BM25: 4.0422, Релевантность: 2)\n",
      "   If you insert the vectors into the collection, the status field may become yellow whilst it is optim...\n",
      "\n",
      "Вопрос: What is the purpose of quantization in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. collections (BM25: 3.7295, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. collections (BM25: 3.5974, Релевантность: 2)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "3. collections (BM25: 3.1757, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. collections (BM25: 3.7295, Релевантность: 3)\n",
      "   Full API specification is available in schema definitions. Calls to this endpoint may be blocking as...\n",
      "2. collections (BM25: 3.5974, Релевантность: 2)\n",
      "   optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_...\n",
      "3. collections (BM25: 3.1757, Релевантность: 2)\n",
      "   hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more...\n",
      "\n",
      "Вопрос: What trade-offs must be considered when using different storage options in Qdrant?\n",
      "Топ-3 наиболее релевантных фрагмента по оценке Claude:\n",
      "1. storage (BM25: 4.9955, Релевантность: 5)\n",
      "   In addition, you can use memmap storage not only for vectors, but also for HNSW index. To enable thi...\n",
      "2. storage (BM25: 9.5951, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "3. indexing (BM25: 5.0902, Релевантность: 3)\n",
      "   Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It au...\n",
      "\n",
      "Топ-3 наиболее релевантных фрагмента по BM25:\n",
      "1. storage (BM25: 9.5951, Релевантность: 5)\n",
      "   Storage All data within one collection is divided into segments. Each segment has its independent ve...\n",
      "2. search (BM25: 7.9640, Релевантность: 3)\n",
      "   hnsw_ef - value that specifies ef parameter of the HNSW algorithm. exact - option to not use the app...\n",
      "3. indexing (BM25: 6.5892, Релевантность: 3)\n",
      "   However, knowing that the collection contains multiple tenants unlocks more opportunities for optimi...\n",
      "Результаты сохранены в sentence_transformers_msmarco_distilbert_reranker_results.csv\n",
      "\n",
      "Начало оценки только BM25 (без реранкера) для сравнения...\n",
      "Оценка BM25 для top_4...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n",
      "Результаты сохранены в bm25_only_top4_results.csv\n",
      "Оценка BM25 для top_6...\n",
      "Всего загружено 130 фрагментов.\n",
      "Начинаем токенизацию и предобработку текста...\n",
      "Инициализация BM25...\n",
      "BM25 успешно инициализирован. Всего документов: 130\n",
      "Результаты сохранены в bm25_only_top6_results.csv\n",
      "\n",
      "Сравнение метрик BM25 и BM25+sentence-transformers/msmarco-distilbert-base-tas-b:\n",
      "Метрика              BM25            BM25+CrossEncoder\n",
      "--------------------------------------------------\n",
      "top_4_recall@4       1.0000          1.0000         \n",
      "top_4_precision@4    0.4354          0.2042         \n",
      "top_4_mrr@4          0.7194          0.3528         \n",
      "top_4_ndcg@4         0.8005          0.4552         \n",
      "top_6_recall@6       1.0000          1.0000         \n",
      "top_6_precision@6    0.3833          0.2083         \n",
      "top_6_mrr@6          0.7189          0.4122         \n",
      "top_6_ndcg@6         0.8078          0.5256         \n",
      "\n",
      "Реранкер sentence-transformers/msmarco-distilbert-base-tas-b улучшил 0 из 8 метрик (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Класс для реранкинга с использованием CrossEncoder модели\n",
    "class CrossEncoderReranker:\n",
    "    def __init__(self, model_name=\"sentence-transformers/msmarco-distilbert-base-tas-b\"):\n",
    "        try:\n",
    "            print(f\"Инициализация CrossEncoder реранкера ({model_name})...\")\n",
    "            from sentence_transformers import CrossEncoder\n",
    "            self.model = CrossEncoder(model_name)\n",
    "            print(f\"CrossEncoder реранкер успешно инициализирован\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при инициализации CrossEncoder реранкера: {e}\")\n",
    "            raise\n",
    "\n",
    "    def rerank(self, query, documents, fragment_scores, batch_size=32):\n",
    "        \"\"\"\n",
    "        Переранжирует документы с использованием CrossEncoder модели.\n",
    "        Args:\n",
    "            query: Текст запроса\n",
    "            documents: Список текстов документов\n",
    "            fragment_scores: Исходные оценки документов (из BM25)\n",
    "            batch_size: Размер батча для инференса\n",
    "        Returns:\n",
    "            Список кортежей (документ, исходная_оценка, новая_оценка)\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return []\n",
    "        # Подготовка входных данных в формате для CrossEncoder\n",
    "        sentence_pairs = [[query, doc] for doc in documents]\n",
    "        # Получение предсказаний\n",
    "        try:\n",
    "            scores = self.model.predict(sentence_pairs, batch_size=batch_size)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при получении предсказаний от CrossEncoder: {e}\")\n",
    "            # В случае ошибки возвращаем исходные результаты\n",
    "            return list(zip(documents, fragment_scores, fragment_scores))\n",
    "        # Комбинирование результатов с исходными документами и оценками\n",
    "        ranked_results = list(zip(documents, fragment_scores, scores))\n",
    "        # Сортировка по убыванию нового скора\n",
    "        ranked_results = sorted(ranked_results, key=lambda x: x[2], reverse=True)\n",
    "        return ranked_results\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Загрузка API ключа\n",
    "        api_key_file = 'api.txt'\n",
    "        if os.path.exists(api_key_file):\n",
    "            with open(api_key_file, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "        else:\n",
    "            print(f\"Файл с API ключом {api_key_file} не найден!\")\n",
    "            api_key = input(\"Введите ваш API ключ: \")\n",
    "        # Проверка API ключа\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API ключ не может быть пустым\")\n",
    "        df = pd.read_csv('texts_with_answers.csv')\n",
    "        test_questions = df.question.to_list()\n",
    "        # Определяем значения k для оценки\n",
    "        k_values = [4, 6]\n",
    "        # Запуск оценки системы с CrossEncoder реранкером\n",
    "        print(\"Начало оценки системы с BM25 и реранкером sentence-transformers/msmarco-distilbert-base-tas-b...\")\n",
    "        # Инициализация QA системы с BM25\n",
    "        qa_system = DocumentationQA_BM25()\n",
    "        qa_system.initialize_database()\n",
    "        # Инициализация CrossEncoder реранкера\n",
    "        reranker = CrossEncoderReranker(\"sentence-transformers/msmarco-distilbert-base-tas-b\")\n",
    "        # Результаты для последующей оценки\n",
    "        retrieval_results = []\n",
    "        # Обработка каждого вопроса\n",
    "        for question in test_questions:\n",
    "            # Получение фрагментов с помощью BM25 и реранкера\n",
    "            # Базовая модель отбирает 20 фрагментов, затем реранкер выбирает лучшие\n",
    "            max_k = max(k_values)  # Максимальное k из запрошенных\n",
    "            reranked_fragments = get_relevant_fragments_with_reranker(\n",
    "                qa_system, reranker, question, initial_top_k=20, final_top_k=max_k\n",
    "            )\n",
    "            # Результаты для текущего вопроса\n",
    "            result = {'question': question, 'fragments': []}\n",
    "            # Оценка релевантности для каждого фрагмента\n",
    "            for text, name, bm25_score, rerank_score in reranked_fragments:\n",
    "                # Делаем задержку между запросами, чтобы не превысить лимиты API\n",
    "                time.sleep(2)\n",
    "                relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                result['fragments'].append((text, name, bm25_score, relevance_score))\n",
    "            retrieval_results.append(result)\n",
    "        # Отдельные метрики для каждого значения k\n",
    "        metrics_results = {}\n",
    "        for k in k_values:\n",
    "            # Для каждого k создаем копию результатов, но ограничиваем количество фрагментов до k\n",
    "            k_results = []\n",
    "            for result in retrieval_results:\n",
    "                k_result = {\n",
    "                    'question': result['question'],\n",
    "                    'fragments': result['fragments'][:k] if result['fragments'] else []\n",
    "                }\n",
    "                k_results.append(k_result)\n",
    "            # Вычисление метрик для текущего k\n",
    "            k_metrics = calculate_metrics(k_results, [k])\n",
    "            metrics_results[f'top_{k}'] = k_metrics\n",
    "        # Объединение всех метрик\n",
    "        metrics = {}\n",
    "        for k, k_metrics in metrics_results.items():\n",
    "            for metric_name, value in k_metrics.items():\n",
    "                metrics[f\"{k}_{metric_name}\"] = value\n",
    "        # Вывод результатов\n",
    "        print(\"\\nРезультаты оценки системы с sentence-transformers/msmarco-distilbert-base-tas-b реранкером:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        # Детальный анализ результатов\n",
    "        print(\"\\nДетальный анализ результатов:\")\n",
    "        for result in retrieval_results:\n",
    "            question = result['question']\n",
    "            print(f\"\\nВопрос: {question}\")\n",
    "            if not result['fragments']:\n",
    "                print(\"Не найдено релевантных фрагментов для этого вопроса.\")\n",
    "                continue\n",
    "            # Сортировка по оценке релевантности (от Claude)\n",
    "            sorted_by_relevance = sorted(result['fragments'], key=lambda x: x[3], reverse=True)\n",
    "            print(\"Топ-3 наиболее релевантных фрагмента по оценке Claude:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_relevance[:min(3, len(sorted_by_relevance))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "            # Сортировка по BM25\n",
    "            sorted_by_bm25 = sorted(result['fragments'], key=lambda x: x[2], reverse=True)\n",
    "            print(\"\\nТоп-3 наиболее релевантных фрагмента по BM25:\")\n",
    "            for i, (text, name, bm25_score, relevance) in enumerate(sorted_by_bm25[:min(3, len(sorted_by_bm25))]):\n",
    "                print(f\"{i+1}. {name} (BM25: {bm25_score:.4f}, Релевантность: {relevance})\")\n",
    "                print(f\"   {text[:100]}...\")\n",
    "        # Сохранение результатов в CSV для дальнейшего анализа\n",
    "        save_results_to_csv(retrieval_results, \"sentence_transformers_msmarco_distilbert_reranker_results.csv\")\n",
    "        # Проведем сравнение с исходной версией без реранкера\n",
    "        print(\"\\nНачало оценки только BM25 (без реранкера) для сравнения...\")\n",
    "        # Функция для оценки BM25 без реранкера\n",
    "        def run_evaluation_bm25_only(api_key, test_questions, top_k):\n",
    "            \"\"\"Запуск оценки только BM25 системы на наборе тестовых вопросов\"\"\"\n",
    "            # Инициализация системы BM25\n",
    "            qa_system = DocumentationQA_BM25()\n",
    "            qa_system.initialize_database()\n",
    "            # Результаты для последующей оценки\n",
    "            retrieval_results = []\n",
    "            # Обработка каждого вопроса\n",
    "            for question in test_questions:\n",
    "                # Получение фрагментов с помощью BM25\n",
    "                fragments = qa_system.search_similar_paragraphs(question, top_k=top_k)\n",
    "                # Результаты для текущего вопроса\n",
    "                result = {'question': question, 'fragments': []}\n",
    "                # Оценка релевантности для каждого фрагмента\n",
    "                for text, name, score in fragments:\n",
    "                    # Используем сохраненные оценки релевантности, если есть\n",
    "                    found = False\n",
    "                    for r in retrieval_results:\n",
    "                        if r['question'] == question:\n",
    "                            for t, n, _, rel_score in r['fragments']:\n",
    "                                if t == text and n == name:\n",
    "                                    result['fragments'].append((text, name, score, rel_score))\n",
    "                                    found = True\n",
    "                                    break\n",
    "                        if found:\n",
    "                            break\n",
    "                    # Если не нашли сохраненную оценку, запрашиваем новую\n",
    "                    if not found:\n",
    "                        time.sleep(2)\n",
    "                        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "                        result['fragments'].append((text, name, score, relevance_score))\n",
    "                retrieval_results.append(result)\n",
    "            # Вычисление метрик\n",
    "            metrics_results = calculate_metrics(retrieval_results, k_values)\n",
    "            return metrics_results, retrieval_results\n",
    "        # Запускаем оценку BM25 отдельно для каждого значения k\n",
    "        bm25_metrics = {}\n",
    "        for k in k_values:\n",
    "            print(f\"Оценка BM25 для top_{k}...\")\n",
    "            k_metrics, k_results = run_evaluation_bm25_only(api_key, test_questions, k)\n",
    "            # Добавляем префикс к метрикам\n",
    "            for metric, value in k_metrics.items():\n",
    "                if f\"@{k}\" in metric:  # Добавляем только метрики для текущего k\n",
    "                    bm25_metrics[f\"top_{k}_{metric}\"] = value\n",
    "            # Сохраняем результаты BM25\n",
    "            save_results_to_csv(k_results, f\"bm25_only_top{k}_results.csv\")\n",
    "        # Сравнение метрик\n",
    "        print(\"\\nСравнение метрик BM25 и BM25+sentence-transformers/msmarco-distilbert-base-tas-b:\")\n",
    "        print(\"{:<20} {:<15} {:<15}\".format(\"Метрика\", \"BM25\", \"BM25+CrossEncoder\"))\n",
    "        print(\"-\" * 50)\n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    print(\"{:<20} {:<15.4f} {:<15.4f}\".format(\n",
    "                        bm25_key, bm25_value, reranker_value\n",
    "                    ))\n",
    "        # Анализ улучшений\n",
    "        total_improvements = 0\n",
    "        total_metrics = 0\n",
    "        for k in k_values:\n",
    "            for metric_name in [f\"recall@{k}\", f\"precision@{k}\", f\"mrr@{k}\", f\"ndcg@{k}\"]:\n",
    "                bm25_key = f\"top_{k}_{metric_name}\"\n",
    "                reranker_key = f\"top_{k}_{metric_name}\"\n",
    "                if bm25_key in bm25_metrics and reranker_key in metrics:\n",
    "                    bm25_value = bm25_metrics[bm25_key]\n",
    "                    reranker_value = metrics[reranker_key]\n",
    "                    if reranker_value > bm25_value:\n",
    "                        total_improvements += 1\n",
    "                    total_metrics += 1\n",
    "        if total_metrics > 0:\n",
    "            improvement_percentage = (total_improvements / total_metrics) * 100\n",
    "            print(f\"\\nРеранкер sentence-transformers/msmarco-distilbert-base-tas-b улучшил {total_improvements} из {total_metrics} метрик ({improvement_percentage:.2f}%)\")\n",
    "        return metrics, retrieval_results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в функции main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
