{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка золотого стандарта для получения релевантных фрагментов для оценки базового пайплайна метриками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pipeline_file import DocumentationQA\n",
    "import time\n",
    "\n",
    "# Чтение данных из CSV\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "\n",
    "# Инициализация системы ретривала\n",
    "qa_system = DocumentationQA()\n",
    "qa_system.initialize_database()\n",
    "\n",
    "# Получение API ключа\n",
    "with open('api.txt', 'r') as file:\n",
    "    api_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаю список для хранения результатов\n",
    "retrieval_results = []\n",
    "\n",
    "# Обрабатываю каждый вопрос\n",
    "for index, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    fragments = qa_system.search_similar_paragraphs(question, top_k=6)\n",
    "    retrieval_results.append({\n",
    "        'question': question,\n",
    "        'fragments': fragments\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": 'chad-ea4e58bc0ac4441ca91e1188ca33120cpsekgbal'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "# Добавляю оценки релевантности к результатам\n",
    "for result in retrieval_results:\n",
    "    question = result['question']\n",
    "    for i, (text, name, score) in enumerate(result['fragments']):\n",
    "        # Делаю задержку между запросами, чтобы не превысить лимиты API\n",
    "        time.sleep(2)  # Увеличила задержку до 2 секунд для надежности\n",
    "        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        result['fragments'][i] = (text, name, score, relevance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(retrieval_results):\n",
    "    metrics = {\n",
    "        'recall@1': [],\n",
    "        'recall@4': [],\n",
    "        'recall@6': [],\n",
    "        'precision@1': [],\n",
    "        'precision@4': [],\n",
    "        'precision@6': [],\n",
    "        'mrr@4': [],\n",
    "        'mrr@6': [],\n",
    "        'ndcg@4': [],\n",
    "        'ndcg@6': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору из системы ретривала (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[3] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@1\n",
    "            relevant_at_1 = sum(1 for f in retrieved_fragments[:1] if f[3] >= 4)\n",
    "            metrics['recall@1'].append(relevant_at_1 / total_relevant)\n",
    "            \n",
    "            # Recall@4\n",
    "            relevant_at_4 = sum(1 for f in retrieved_fragments[:4] if f[3] >= 4)\n",
    "            metrics['recall@4'].append(relevant_at_4 / total_relevant)\n",
    "            \n",
    "            # Recall@6\n",
    "            relevant_at_6 = sum(1 for f in retrieved_fragments[:6] if f[3] >= 4)\n",
    "            metrics['recall@6'].append(relevant_at_6 / total_relevant)\n",
    "            \n",
    "            # Precision@1\n",
    "            metrics['precision@1'].append(relevant_at_1 / 1)\n",
    "            \n",
    "            # Precision@4\n",
    "            metrics['precision@4'].append(relevant_at_4 / 4)  # Исправлено с 3 на 4\n",
    "            \n",
    "            # Precision@6\n",
    "            metrics['precision@6'].append(relevant_at_6 / 6)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics['recall@1'].append(1.0)\n",
    "            metrics['recall@4'].append(1.0)\n",
    "            metrics['recall@6'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics['precision@1'].append(0.0)\n",
    "            metrics['precision@4'].append(0.0)\n",
    "            metrics['precision@6'].append(0.0)\n",
    "        \n",
    "        # MRR@4 (Mean Reciprocal Rank для первых 4)\n",
    "        first_relevant_rank_at_4 = next((i + 1 for i, f in enumerate(retrieved_fragments[:4]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_4 > 0:\n",
    "            metrics['mrr@4'].append(1.0 / first_relevant_rank_at_4)\n",
    "        else:\n",
    "            metrics['mrr@4'].append(0.0)\n",
    "            \n",
    "        # MRR@6 (Mean Reciprocal Rank для первых 6)\n",
    "        first_relevant_rank_at_6 = next((i + 1 for i, f in enumerate(retrieved_fragments[:6]) if f[3] >= 4), 0)\n",
    "        if first_relevant_rank_at_6 > 0:\n",
    "            metrics['mrr@6'].append(1.0 / first_relevant_rank_at_6)\n",
    "        else:\n",
    "            metrics['mrr@6'].append(0.0)\n",
    "        \n",
    "        # nDCG@4\n",
    "        if len(sorted_fragments) >= 4 and len(retrieved_fragments) >= 4:\n",
    "            # Берем только первые 4 документа для nDCG@4\n",
    "            true_relevance_4 = np.array([f[3] for f in sorted_fragments[:4]])\n",
    "            predicted_relevance_4 = np.array([f[3] for f in retrieved_fragments[:4]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_4 = ndcg_score([true_relevance_4], [predicted_relevance_4])\n",
    "                metrics['ndcg@4'].append(ndcg_4)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@4: {e}\")\n",
    "                metrics['ndcg@4'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@4'].append(0.0)\n",
    "            \n",
    "        # nDCG@6\n",
    "        if len(sorted_fragments) >= 6 and len(retrieved_fragments) >= 6:\n",
    "            # Берем только первые 6 документов для nDCG@6\n",
    "            true_relevance_6 = np.array([f[3] for f in sorted_fragments[:6]])\n",
    "            predicted_relevance_6 = np.array([f[3] for f in retrieved_fragments[:6]])\n",
    "            \n",
    "            try:\n",
    "                ndcg_6 = ndcg_score([true_relevance_6], [predicted_relevance_6])\n",
    "                metrics['ndcg@6'].append(ndcg_6)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@6: {e}\")\n",
    "                metrics['ndcg@6'].append(0.0)\n",
    "        else:\n",
    "            metrics['ndcg@6'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Вычисляем метрики\n",
    "metrics_results = calculate_metrics(retrieval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка подхода к ретривалу:\n",
      "Recall@1: 0.4440\n",
      "Recall@4: 0.8444\n",
      "Recall@6: 1.0000\n",
      "Precision@1: 0.7167\n",
      "Precision@4: 0.4125\n",
      "Precision@6: 0.3431\n",
      "MRR@4: 0.8014\n",
      "MRR@6: 0.8092\n",
      "nDCG@4: 0.9626\n",
      "nDCG@6: 0.9467\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов\n",
    "print(\"Оценка подхода к ретривалу:\")\n",
    "print(f\"Recall@1: {metrics_results['recall@1']:.4f}\")\n",
    "print(f\"Recall@4: {metrics_results['recall@4']:.4f}\")\n",
    "print(f\"Recall@6: {metrics_results['recall@6']:.4f}\")\n",
    "print(f\"Precision@1: {metrics_results['precision@1']:.4f}\")\n",
    "print(f\"Precision@4: {metrics_results['precision@4']:.4f}\")\n",
    "print(f\"Precision@6: {metrics_results['precision@6']:.4f}\")\n",
    "print(f\"MRR@4: {metrics_results['mrr@4']:.4f}\")\n",
    "print(f\"MRR@6: {metrics_results['mrr@6']:.4f}\")\n",
    "print(f\"nDCG@4: {metrics_results['ndcg@4']:.4f}\")\n",
    "print(f\"nDCG@6: {metrics_results['ndcg@6']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка подхода с reranker и top-4 фрагментами:\n",
      "Recall@4: 1.0000\n",
      "Precision@4: 0.4604\n",
      "MRR@4: 0.8326\n",
      "nDCG@4: 0.9668\n",
      "\n",
      "Оценка подхода с reranker и top-6 фрагментами:\n",
      "Recall@6: 1.0000\n",
      "Precision@6: 0.3708\n",
      "MRR@6: 0.8360\n",
      "nDCG@6: 0.9608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from pipeline_file import DocumentationQA\n",
    "import time\n",
    "\n",
    "# Чтение данных из CSV\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "\n",
    "# Инициализация системы ретривала\n",
    "qa_system = DocumentationQA()\n",
    "qa_system.initialize_database()\n",
    "\n",
    "# Инициализация reranker'а\n",
    "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "# Получение API ключа\n",
    "with open('api.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Создаю списки для хранения результатов\n",
    "retrieval_results_4 = []  # Результаты для top-4 после reranker'а\n",
    "retrieval_results_6 = []  # Результаты для top-6 после reranker'а\n",
    "\n",
    "# Обрабатываю каждый вопрос\n",
    "for index, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    \n",
    "    # Сначала получаем 20 фрагментов\n",
    "    initial_fragments = qa_system.search_similar_paragraphs(question, top_k=20)\n",
    "    \n",
    "    # Подготовка пар \"вопрос-фрагмент\" для reranker'а\n",
    "    pairs = [(question, fragment[0]) for fragment in initial_fragments]\n",
    "    \n",
    "    # Применение reranker'а\n",
    "    reranker_scores = reranker.predict(pairs)\n",
    "    \n",
    "    # Создаем кортежи (текст, имя, первоначальный скор, скор reranker'а)\n",
    "    reranked_fragments = [(fragment[0], fragment[1], fragment[2], score) \n",
    "                         for fragment, score in zip(initial_fragments, reranker_scores)]\n",
    "    \n",
    "    # Сортировка по скору reranker'а\n",
    "    reranked_fragments = sorted(reranked_fragments, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # Отбираем top-4 и top-6 после reranking'а\n",
    "    top_4_fragments = reranked_fragments[:4]\n",
    "    top_6_fragments = reranked_fragments[:6]\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    retrieval_results_4.append({\n",
    "        'question': question,\n",
    "        'fragments': top_4_fragments\n",
    "    })\n",
    "    \n",
    "    retrieval_results_6.append({\n",
    "        'question': question,\n",
    "        'fragments': top_6_fragments\n",
    "    })\n",
    "\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": 'chad-ea4e58bc0ac4441ca91e1188ca33120cpsekgbal'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-4\n",
    "for result in retrieval_results_4:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Делаю задержку между запросами\n",
    "        time.sleep(2)\n",
    "        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-6\n",
    "for result in retrieval_results_6:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Для фрагментов, которые уже оценены в top-4, не делаем повторный запрос\n",
    "        if i < 4:\n",
    "            # Находим соответствующий фрагмент в top-4 и берем оценку оттуда\n",
    "            for r4 in retrieval_results_4:\n",
    "                if r4['question'] == question:\n",
    "                    # Ищем совпадающий фрагмент\n",
    "                    for f4 in r4['fragments']:\n",
    "                        if f4[0] == text:\n",
    "                            relevance_score = f4[4]  # Используем уже полученную оценку\n",
    "                            break\n",
    "                    break\n",
    "        else:\n",
    "            # Для новых фрагментов делаем запрос\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        \n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "def calculate_metrics_reranker(retrieval_results, k_value):\n",
    "    metrics = {\n",
    "        f'recall@{k_value}': [],\n",
    "        f'precision@{k_value}': [],\n",
    "        f'mrr@{k_value}': [],\n",
    "        f'ndcg@{k_value}': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[4], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору reranker'а (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[4] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@k\n",
    "            relevant_at_k = sum(1 for f in retrieved_fragments[:k_value] if f[4] >= 4)\n",
    "            metrics[f'recall@{k_value}'].append(relevant_at_k / total_relevant)\n",
    "            \n",
    "            # Precision@k\n",
    "            metrics[f'precision@{k_value}'].append(relevant_at_k / k_value)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics[f'recall@{k_value}'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics[f'precision@{k_value}'].append(0.0)\n",
    "        \n",
    "        # MRR@k (Mean Reciprocal Rank)\n",
    "        first_relevant_rank = next((i + 1 for i, f in enumerate(retrieved_fragments[:k_value]) if f[4] >= 4), 0)\n",
    "        if first_relevant_rank > 0:\n",
    "            metrics[f'mrr@{k_value}'].append(1.0 / first_relevant_rank)\n",
    "        else:\n",
    "            metrics[f'mrr@{k_value}'].append(0.0)\n",
    "        \n",
    "        # nDCG@k\n",
    "        if len(sorted_fragments) >= k_value and len(retrieved_fragments) >= k_value:\n",
    "            # Берем только первые k документов\n",
    "            true_relevance = np.array([f[4] for f in sorted_fragments[:k_value]])\n",
    "            predicted_relevance = np.array([f[4] for f in retrieved_fragments[:k_value]])\n",
    "            \n",
    "            try:\n",
    "                ndcg = ndcg_score([true_relevance], [predicted_relevance])\n",
    "                metrics[f'ndcg@{k_value}'].append(ndcg)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@{k_value}: {e}\")\n",
    "                metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "        else:\n",
    "            metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Вычисляем метрики для top-4 результатов\n",
    "metrics_results_4 = calculate_metrics_reranker(retrieval_results_4, 4)\n",
    "\n",
    "# Вычисляем метрики для top-6 результатов\n",
    "metrics_results_6 = calculate_metrics_reranker(retrieval_results_6, 6)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Оценка подхода с reranker и top-4 фрагментами:\")\n",
    "print(f\"Recall@4: {metrics_results_4['recall@4']:.4f}\")\n",
    "print(f\"Precision@4: {metrics_results_4['precision@4']:.4f}\")\n",
    "print(f\"MRR@4: {metrics_results_4['mrr@4']:.4f}\")\n",
    "print(f\"nDCG@4: {metrics_results_4['ndcg@4']:.4f}\")\n",
    "\n",
    "print(\"\\nОценка подхода с reranker и top-6 фрагментами:\")\n",
    "print(f\"Recall@6: {metrics_results_6['recall@6']:.4f}\")\n",
    "print(f\"Precision@6: {metrics_results_6['precision@6']:.4f}\")\n",
    "print(f\"MRR@6: {metrics_results_6['mrr@6']:.4f}\")\n",
    "print(f\"nDCG@6: {metrics_results_6['ndcg@6']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка подхода с reranker и top-4 фрагментами:\n",
      "Recall@4: 1.0000\n",
      "Precision@4: 0.4625\n",
      "MRR@4: 0.8618\n",
      "nDCG@4: 0.9707\n",
      "\n",
      "Оценка подхода с reranker и top-6 фрагментами:\n",
      "Recall@6: 1.0000\n",
      "Precision@6: 0.3806\n",
      "MRR@6: 0.8646\n",
      "nDCG@6: 0.9602\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from pipeline_file import DocumentationQA\n",
    "import time\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "# Чтение данных из CSV\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "\n",
    "# Инициализация системы ретривала\n",
    "qa_system = DocumentationQA()\n",
    "qa_system.initialize_database()\n",
    "\n",
    "# Инициализация reranker'а\n",
    "reranker = FlagReranker('BAAI/bge-reranker-base')\n",
    "\n",
    "# Получение API ключа\n",
    "with open('api.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Создаю списки для хранения результатов\n",
    "retrieval_results_4 = []  # Результаты для top-4 после reranker'а\n",
    "retrieval_results_6 = []  # Результаты для top-6 после reranker'а\n",
    "\n",
    "# Обрабатываю каждый вопрос\n",
    "for index, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    \n",
    "    # Сначала получаем 20 фрагментов\n",
    "    initial_fragments = qa_system.search_similar_paragraphs(question, top_k=20)\n",
    "    \n",
    "    # Подготовка пар \"вопрос-фрагмент\" для reranker'а\n",
    "    pairs = [(question, fragment[0]) for fragment in initial_fragments]\n",
    "    \n",
    "    # Применение reranker'а\n",
    "    reranker_scores = reranker.compute_score(pairs)\n",
    "    \n",
    "    # Создаем кортежи (текст, имя, первоначальный скор, скор reranker'а)\n",
    "    reranked_fragments = [(fragment[0], fragment[1], fragment[2], score) \n",
    "                         for fragment, score in zip(initial_fragments, reranker_scores)]\n",
    "    \n",
    "    # Сортировка по скору reranker'а\n",
    "    reranked_fragments = sorted(reranked_fragments, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # Отбираем top-4 и top-6 после reranking'а\n",
    "    top_4_fragments = reranked_fragments[:4]\n",
    "    top_6_fragments = reranked_fragments[:6]\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    retrieval_results_4.append({\n",
    "        'question': question,\n",
    "        'fragments': top_4_fragments\n",
    "    })\n",
    "    \n",
    "    retrieval_results_6.append({\n",
    "        'question': question,\n",
    "        'fragments': top_6_fragments\n",
    "    })\n",
    "\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": 'chad-ea4e58bc0ac4441ca91e1188ca33120cpsekgbal'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-4\n",
    "for result in retrieval_results_4:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Делаю задержку между запросами\n",
    "        time.sleep(2)\n",
    "        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-6\n",
    "for result in retrieval_results_6:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Для фрагментов, которые уже оценены в top-4, не делаем повторный запрос\n",
    "        if i < 4:\n",
    "            # Находим соответствующий фрагмент в top-4 и берем оценку оттуда\n",
    "            for r4 in retrieval_results_4:\n",
    "                if r4['question'] == question:\n",
    "                    # Ищем совпадающий фрагмент\n",
    "                    for f4 in r4['fragments']:\n",
    "                        if f4[0] == text:\n",
    "                            relevance_score = f4[4]  # Используем уже полученную оценку\n",
    "                            break\n",
    "                    break\n",
    "        else:\n",
    "            # Для новых фрагментов делаем запрос\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        \n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "def calculate_metrics_reranker(retrieval_results, k_value):\n",
    "    metrics = {\n",
    "        f'recall@{k_value}': [],\n",
    "        f'precision@{k_value}': [],\n",
    "        f'mrr@{k_value}': [],\n",
    "        f'ndcg@{k_value}': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[4], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору reranker'а (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[4] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@k\n",
    "            relevant_at_k = sum(1 for f in retrieved_fragments[:k_value] if f[4] >= 4)\n",
    "            metrics[f'recall@{k_value}'].append(relevant_at_k / total_relevant)\n",
    "            \n",
    "            # Precision@k\n",
    "            metrics[f'precision@{k_value}'].append(relevant_at_k / k_value)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics[f'recall@{k_value}'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics[f'precision@{k_value}'].append(0.0)\n",
    "        \n",
    "        # MRR@k (Mean Reciprocal Rank)\n",
    "        first_relevant_rank = next((i + 1 for i, f in enumerate(retrieved_fragments[:k_value]) if f[4] >= 4), 0)\n",
    "        if first_relevant_rank > 0:\n",
    "            metrics[f'mrr@{k_value}'].append(1.0 / first_relevant_rank)\n",
    "        else:\n",
    "            metrics[f'mrr@{k_value}'].append(0.0)\n",
    "        \n",
    "        # nDCG@k\n",
    "        if len(sorted_fragments) >= k_value and len(retrieved_fragments) >= k_value:\n",
    "            # Берем только первые k документов\n",
    "            true_relevance = np.array([f[4] for f in sorted_fragments[:k_value]])\n",
    "            predicted_relevance = np.array([f[4] for f in retrieved_fragments[:k_value]])\n",
    "            \n",
    "            try:\n",
    "                ndcg = ndcg_score([true_relevance], [predicted_relevance])\n",
    "                metrics[f'ndcg@{k_value}'].append(ndcg)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@{k_value}: {e}\")\n",
    "                metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "        else:\n",
    "            metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Вычисляем метрики для top-4 результатов\n",
    "metrics_results_4 = calculate_metrics_reranker(retrieval_results_4, 4)\n",
    "\n",
    "# Вычисляем метрики для top-6 результатов\n",
    "metrics_results_6 = calculate_metrics_reranker(retrieval_results_6, 6)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Оценка подхода с reranker и top-4 фрагментами:\")\n",
    "print(f\"Recall@4: {metrics_results_4['recall@4']:.4f}\")\n",
    "print(f\"Precision@4: {metrics_results_4['precision@4']:.4f}\")\n",
    "print(f\"MRR@4: {metrics_results_4['mrr@4']:.4f}\")\n",
    "print(f\"nDCG@4: {metrics_results_4['ndcg@4']:.4f}\")\n",
    "\n",
    "print(\"\\nОценка подхода с reranker и top-6 фрагментами:\")\n",
    "print(f\"Recall@6: {metrics_results_6['recall@6']:.4f}\")\n",
    "print(f\"Precision@6: {metrics_results_6['precision@6']:.4f}\")\n",
    "print(f\"MRR@6: {metrics_results_6['mrr@6']:.4f}\")\n",
    "print(f\"nDCG@6: {metrics_results_6['ndcg@6']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd926641a8ff4fea9c67f1ed43a5a7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sekho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sekho\\.cache\\huggingface\\hub\\models--nboost--pt-tinybert-msmarco. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13ff7e3930f4407a720b9271ddb7b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3416d722274c7b8f4b010fb7774699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/58.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d830a2aa664d328450975a2b94f54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/58.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка подхода с reranker и top-4 фрагментами:\n",
      "Recall@4: 1.0000\n",
      "Precision@4: 0.3729\n",
      "MRR@4: 0.6813\n",
      "nDCG@4: 0.9473\n",
      "\n",
      "Оценка подхода с reranker и top-6 фрагментами:\n",
      "Recall@6: 1.0000\n",
      "Precision@6: 0.3069\n",
      "MRR@6: 0.6890\n",
      "nDCG@6: 0.9401\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from pipeline_file import DocumentationQA\n",
    "import time\n",
    "from FlagEmbedding import FlagReranker\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Инициализация reranker'а\n",
    "class TinyBERTReranker:\n",
    "    def __init__(self, model_name='nboost/pt-tinybert-msmarco', batch_size=16, device=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        # Выбор устройства\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def compute_score(self, pairs):\n",
    "        scores = []\n",
    "        for i in range(0, len(pairs), self.batch_size):\n",
    "            batch_pairs = pairs[i:i+self.batch_size]\n",
    "            inputs = self.tokenizer(\n",
    "                batch_pairs,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                batch_scores = torch.nn.functional.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
    "                scores.extend(batch_scores)\n",
    "        return scores\n",
    "\n",
    "# Чтение данных из CSV\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "\n",
    "# Инициализация системы ретривала\n",
    "qa_system = DocumentationQA()\n",
    "qa_system.initialize_database()\n",
    "\n",
    "# Инициализация reranker'а\n",
    "reranker = TinyBERTReranker()\n",
    "\n",
    "# Получение API ключа\n",
    "with open('api.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Создаю списки для хранения результатов\n",
    "retrieval_results_4 = []  # Результаты для top-4 после reranker'а\n",
    "retrieval_results_6 = []  # Результаты для top-6 после reranker'а\n",
    "\n",
    "# Обрабатываю каждый вопрос\n",
    "for index, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    \n",
    "    # Сначала получаем 20 фрагментов\n",
    "    initial_fragments = qa_system.search_similar_paragraphs(question, top_k=20)\n",
    "    \n",
    "    # Подготовка пар \"вопрос-фрагмент\" для reranker'а\n",
    "    pairs = [(question, fragment[0]) for fragment in initial_fragments]\n",
    "    \n",
    "    # Применение reranker'а\n",
    "    reranker_scores = reranker.compute_score(pairs)\n",
    "    \n",
    "    # Создаем кортежи (текст, имя, первоначальный скор, скор reranker'а)\n",
    "    reranked_fragments = [(fragment[0], fragment[1], fragment[2], score) \n",
    "                         for fragment, score in zip(initial_fragments, reranker_scores)]\n",
    "    \n",
    "    # Сортировка по скору reranker'а\n",
    "    reranked_fragments = sorted(reranked_fragments, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # Отбираем top-4 и top-6 после reranking'а\n",
    "    top_4_fragments = reranked_fragments[:4]\n",
    "    top_6_fragments = reranked_fragments[:6]\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    retrieval_results_4.append({\n",
    "        'question': question,\n",
    "        'fragments': top_4_fragments\n",
    "    })\n",
    "    \n",
    "    retrieval_results_6.append({\n",
    "        'question': question,\n",
    "        'fragments': top_6_fragments\n",
    "    })\n",
    "\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": 'chad-ea4e58bc0ac4441ca91e1188ca33120cpsekgbal'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-4\n",
    "for result in retrieval_results_4:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Делаю задержку между запросами\n",
    "        time.sleep(2)\n",
    "        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-6\n",
    "for result in retrieval_results_6:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Для фрагментов, которые уже оценены в top-4, не делаем повторный запрос\n",
    "        if i < 4:\n",
    "            # Находим соответствующий фрагмент в top-4 и берем оценку оттуда\n",
    "            for r4 in retrieval_results_4:\n",
    "                if r4['question'] == question:\n",
    "                    # Ищем совпадающий фрагмент\n",
    "                    for f4 in r4['fragments']:\n",
    "                        if f4[0] == text:\n",
    "                            relevance_score = f4[4]  # Используем уже полученную оценку\n",
    "                            break\n",
    "                    break\n",
    "        else:\n",
    "            # Для новых фрагментов делаем запрос\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        \n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "def calculate_metrics_reranker(retrieval_results, k_value):\n",
    "    metrics = {\n",
    "        f'recall@{k_value}': [],\n",
    "        f'precision@{k_value}': [],\n",
    "        f'mrr@{k_value}': [],\n",
    "        f'ndcg@{k_value}': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[4], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору reranker'а (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[4] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@k\n",
    "            relevant_at_k = sum(1 for f in retrieved_fragments[:k_value] if f[4] >= 4)\n",
    "            metrics[f'recall@{k_value}'].append(relevant_at_k / total_relevant)\n",
    "            \n",
    "            # Precision@k\n",
    "            metrics[f'precision@{k_value}'].append(relevant_at_k / k_value)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics[f'recall@{k_value}'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics[f'precision@{k_value}'].append(0.0)\n",
    "        \n",
    "        # MRR@k (Mean Reciprocal Rank)\n",
    "        first_relevant_rank = next((i + 1 for i, f in enumerate(retrieved_fragments[:k_value]) if f[4] >= 4), 0)\n",
    "        if first_relevant_rank > 0:\n",
    "            metrics[f'mrr@{k_value}'].append(1.0 / first_relevant_rank)\n",
    "        else:\n",
    "            metrics[f'mrr@{k_value}'].append(0.0)\n",
    "        \n",
    "        # nDCG@k\n",
    "        if len(sorted_fragments) >= k_value and len(retrieved_fragments) >= k_value:\n",
    "            # Берем только первые k документов\n",
    "            true_relevance = np.array([f[4] for f in sorted_fragments[:k_value]])\n",
    "            predicted_relevance = np.array([f[4] for f in retrieved_fragments[:k_value]])\n",
    "            \n",
    "            try:\n",
    "                ndcg = ndcg_score([true_relevance], [predicted_relevance])\n",
    "                metrics[f'ndcg@{k_value}'].append(ndcg)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@{k_value}: {e}\")\n",
    "                metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "        else:\n",
    "            metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Вычисляем метрики для top-4 результатов\n",
    "metrics_results_4 = calculate_metrics_reranker(retrieval_results_4, 4)\n",
    "\n",
    "# Вычисляем метрики для top-6 результатов\n",
    "metrics_results_6 = calculate_metrics_reranker(retrieval_results_6, 6)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Оценка подхода с reranker и top-4 фрагментами:\")\n",
    "print(f\"Recall@4: {metrics_results_4['recall@4']:.4f}\")\n",
    "print(f\"Precision@4: {metrics_results_4['precision@4']:.4f}\")\n",
    "print(f\"MRR@4: {metrics_results_4['mrr@4']:.4f}\")\n",
    "print(f\"nDCG@4: {metrics_results_4['ndcg@4']:.4f}\")\n",
    "\n",
    "print(\"\\nОценка подхода с reranker и top-6 фрагментами:\")\n",
    "print(f\"Recall@6: {metrics_results_6['recall@6']:.4f}\")\n",
    "print(f\"Precision@6: {metrics_results_6['precision@6']:.4f}\")\n",
    "print(f\"MRR@6: {metrics_results_6['mrr@6']:.4f}\")\n",
    "print(f\"nDCG@6: {metrics_results_6['ndcg@6']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27597bb5e71c47d9bf745163af33f913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sekho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sekho\\.cache\\huggingface\\hub\\models--sentence-transformers--msmarco-distilbert-base-tas-b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99b5f84298c40cdaaec10b16064e269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-tas-b and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bf026222744465bb90e70b97c6a4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb15bb636a54d1489fe640705e0d0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0573dfaf97f46459b16ee2ca9d12048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbef97fc15d84e82aaa0a99d5deced26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7becefd3d7264152b3fda1880a9b7721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c349f62181c4f5baded77ee042fb2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855f3dfc035b4a399f1b01339cba3476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a16a5ea4c3a470980cdaa163b393441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ad3371fa2f4697a4c9231a1ed34404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11ccf10c48c48d18b8dbb720c6d2ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0062de2e502a453080c5bbaba6086611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc866de654343bda669e9f9643c7f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0ad10aacbf4a238f017f4649965baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3381aaf393416f8f3a54b62a1875d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a001cb7e05d4586b9fba0afd32a9404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd7bf95afd34b3580e0f231e8813df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de7f17ee5844b11bdcafe9aae754b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda4b1ce6b4f46078b441357936a4ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd84ec11ef94db0a8f7d058dfae5aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c83655de89405c8b7d0c9ee933837f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9751504489c0438cab348abb395f2da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b907b36c545de85118e3af118acb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972896d62cf24401926f054fad9a2bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9193964dc7f0493985860c63c18c2087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a63ed7bb0c43b3a19aebab109e43cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362325a0286e4e3ea5f867c2eb8f5701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e758bb5d7a4563b4b7e3eb98ee8813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d82f17e8f24393bf85003338b81db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6041b23a093b4983aaa7e80e8b76975f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5545073883841dc8931b778f361964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d2dfcf9c644bea82c7d36c5e2720f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6712d297de433294d0a53641779f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0491974c06b84508a7171bfa7a7ec1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557b8dad51864d0ba0a0d18aab963b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dce8405989f46aaaa6353d8408f16df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f7729b56b44fe2b3e849a7fffac5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6573f43164154ef9a83da1367dd13692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d650f1fc6cf14d3dae70c44ef76f9b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b05e022d5144287870d6c7f85f0246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2386ec07ff2246ebbb244d90f618ce9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a79c9672f574281bd0c6d1f0831df17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866daae5b3ca42afbc036b8110118bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a423a139b30e4f1f94db044be83a907a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c92f80ec6d24b18b16b4c61788cdaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c2bb2b27f64919a728959f8f9e9e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fffedff48c4205880a573cf055465a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220c569a87974f34afa728b8d47aae72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae51af1ca0b145ee9bbf51cd309ee6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52798bfa57a444afb828370c037b6d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff1ec0661f64ed4893abcdeaa99e111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb189ea182f64788b89ae3ae5ec8ac59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffc73411efc49d6bcfae8baa109ac4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86edff064f44fb589f93f1f45a8e969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7980ff2636543ccb1555beb12b40521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304a471ff64b4210ae258cf23a1a4853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ec3d4ef6154282ac63696a13da04a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f0c5546b0b4abfaaae1dd87c036cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb83e9dd2e124e1893576c5d3a2c0048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92896d72b0854903a1a48a3ae277365c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb32bc1f47bd4a3eb79009f0b3e9d2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240167f097ee487d8ad06c1f8462242f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bec15d5ee8451ca3059ee8f29d5bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fc0bc27c1a4aa590d5868f0bb87e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a683499cf04c669223a93d4d6ed7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f0372b474041bb801327d57af517f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85248a9664ff492d87910b58ec9d7d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e452d07b81243c8a7c7a5347de2a033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f76cdb823a4e15935c2965f1064d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b23864bdd294e3eaf5551dc8ab5a1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae750bdd8f294b6889593587d3e57ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c53eff5c8724a9c9e469a9dc4bec736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665c66224b324000a8a596628d6a4fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc6c37283f45a4b65075b8eb514328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbd1e6021b84446bc671f887f4fd7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce15f1edb18341e59198d17d74b56570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1854e25bf6424f468bd7e45547240c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1299c6e631b44350be8346a4e49f2f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861e933948664357a7ca898dc68f88ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847ee136305d4f739c6acd087d7660f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbfdfd30f734b069a80ccc336430094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7680ab320d34eefbb0095650829033d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6a6ce2f18f4c77a9f6de8500e5d450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8201f5e86d741f8a762e954da74873f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5200fc5a8da436aacdc2ad4545b2cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4ea76861e74106b3c19967922657d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bde58cde6844b018e2ba4f938a64c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba55ce1487e40adbedb1d0363fbe618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6904ee1d62b47b8a4c6ad9636df7c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c9bb31d5894ca5b70481907a9b5b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc3d6448b27445f9fd85c576d158fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90b7cb57d0541699385e00194a39cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f693db4ab274a9594fa73fa014aee56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f04f1b8c2e4c79afc7b9b233e4d738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120d87d66885454c950e34bda72970c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ab402acdd74fada8eef97f31479b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d989b09f8a3a4b3abeae6e6533df532d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2492ca8bf852450a92327b1251562bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d78fddc9be40d8b44c4ebdccb236fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687f21a9fd98403d9146e895773407fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b8be15a52b44b88d006826be74c756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d748965f8a9b46189955cf252956746d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dcf6bf5b84497181da8e38047a0b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29994d467eab4702b393b52217f888b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420ff526c06941d2b6bab5f26c12f2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaa3decd77a47dbab8e003d35429cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07467c7594cc49dc8240d7418fe2a265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb4a22983134a07a43dfbb6490a7381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd550c5cc3304907a9d432377bac17ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29c47deb67d4c24a2e009719e6a09b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde7fd2e0fe44ccd994f48c6b5e48ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6564380a1a794115bf80e94a7c022988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7544d4f3c3b64fb89171ff7b940c4a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdad529a0f64739aaf268ef73113fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a276f470ec9422bab0b7a28b7e1d534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b2de40abcc4dbb84e34dfd33b02355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7f4c80bc2646d0928bf8a1f0a0142f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c839f2784f4ed2a3236abae84e8231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182d6f22a865488da66d62d352f064a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdc3363114541c4a92916e89cd894ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a8ff63f2384be2a8ef77bbb4b2d516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461cb41509c14c26a76a884d8a9808c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e66e74054d4433bd26413b68586614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3b0e4490fe49929c66ce01b171919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203515fe531c4252b71f5f3f67d120fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка подхода с reranker и top-4 фрагментами:\n",
      "Recall@4: 1.0000\n",
      "Precision@4: 0.2083\n",
      "MRR@4: 0.3069\n",
      "nDCG@4: 0.9244\n",
      "\n",
      "Оценка подхода с reranker и top-6 фрагментами:\n",
      "Recall@6: 1.0000\n",
      "Precision@6: 0.2028\n",
      "MRR@6: 0.3286\n",
      "nDCG@6: 0.9084\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from pipeline_file import DocumentationQA\n",
    "import time\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "# Чтение данных из CSV\n",
    "df = pd.read_csv('texts_with_answers.csv')\n",
    "\n",
    "# Инициализация системы ретривала\n",
    "qa_system = DocumentationQA()\n",
    "qa_system.initialize_database()\n",
    "\n",
    "# Инициализация reranker'а\n",
    "reranker = CrossEncoder('sentence-transformers/msmarco-distilbert-base-tas-b')\n",
    "\n",
    "# Получение API ключа\n",
    "with open('api.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Создаю списки для хранения результатов\n",
    "retrieval_results_4 = []  # Результаты для top-4 после reranker'а\n",
    "retrieval_results_6 = []  # Результаты для top-6 после reranker'а\n",
    "\n",
    "# Обрабатываю каждый вопрос\n",
    "for index, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    \n",
    "    # Сначала получаем 20 фрагментов\n",
    "    initial_fragments = qa_system.search_similar_paragraphs(question, top_k=20)\n",
    "    \n",
    "    # Подготовка пар \"вопрос-фрагмент\" для reranker'а\n",
    "    pairs = [(question, fragment[0]) for fragment in initial_fragments]\n",
    "    \n",
    "    # Применение reranker'а\n",
    "    reranker_scores = reranker.predict(pairs, batch_size=16, show_progress_bar=True, convert_to_numpy=True)\n",
    "    \n",
    "    # Создаем кортежи (текст, имя, первоначальный скор, скор reranker'а)\n",
    "    reranked_fragments = [(fragment[0], fragment[1], fragment[2], score) \n",
    "                         for fragment, score in zip(initial_fragments, reranker_scores)]\n",
    "    \n",
    "    # Сортировка по скору reranker'а\n",
    "    reranked_fragments = sorted(reranked_fragments, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # Отбираем top-4 и top-6 после reranking'а\n",
    "    top_4_fragments = reranked_fragments[:4]\n",
    "    top_6_fragments = reranked_fragments[:6]\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    retrieval_results_4.append({\n",
    "        'question': question,\n",
    "        'fragments': top_4_fragments\n",
    "    })\n",
    "    \n",
    "    retrieval_results_6.append({\n",
    "        'question': question,\n",
    "        'fragments': top_6_fragments\n",
    "    })\n",
    "\n",
    "def evaluate_relevance_with_claude(question, fragment_text, api_key):\n",
    "    url = \"https://ask.chadgpt.ru/api/public/gpt-4o-mini\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Задача: оценить релевантность текстового фрагмента вопросу.\n",
    "    \n",
    "    Вопрос: {question}\n",
    "    \n",
    "    Фрагмент: {fragment_text}\n",
    "    \n",
    "    Оцени релевантность фрагмента к вопросу по шкале от 1 до 5, где:\n",
    "    1 - совершенно не релевантен\n",
    "    2 - слабо релевантен\n",
    "    3 - умеренно релевантен\n",
    "    4 - очень релевантен\n",
    "    5 - идеально релевантен\n",
    "    \n",
    "    Ответь только числом от 1 до 5 без пояснений.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формируем запрос согласно примеру\n",
    "    request_json = {\n",
    "        \"message\": prompt,\n",
    "        \"api_key\": 'chad-ea4e58bc0ac4441ca91e1188ca33120cpsekgbal'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Отправляем запрос и дожидаемся ответа\n",
    "        response = requests.post(url=url, json=request_json)\n",
    "        \n",
    "        # Проверяем, отправился ли запрос\n",
    "        if response.status_code != 200:\n",
    "            print(f'Ошибка! Код http-ответа: {response.status_code}')\n",
    "            return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "        else:\n",
    "            # Получаем текст ответа и преобразовываем в dict\n",
    "            resp_json = response.json()\n",
    "            \n",
    "            # Если успешен ответ, то извлекаем результат\n",
    "            if resp_json['is_success']:\n",
    "                resp_msg = resp_json['response'].strip()\n",
    "                # Ищем число от 1 до 5 в ответе\n",
    "                import re\n",
    "                score_match = re.search(r'[1-5]', resp_msg)\n",
    "                if score_match:\n",
    "                    relevance_score = int(score_match.group(0))\n",
    "                    return relevance_score\n",
    "                else:\n",
    "                    print(f'Не удалось извлечь оценку из ответа: {resp_msg}')\n",
    "                    return 3  # Средняя оценка по умолчанию в случае неоднозначного ответа\n",
    "            else:\n",
    "                error = resp_json['error_message']\n",
    "                print(f'Ошибка: {error}')\n",
    "                return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "    except Exception as e:\n",
    "        print(f'Исключение при обработке запроса: {str(e)}')\n",
    "        return 1  # Возвращаем минимальную оценку в случае ошибки\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-4\n",
    "for result in retrieval_results_4:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Делаю задержку между запросами\n",
    "        time.sleep(2)\n",
    "        relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "# Добавляю оценки релевантности к результатам для top-6\n",
    "for result in retrieval_results_6:\n",
    "    question = result['question']\n",
    "    for i, (text, name, initial_score, reranker_score) in enumerate(result['fragments']):\n",
    "        # Для фрагментов, которые уже оценены в top-4, не делаем повторный запрос\n",
    "        if i < 4:\n",
    "            # Находим соответствующий фрагмент в top-4 и берем оценку оттуда\n",
    "            for r4 in retrieval_results_4:\n",
    "                if r4['question'] == question:\n",
    "                    # Ищем совпадающий фрагмент\n",
    "                    for f4 in r4['fragments']:\n",
    "                        if f4[0] == text:\n",
    "                            relevance_score = f4[4]  # Используем уже полученную оценку\n",
    "                            break\n",
    "                    break\n",
    "        else:\n",
    "            # Для новых фрагментов делаем запрос\n",
    "            time.sleep(2)\n",
    "            relevance_score = evaluate_relevance_with_claude(question, text, api_key)\n",
    "        \n",
    "        result['fragments'][i] = (text, name, initial_score, reranker_score, relevance_score)\n",
    "\n",
    "def calculate_metrics_reranker(retrieval_results, k_value):\n",
    "    metrics = {\n",
    "        f'recall@{k_value}': [],\n",
    "        f'precision@{k_value}': [],\n",
    "        f'mrr@{k_value}': [],\n",
    "        f'ndcg@{k_value}': []\n",
    "    }\n",
    "    \n",
    "    for result in retrieval_results:\n",
    "        fragments = result['fragments']\n",
    "        \n",
    "        # Сортировка фрагментов по оценке релевантности от Claude (по убыванию)\n",
    "        sorted_fragments = sorted(fragments, key=lambda x: x[4], reverse=True)\n",
    "        \n",
    "        # Сортировка фрагментов по скору reranker'а (по убыванию)\n",
    "        retrieved_fragments = sorted(fragments, key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        # Вычисление Recall@k\n",
    "        relevant_fragments = [f for f in sorted_fragments if f[4] >= 4]  # Считаем релевантными фрагменты с оценкой >= 4\n",
    "        total_relevant = len(relevant_fragments)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            # Recall@k\n",
    "            relevant_at_k = sum(1 for f in retrieved_fragments[:k_value] if f[4] >= 4)\n",
    "            metrics[f'recall@{k_value}'].append(relevant_at_k / total_relevant)\n",
    "            \n",
    "            # Precision@k\n",
    "            metrics[f'precision@{k_value}'].append(relevant_at_k / k_value)\n",
    "        else:\n",
    "            # Если нет релевантных фрагментов, устанавливаем recall = 1.0 (все релевантные найдены)\n",
    "            metrics[f'recall@{k_value}'].append(1.0)\n",
    "            \n",
    "            # Если нет релевантных фрагментов, устанавливаем precision = 0.0\n",
    "            metrics[f'precision@{k_value}'].append(0.0)\n",
    "        \n",
    "        # MRR@k (Mean Reciprocal Rank)\n",
    "        first_relevant_rank = next((i + 1 for i, f in enumerate(retrieved_fragments[:k_value]) if f[4] >= 4), 0)\n",
    "        if first_relevant_rank > 0:\n",
    "            metrics[f'mrr@{k_value}'].append(1.0 / first_relevant_rank)\n",
    "        else:\n",
    "            metrics[f'mrr@{k_value}'].append(0.0)\n",
    "        \n",
    "        # nDCG@k\n",
    "        if len(sorted_fragments) >= k_value and len(retrieved_fragments) >= k_value:\n",
    "            # Берем только первые k документов\n",
    "            true_relevance = np.array([f[4] for f in sorted_fragments[:k_value]])\n",
    "            predicted_relevance = np.array([f[4] for f in retrieved_fragments[:k_value]])\n",
    "            \n",
    "            try:\n",
    "                ndcg = ndcg_score([true_relevance], [predicted_relevance])\n",
    "                metrics[f'ndcg@{k_value}'].append(ndcg)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при вычислении nDCG@{k_value}: {e}\")\n",
    "                metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "        else:\n",
    "            metrics[f'ndcg@{k_value}'].append(0.0)\n",
    "    \n",
    "    # Вычисляем средние значения метрик\n",
    "    result_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        result_metrics[key] = sum(values) / len(values) if values else 0.0\n",
    "    \n",
    "    return result_metrics\n",
    "\n",
    "# Вычисляем метрики для top-4 результатов\n",
    "metrics_results_4 = calculate_metrics_reranker(retrieval_results_4, 4)\n",
    "\n",
    "# Вычисляем метрики для top-6 результатов\n",
    "metrics_results_6 = calculate_metrics_reranker(retrieval_results_6, 6)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Оценка подхода с reranker и top-4 фрагментами:\")\n",
    "print(f\"Recall@4: {metrics_results_4['recall@4']:.4f}\")\n",
    "print(f\"Precision@4: {metrics_results_4['precision@4']:.4f}\")\n",
    "print(f\"MRR@4: {metrics_results_4['mrr@4']:.4f}\")\n",
    "print(f\"nDCG@4: {metrics_results_4['ndcg@4']:.4f}\")\n",
    "\n",
    "print(\"\\nОценка подхода с reranker и top-6 фрагментами:\")\n",
    "print(f\"Recall@6: {metrics_results_6['recall@6']:.4f}\")\n",
    "print(f\"Precision@6: {metrics_results_6['precision@6']:.4f}\")\n",
    "print(f\"MRR@6: {metrics_results_6['mrr@6']:.4f}\")\n",
    "print(f\"nDCG@6: {metrics_results_6['ndcg@6']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
